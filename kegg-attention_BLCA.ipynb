{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094868a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ed8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genes-pathways annotation\n",
    "\n",
    "path = './KEGG_pathways/20230205_kegg_hsa.gmt'\n",
    "\n",
    "files = open(path,encoding='utf-8')\n",
    "\n",
    "files = files.readlines()\n",
    "\n",
    "paways_genes_dict = {}\n",
    "for i in files: \n",
    "    paways_genes_dict[i.split('\\t')[0].split('_')[0]] = i.replace('\\n','').split('\\t')[2:] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376544fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mirna-pathways annotation\n",
    "path = './KEGG_pathways/kegg_anano.txt'\n",
    "\n",
    "files = open(path,encoding='utf-8')\n",
    "\n",
    "files = files.readlines()\n",
    "\n",
    "paways_mirna_dict = {}\n",
    "for i in files:\n",
    "     keys = i.split(',')[0].split('|')[1]\n",
    "     values1 = i.split(',')[1:-1]\n",
    "     values2 =  i.split(',')[-1].replace('\\n','')\n",
    "     values1.append(values2)\n",
    "     values1 =list(set(values1)) \n",
    "     paways_mirna_dict[keys] = values1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27293b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_kegg = list(set(paways_genes_dict.keys()).intersection(set(paways_mirna_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cde7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "paways_genes_dicts ={}\n",
    "paways_mirna_dicts ={}\n",
    "\n",
    "for i in union_kegg:\n",
    "    paways_genes_dicts[i] = paways_genes_dict[i]\n",
    "    \n",
    "for i in union_kegg:\n",
    "    paways_mirna_dicts[i] = paways_mirna_dict[i]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fe7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genes_existed_pathway = []\n",
    "\n",
    "mirna_existed_pathway = []\n",
    "\n",
    "for index in paways_genes_dicts.keys():\n",
    "    genes_existed_pathway = genes_existed_pathway+ list(paways_genes_dicts[index])\n",
    "genes_existed_pathway = set(genes_existed_pathway)\n",
    "\n",
    "\n",
    "for index in paways_mirna_dicts.keys():\n",
    "    mirna_existed_pathway = mirna_existed_pathway+ list(paways_mirna_dicts[index])\n",
    "mirna_existed_pathway = set(mirna_existed_pathway)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d8c874f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7768\n",
      "812\n"
     ]
    }
   ],
   "source": [
    "print(len(genes_existed_pathway))\n",
    "print(len(mirna_existed_pathway))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948c50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3877bbba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading data\n",
    "snv_data = pd.read_csv(\"./BLCA_data/snv_data.csv\",index_col = 0)\n",
    "\n",
    "miRNA_data = pd.read_csv(\"./BLCA_data/miRNA_data.csv\",index_col = 0)\n",
    "\n",
    "mRNA_data = pd.read_csv(\"./BLCA_data/mRNA_data.csv\",index_col = 0)\n",
    "\n",
    "example_case = pd.read_csv('./BLCA_data/response.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8a004d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402, 1000)\n",
      "(402, 1000)\n",
      "(402, 100)\n"
     ]
    }
   ],
   "source": [
    "print(snv_data.shape)\n",
    "print(mRNA_data.shape)\n",
    "print(miRNA_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5295fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_gene_snv = list(snv_data.columns)\n",
    "union_gene_miRNA = list(miRNA_data.columns)\n",
    "union_gene_mRNA = list(mRNA_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0b65eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathway_union = list(paways_genes_dicts.keys())\n",
    "len(pathway_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0608bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_list = [union_gene_snv,union_gene_mRNA]\n",
    "\n",
    "gene_pathway_bp_dfs = []\n",
    "\n",
    "\n",
    "for i in range(len(mask_list)):\n",
    "    pathways_genes = np.zeros((len(pathway_union), len(mask_list[i]))) \n",
    "    for p  in pathway_union:\n",
    "        gs = paways_genes_dicts[p]\n",
    "        g_inds = [mask_list[i].index(g) for g in gs if g in mask_list[i]]\n",
    "        p_ind = pathway_union.index(p)\n",
    "        pathways_genes[p_ind, g_inds] = 1\n",
    "    gene_pathway_bp = pd.DataFrame(pathways_genes, index=pathway_union, columns=mask_list[i])\n",
    "    \n",
    "    gene_pathway_bp_dfs.append(gene_pathway_bp)\n",
    "    \n",
    "\n",
    "pathways_genes = np.zeros((len(pathway_union), len(union_gene_miRNA))) \n",
    "for p  in pathway_union:\n",
    "    gs = paways_mirna_dicts[p]\n",
    "    g_inds = [union_gene_miRNA.index(g) for g in gs if g in union_gene_miRNA]\n",
    "    p_ind = pathway_union.index(p)\n",
    "    pathways_genes[p_ind, g_inds] = 1\n",
    "gene_pathway_bp = pd.DataFrame(pathways_genes, index=pathway_union, columns=union_gene_miRNA)\n",
    "\n",
    "gene_pathway_bp_dfs.append(gene_pathway_bp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9d194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15821250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_pathway_bp_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "125e5848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import glorot_uniform, Initializer\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, GlobalAveragePooling1D,Layer\n",
    "from tensorflow.keras import initializers,activations,regularizers\n",
    "from tensorflow.keras.regularizers import Regularizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    " \n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11f21ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Biological_module(Layer):\n",
    "    def __init__(self, units, mapp=None, nonzero_ind=None, kernel_initializer='glorot_uniform', W_regularizer=None,\n",
    "                 activation='tanh', use_bias=True,bias_initializer='zeros', bias_regularizer=None,\n",
    "                 bias_constraint=None,**kwargs):\n",
    "        \n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.mapp = mapp\n",
    "        self.nonzero_ind = nonzero_ind\n",
    "        self.use_bias = use_bias\n",
    "        \n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(W_regularizer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activation_fn = activations.get(activation)\n",
    "        super(Biological_module, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        input_dim = input_shape[1]\n",
    "   \n",
    "\n",
    "        if not self.mapp is None:\n",
    "            self.mapp = self.mapp.astype(np.float32)\n",
    "\n",
    "   \n",
    "        if self.nonzero_ind is None:\n",
    "            nonzero_ind = np.array(np.nonzero(self.mapp)).T\n",
    "            self.nonzero_ind = nonzero_ind\n",
    "\n",
    "        self.kernel_shape = (input_dim, self.units)\n",
    "        \n",
    "\n",
    "        nonzero_count = self.nonzero_ind.shape[0]   \n",
    "\n",
    "\n",
    "        self.kernel_vector = self.add_weight(name='kernel_vector',\n",
    "                                             shape=(nonzero_count,),\n",
    "                                             initializer=self.kernel_initializer,\n",
    "                                             regularizer=self.kernel_regularizer,\n",
    "                                             trainable=True)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer\n",
    "                                        )\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        super(Biological_module, self).build(input_shape)  \n",
    "      \n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        \n",
    "        trans = tf.scatter_nd(tf.constant(self.nonzero_ind, tf.int32), self.kernel_vector,\n",
    "                           tf.constant(list(self.kernel_shape)))\n",
    "    \n",
    "        output = K.dot(inputs, trans)\n",
    "        \n",
    "    \n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias)\n",
    "            \n",
    "        if self.activation_fn is not None:\n",
    "            output = self.activation_fn(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'activation': self.activation,\n",
    "            'use_bias': self.use_bias,\n",
    "            'nonzero_ind': np.array(self.nonzero_ind),\n",
    "          \n",
    "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "\n",
    "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "            'W_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "\n",
    "        }\n",
    "        base_config = super(Biological_module, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "      \n",
    "        return (input_shape[0], self.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c438cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attention(Layer):\n",
    " \n",
    "    def __init__(self, output_dim,  W_regularizer=None,**kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.kernel_regularizer = regularizers.get(W_regularizer)\n",
    "        super(Self_Attention, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(3,input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      trainable=True)\n",
    " \n",
    "        super(Self_Attention, self).build(input_shape)  \n",
    " \n",
    "    def call(self, x):\n",
    "        WQ = K.dot(x, self.kernel[0])\n",
    "        WK = K.dot(x, self.kernel[1])\n",
    "        WV = K.dot(x, self.kernel[2])\n",
    " \n",
    "\n",
    "        print(\"K.permute_dimensions(WK.shape\",(K.permute_dimensions(WK,[1,0]).shape))\n",
    " \n",
    "        QK =  K.dot(K.permute_dimensions(WK,[1,0]),WQ)\n",
    "    \n",
    " \n",
    "        QK = QK / (64**0.5)\n",
    " \n",
    "        QK = K.softmax(QK)\n",
    " \n",
    "        print(\"QK.shape\",QK.shape)\n",
    " \n",
    "        V = K.dot(WV,QK)\n",
    "        \n",
    "        print(V.shape)\n",
    " \n",
    "        return V\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          \n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "\n",
    "\n",
    "        }\n",
    "        base_config = super(Self_Attention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    " \n",
    "        return (input_shape[0],input_shape[1],self.output_dim)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab00da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "020e30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(snv_data,mRNA_data,miRNA_data):\n",
    "    \n",
    "    S_inputs_snv = Input(shape=(snv_data.shape[1],), dtype='float32',name= 'snv_inputs')\n",
    "    \n",
    "    S_inputs_mRNA = Input(shape=(mRNA_data.shape[1],), dtype='float32',name= 'mRNA_inputs')\n",
    "  \n",
    "    S_inputs_miRNA = Input(shape=(miRNA_data.shape[1],), dtype='float32',name= 'miRNA_inputs')\n",
    "    \n",
    "\n",
    "    h0_snv = Biological_module(gene_pathway_bp_dfs[0].shape[0],mapp =gene_pathway_bp_dfs[0].values.T, name = 'h0_snv',W_regularizer=l2(0.001))(S_inputs_snv)\n",
    "\n",
    "    \n",
    "    h0_mRNA = Biological_module(gene_pathway_bp_dfs[1].shape[0],mapp =gene_pathway_bp_dfs[1].values.T, name = 'h0_mRNA',W_regularizer=l2(0.001))(S_inputs_mRNA)\n",
    "\n",
    "    \n",
    "    h0_miRNA = Biological_module(gene_pathway_bp_dfs[2].shape[0],mapp =gene_pathway_bp_dfs[2].values.T, name = 'h0_miRNA',W_regularizer=l2(0.001))(S_inputs_miRNA)\n",
    "\n",
    "\n",
    "    atten1 = Self_Attention(64,W_regularizer=l2(0.001))(h0_snv)\n",
    "    atten2 = Self_Attention(64,W_regularizer=l2(0.001))(h0_mRNA)\n",
    "    atten3 = Self_Attention(64,W_regularizer=l2(0.001))(h0_miRNA)\n",
    "    \n",
    "    feature_tal = tf.keras.layers.concatenate([atten1,atten2,atten3])\n",
    "\n",
    "    \n",
    "    h4 = tf.keras.layers.Dense(32,activation='tanh')(feature_tal)\n",
    "    \n",
    "    h5 = tf.keras.layers.Dense(1,activation='sigmoid')(h4)\n",
    "    \n",
    "\n",
    "    model = Model(inputs=[S_inputs_snv,S_inputs_mRNA,S_inputs_miRNA], outputs=h5)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 0.0001,decay=0.0001) \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8181c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1044dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation function\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "   \n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "def get_metrics(true_score,pre_score,pre_probe):\n",
    "    \n",
    "  \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_score, pre_probe, pos_label=1)\n",
    "   \n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    aupr = average_precision_score(true_score, pre_probe)\n",
    "    \n",
    "    pre, rec, thresholds = precision_recall_curve(true_score, pre_probe)    \n",
    "    auprc  = metrics.auc(rec, pre)\n",
    "    \n",
    "    \n",
    "    accuracy = accuracy_score(true_score,pre_score)\n",
    "    \n",
    "    f1 = metrics.f1_score(true_score, pre_score)\n",
    "    \n",
    "    precision = metrics.precision_score(true_score,pre_score)\n",
    "    \n",
    "    recall = metrics.recall_score(true_score,pre_score)\n",
    "    \n",
    "     \n",
    "    print( print(confusion_matrix(true_score,pre_score)))\n",
    "    return precision,accuracy,recall,f1,auc,aupr,auprc\n",
    "\n",
    "\n",
    "def evaluates(y_test, y_pred):\n",
    "    \n",
    "    auc = metrics.roc_auc_score(y_test,y_pred)\n",
    "    \n",
    "    aupr = average_precision_score(y_test, y_pred)\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)    \n",
    "    auprc  = metrics.auc(recall, precision)\n",
    "    \n",
    "    pp = [1 if index>=0.5  else 0 for index in  y_pred ]\n",
    "    \n",
    "    pre = metrics.precision_score(y_test,pp)\n",
    "    \n",
    "    f1 = metrics.f1_score(y_test,pp)\n",
    "    \n",
    "    rec = metrics.recall_score(y_test,pp)\n",
    "    \n",
    "    acc = metrics.accuracy_score(y_test,pp)\n",
    "    \n",
    "    print(confusion_matrix(y_test,pp))\n",
    "    return pre,acc,rec,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "825824f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_data = snv_data.loc[example_case.index]\n",
    "\n",
    "miRNA_data = miRNA_data.loc[example_case.index]\n",
    "\n",
    "mRNA_data = mRNA_data.loc[example_case.index]\n",
    "\n",
    "example_case = example_case.loc[example_case.index]\n",
    "\n",
    "y = example_case['response'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cad9be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402 143 259\n",
      "0.7760617760617761 1.4055944055944056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_samples =example_case['response'].values\n",
    "\n",
    "print(len(n_samples),n_samples.sum(),(len(n_samples) -n_samples.sum()))\n",
    "\n",
    "x_0 =  len(n_samples) / (2*  (len(n_samples) -n_samples.sum()))\n",
    "x_1 =  len(n_samples) / (2*  n_samples.sum())\n",
    "\n",
    "print(x_0,x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13f75a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance\n",
    "from keras.models import Sequential\n",
    "def get_layers(model, level=1):\n",
    "    layers = []\n",
    "    for i, l in enumerate(model.layers):\n",
    "\n",
    "        if type(l) == Sequential:\n",
    "            layers.extend(get_layers(l, level + 1))\n",
    "        else:\n",
    "            layers.append(l)\n",
    "\n",
    "    return layers\n",
    "\n",
    "\n",
    "\n",
    "positive_example= example_case[example_case['response']==1]\n",
    "snv_data_p = snv_data.loc[positive_example.index].values\n",
    "mRNA_data_p  = mRNA_data.loc[positive_example.index].values\n",
    "miRNA_data_p = miRNA_data.loc[positive_example.index].values\n",
    "\n",
    "\n",
    "data_pd_s = [snv_data,mRNA_data,miRNA_data]\n",
    "data_pd_name =['snv','mRNA','miRNA']\n",
    "def get_weigjts(model,p):\n",
    "    \n",
    "   \n",
    "    feed_dict ={}\n",
    "    model_layers = get_layers(model)\n",
    "    multi_data_inputs = [snv_data_p,mRNA_data_p,miRNA_data_p]\n",
    "    for i in range(0,3):\n",
    "        feed_dict[model.get_layer(model_layers[i].name).output] = multi_data_inputs[i]\n",
    "        \n",
    "    for k in range(0,3):\n",
    "        meth_inputs_name = model_layers[k].name\n",
    "        X = model.get_layer(meth_inputs_name).output \n",
    "        Y  = model.outputs[-1]\n",
    "        ret = [g * (x - b) for g, x, b in zip(tf.gradients(Y, X), [X], [np.zeros((multi_data_inputs[k].shape))[0].shape])]\n",
    "        sess = tf.compat.v1.InteractiveSession()\n",
    "        sess.run(tf.compat.v1.initialize_all_variables())\n",
    "        evaluated_gradients = sess.run(ret,feed_dict=feed_dict)\n",
    "        gene_pd = pd.DataFrame(columns=['genes','values'])\n",
    "        gene_pd['genes'] = data_pd_s[k].columns\n",
    "        gene_pd['values'] = evaluated_gradients[0].sum(axis=0)\n",
    "        gene_pd.to_csv('./coef_weight/BLCA/h{}/{}.csv'.format(p,data_pd_name[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80621e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b58a98f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " snv_inputs (InputLayer)        [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " mRNA_inputs (InputLayer)       [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " miRNA_inputs (InputLayer)      [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " h0_snv (Biological_module)     (None, 238)          3170        ['snv_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " h0_mRNA (Biological_module)    (None, 238)          3113        ['mRNA_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " h0_miRNA (Biological_module)   (None, 238)          8124        ['miRNA_inputs[0][0]']           \n",
      "                                                                                                  \n",
      " self__attention_18 (Self_Atten  (None, 64)          45696       ['h0_snv[0][0]']                 \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_19 (Self_Atten  (None, 64)          45696       ['h0_mRNA[0][0]']                \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_20 (Self_Atten  (None, 64)          45696       ['h0_miRNA[0][0]']               \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 192)          0           ['self__attention_18[0][0]',     \n",
      "                                                                  'self__attention_19[0][0]',     \n",
      "                                                                  'self__attention_20[0][0]']     \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 32)           6176        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            33          ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 157,704\n",
      "Trainable params: 157,704\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 321 samples, validate on 81 samples\n",
      "Epoch 1/170\n",
      "320/321 [============================>.] - ETA: 0s - loss: 0.8095 - acc: 0.4812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 1s 2ms/sample - loss: 0.8090 - acc: 0.4798 - val_loss: 0.8069 - val_acc: 0.3704\n",
      "Epoch 2/170\n",
      "321/321 [==============================] - 0s 423us/sample - loss: 0.8049 - acc: 0.4579 - val_loss: 0.8026 - val_acc: 0.6543\n",
      "Epoch 3/170\n",
      "321/321 [==============================] - 0s 590us/sample - loss: 0.8012 - acc: 0.6511 - val_loss: 0.7985 - val_acc: 0.6420\n",
      "Epoch 4/170\n",
      "321/321 [==============================] - 0s 475us/sample - loss: 0.7977 - acc: 0.6542 - val_loss: 0.7955 - val_acc: 0.5556\n",
      "Epoch 5/170\n",
      "321/321 [==============================] - 0s 298us/sample - loss: 0.7941 - acc: 0.5296 - val_loss: 0.7930 - val_acc: 0.3580\n",
      "Epoch 6/170\n",
      "321/321 [==============================] - 0s 295us/sample - loss: 0.7908 - acc: 0.3551 - val_loss: 0.7907 - val_acc: 0.3580\n",
      "Epoch 7/170\n",
      "321/321 [==============================] - 0s 329us/sample - loss: 0.7874 - acc: 0.3551 - val_loss: 0.7876 - val_acc: 0.3580\n",
      "Epoch 8/170\n",
      "321/321 [==============================] - 0s 298us/sample - loss: 0.7843 - acc: 0.3551 - val_loss: 0.7845 - val_acc: 0.3580\n",
      "Epoch 9/170\n",
      "321/321 [==============================] - 0s 295us/sample - loss: 0.7813 - acc: 0.3551 - val_loss: 0.7821 - val_acc: 0.3580\n",
      "Epoch 10/170\n",
      "321/321 [==============================] - 0s 295us/sample - loss: 0.7784 - acc: 0.3551 - val_loss: 0.7802 - val_acc: 0.3580\n",
      "Epoch 11/170\n",
      "321/321 [==============================] - 0s 398us/sample - loss: 0.7753 - acc: 0.3551 - val_loss: 0.7776 - val_acc: 0.3580\n",
      "Epoch 12/170\n",
      "321/321 [==============================] - 0s 360us/sample - loss: 0.7726 - acc: 0.3551 - val_loss: 0.7760 - val_acc: 0.3580\n",
      "Epoch 13/170\n",
      "321/321 [==============================] - 0s 301us/sample - loss: 0.7698 - acc: 0.3551 - val_loss: 0.7751 - val_acc: 0.3580\n",
      "Epoch 14/170\n",
      "321/321 [==============================] - 0s 286us/sample - loss: 0.7670 - acc: 0.3551 - val_loss: 0.7747 - val_acc: 0.3580\n",
      "Epoch 15/170\n",
      "321/321 [==============================] - 0s 301us/sample - loss: 0.7645 - acc: 0.3551 - val_loss: 0.7747 - val_acc: 0.3580\n",
      "Epoch 16/170\n",
      "321/321 [==============================] - 0s 323us/sample - loss: 0.7621 - acc: 0.3551 - val_loss: 0.7727 - val_acc: 0.3580\n",
      "Epoch 17/170\n",
      "321/321 [==============================] - 0s 329us/sample - loss: 0.7597 - acc: 0.3551 - val_loss: 0.7698 - val_acc: 0.3580\n",
      "Epoch 18/170\n",
      "321/321 [==============================] - 0s 329us/sample - loss: 0.7573 - acc: 0.3551 - val_loss: 0.7670 - val_acc: 0.3580\n",
      "Epoch 19/170\n",
      "321/321 [==============================] - 0s 348us/sample - loss: 0.7551 - acc: 0.3551 - val_loss: 0.7665 - val_acc: 0.3580\n",
      "Epoch 20/170\n",
      "321/321 [==============================] - 0s 301us/sample - loss: 0.7528 - acc: 0.3551 - val_loss: 0.7666 - val_acc: 0.3580\n",
      "Epoch 21/170\n",
      "321/321 [==============================] - 0s 336us/sample - loss: 0.7506 - acc: 0.3551 - val_loss: 0.7655 - val_acc: 0.3580\n",
      "Epoch 22/170\n",
      "321/321 [==============================] - 0s 304us/sample - loss: 0.7484 - acc: 0.3551 - val_loss: 0.7656 - val_acc: 0.3580\n",
      "Epoch 23/170\n",
      "321/321 [==============================] - 0s 267us/sample - loss: 0.7462 - acc: 0.3583 - val_loss: 0.7629 - val_acc: 0.3580\n",
      "Epoch 24/170\n",
      "321/321 [==============================] - 0s 404us/sample - loss: 0.7438 - acc: 0.3583 - val_loss: 0.7594 - val_acc: 0.3580\n",
      "Epoch 25/170\n",
      "321/321 [==============================] - 0s 497us/sample - loss: 0.7417 - acc: 0.3583 - val_loss: 0.7579 - val_acc: 0.3580\n",
      "Epoch 26/170\n",
      "321/321 [==============================] - 0s 510us/sample - loss: 0.7393 - acc: 0.3583 - val_loss: 0.7543 - val_acc: 0.3580\n",
      "Epoch 27/170\n",
      "321/321 [==============================] - 0s 314us/sample - loss: 0.7368 - acc: 0.3614 - val_loss: 0.7499 - val_acc: 0.3580\n",
      "Epoch 28/170\n",
      "321/321 [==============================] - 0s 245us/sample - loss: 0.7345 - acc: 0.3707 - val_loss: 0.7451 - val_acc: 0.3704\n",
      "Epoch 29/170\n",
      "321/321 [==============================] - 0s 242us/sample - loss: 0.7317 - acc: 0.4237 - val_loss: 0.7403 - val_acc: 0.4198\n",
      "Epoch 30/170\n",
      "321/321 [==============================] - 0s 295us/sample - loss: 0.7287 - acc: 0.5358 - val_loss: 0.7356 - val_acc: 0.5185\n",
      "Epoch 31/170\n",
      "321/321 [==============================] - 0s 245us/sample - loss: 0.7259 - acc: 0.6636 - val_loss: 0.7304 - val_acc: 0.6790\n",
      "Epoch 32/170\n",
      "321/321 [==============================] - 0s 332us/sample - loss: 0.7229 - acc: 0.7944 - val_loss: 0.7248 - val_acc: 0.7901\n",
      "Epoch 33/170\n",
      "321/321 [==============================] - 0s 308us/sample - loss: 0.7193 - acc: 0.8224 - val_loss: 0.7199 - val_acc: 0.7407\n",
      "Epoch 34/170\n",
      "321/321 [==============================] - 0s 317us/sample - loss: 0.7157 - acc: 0.7975 - val_loss: 0.7175 - val_acc: 0.8148\n",
      "Epoch 35/170\n",
      "321/321 [==============================] - 0s 269us/sample - loss: 0.7116 - acc: 0.8567 - val_loss: 0.7162 - val_acc: 0.8272\n",
      "Epoch 36/170\n",
      "321/321 [==============================] - 0s 320us/sample - loss: 0.7069 - acc: 0.8442 - val_loss: 0.7129 - val_acc: 0.8148\n",
      "Epoch 37/170\n",
      "321/321 [==============================] - 0s 295us/sample - loss: 0.7017 - acc: 0.8380 - val_loss: 0.7103 - val_acc: 0.7531\n",
      "Epoch 38/170\n",
      "321/321 [==============================] - 0s 326us/sample - loss: 0.6963 - acc: 0.8193 - val_loss: 0.7051 - val_acc: 0.7901\n",
      "Epoch 39/170\n",
      "321/321 [==============================] - 0s 345us/sample - loss: 0.6900 - acc: 0.8536 - val_loss: 0.6982 - val_acc: 0.8642\n",
      "Epoch 40/170\n",
      "321/321 [==============================] - 0s 308us/sample - loss: 0.6843 - acc: 0.8660 - val_loss: 0.6910 - val_acc: 0.8519\n",
      "Epoch 41/170\n",
      "321/321 [==============================] - 0s 339us/sample - loss: 0.6778 - acc: 0.8754 - val_loss: 0.6877 - val_acc: 0.8642\n",
      "Epoch 42/170\n",
      "321/321 [==============================] - 0s 497us/sample - loss: 0.6708 - acc: 0.8754 - val_loss: 0.6824 - val_acc: 0.8642\n",
      "Epoch 43/170\n",
      "321/321 [==============================] - 0s 432us/sample - loss: 0.6639 - acc: 0.8723 - val_loss: 0.6813 - val_acc: 0.7778\n",
      "Epoch 44/170\n",
      "321/321 [==============================] - 0s 345us/sample - loss: 0.6562 - acc: 0.8100 - val_loss: 0.6810 - val_acc: 0.6667\n",
      "Epoch 45/170\n",
      "321/321 [==============================] - 0s 336us/sample - loss: 0.6488 - acc: 0.7632 - val_loss: 0.6756 - val_acc: 0.6790\n",
      "Epoch 46/170\n",
      "321/321 [==============================] - 0s 308us/sample - loss: 0.6416 - acc: 0.7944 - val_loss: 0.6657 - val_acc: 0.7901\n",
      "Epoch 47/170\n",
      "321/321 [==============================] - 0s 261us/sample - loss: 0.6338 - acc: 0.8411 - val_loss: 0.6548 - val_acc: 0.8395\n",
      "Epoch 48/170\n",
      "321/321 [==============================] - 0s 388us/sample - loss: 0.6261 - acc: 0.8879 - val_loss: 0.6441 - val_acc: 0.8642\n",
      "Epoch 49/170\n",
      "321/321 [==============================] - 0s 308us/sample - loss: 0.6192 - acc: 0.8972 - val_loss: 0.6347 - val_acc: 0.8272\n",
      "Epoch 50/170\n",
      "321/321 [==============================] - 0s 280us/sample - loss: 0.6106 - acc: 0.9003 - val_loss: 0.6299 - val_acc: 0.8642\n",
      "Epoch 51/170\n",
      "321/321 [==============================] - 0s 311us/sample - loss: 0.6010 - acc: 0.8972 - val_loss: 0.6233 - val_acc: 0.8642\n",
      "Epoch 52/170\n",
      "321/321 [==============================] - 0s 278us/sample - loss: 0.5925 - acc: 0.9003 - val_loss: 0.6167 - val_acc: 0.8642\n",
      "Epoch 53/170\n",
      "321/321 [==============================] - 0s 320us/sample - loss: 0.5826 - acc: 0.8879 - val_loss: 0.6153 - val_acc: 0.8272\n",
      "Epoch 54/170\n",
      "321/321 [==============================] - 0s 363us/sample - loss: 0.5736 - acc: 0.8754 - val_loss: 0.6103 - val_acc: 0.8025\n",
      "Epoch 55/170\n",
      "321/321 [==============================] - 0s 1ms/sample - loss: 0.5643 - acc: 0.8723 - val_loss: 0.6018 - val_acc: 0.8272\n",
      "Epoch 56/170\n",
      "321/321 [==============================] - 0s 404us/sample - loss: 0.5554 - acc: 0.8816 - val_loss: 0.5947 - val_acc: 0.8272\n",
      "Epoch 57/170\n",
      "321/321 [==============================] - 0s 286us/sample - loss: 0.5455 - acc: 0.8754 - val_loss: 0.5961 - val_acc: 0.8148\n",
      "Epoch 58/170\n",
      "321/321 [==============================] - 0s 317us/sample - loss: 0.5356 - acc: 0.8193 - val_loss: 0.6041 - val_acc: 0.6914\n",
      "Epoch 59/170\n",
      "321/321 [==============================] - 0s 280us/sample - loss: 0.5284 - acc: 0.7632 - val_loss: 0.6131 - val_acc: 0.6173\n",
      "Epoch 60/170\n",
      "321/321 [==============================] - 0s 249us/sample - loss: 0.5205 - acc: 0.7383 - val_loss: 0.6016 - val_acc: 0.6667\n",
      "Epoch 61/170\n",
      "321/321 [==============================] - 0s 270us/sample - loss: 0.5101 - acc: 0.7850 - val_loss: 0.5820 - val_acc: 0.7407\n",
      "Epoch 62/170\n",
      "321/321 [==============================] - 0s 354us/sample - loss: 0.5003 - acc: 0.8162 - val_loss: 0.5670 - val_acc: 0.8025\n",
      "Epoch 63/170\n",
      "321/321 [==============================] - 0s 295us/sample - loss: 0.4920 - acc: 0.8629 - val_loss: 0.5574 - val_acc: 0.8025\n",
      "Epoch 64/170\n",
      "321/321 [==============================] - 0s 304us/sample - loss: 0.4841 - acc: 0.8629 - val_loss: 0.5567 - val_acc: 0.8025\n",
      "Epoch 65/170\n",
      "321/321 [==============================] - 0s 239us/sample - loss: 0.4763 - acc: 0.8567 - val_loss: 0.5523 - val_acc: 0.8025\n",
      "Epoch 66/170\n",
      "321/321 [==============================] - 0s 289us/sample - loss: 0.4689 - acc: 0.8349 - val_loss: 0.5571 - val_acc: 0.7407\n",
      "Epoch 67/170\n",
      "321/321 [==============================] - 0s 317us/sample - loss: 0.4622 - acc: 0.8037 - val_loss: 0.5619 - val_acc: 0.7160\n",
      "Epoch 68/170\n",
      "321/321 [==============================] - 0s 255us/sample - loss: 0.4588 - acc: 0.7757 - val_loss: 0.5670 - val_acc: 0.6790\n",
      "Epoch 69/170\n",
      "321/321 [==============================] - 0s 314us/sample - loss: 0.4502 - acc: 0.7819 - val_loss: 0.5483 - val_acc: 0.7284\n",
      "Epoch 70/170\n",
      "321/321 [==============================] - 0s 295us/sample - loss: 0.4394 - acc: 0.8349 - val_loss: 0.5259 - val_acc: 0.8025\n",
      "Epoch 71/170\n",
      "321/321 [==============================] - 0s 292us/sample - loss: 0.4305 - acc: 0.8629 - val_loss: 0.5134 - val_acc: 0.8025\n",
      "Epoch 72/170\n",
      "321/321 [==============================] - 0s 283us/sample - loss: 0.4227 - acc: 0.8785 - val_loss: 0.4977 - val_acc: 0.8642\n",
      "Epoch 73/170\n",
      "321/321 [==============================] - 0s 277us/sample - loss: 0.4183 - acc: 0.9159 - val_loss: 0.4843 - val_acc: 0.8889\n",
      "Epoch 74/170\n",
      "321/321 [==============================] - 0s 270us/sample - loss: 0.4154 - acc: 0.9252 - val_loss: 0.4762 - val_acc: 0.9012\n",
      "Epoch 75/170\n",
      "321/321 [==============================] - 0s 236us/sample - loss: 0.4127 - acc: 0.9221 - val_loss: 0.4700 - val_acc: 0.9012\n",
      "Epoch 76/170\n",
      "321/321 [==============================] - 0s 221us/sample - loss: 0.4072 - acc: 0.9252 - val_loss: 0.4649 - val_acc: 0.9012\n",
      "Epoch 77/170\n",
      "321/321 [==============================] - 0s 304us/sample - loss: 0.4019 - acc: 0.9252 - val_loss: 0.4607 - val_acc: 0.9012\n",
      "Epoch 78/170\n",
      "321/321 [==============================] - 0s 304us/sample - loss: 0.3948 - acc: 0.9283 - val_loss: 0.4593 - val_acc: 0.9012\n",
      "Epoch 79/170\n",
      "321/321 [==============================] - 0s 434us/sample - loss: 0.3855 - acc: 0.9315 - val_loss: 0.4594 - val_acc: 0.9136\n",
      "Epoch 80/170\n",
      "321/321 [==============================] - 0s 584us/sample - loss: 0.3771 - acc: 0.9159 - val_loss: 0.4588 - val_acc: 0.9136\n",
      "Epoch 81/170\n",
      "321/321 [==============================] - 0s 609us/sample - loss: 0.3710 - acc: 0.9159 - val_loss: 0.4515 - val_acc: 0.9136\n",
      "Epoch 82/170\n",
      "321/321 [==============================] - 0s 503us/sample - loss: 0.3675 - acc: 0.9283 - val_loss: 0.4424 - val_acc: 0.9012\n",
      "Epoch 83/170\n",
      "321/321 [==============================] - 0s 435us/sample - loss: 0.3656 - acc: 0.9346 - val_loss: 0.4385 - val_acc: 0.9012\n",
      "Epoch 84/170\n",
      "321/321 [==============================] - 0s 267us/sample - loss: 0.3582 - acc: 0.9346 - val_loss: 0.4477 - val_acc: 0.8642\n",
      "Epoch 85/170\n",
      "321/321 [==============================] - 0s 267us/sample - loss: 0.3503 - acc: 0.9065 - val_loss: 0.4505 - val_acc: 0.8642\n",
      "Epoch 86/170\n",
      "321/321 [==============================] - 0s 258us/sample - loss: 0.3452 - acc: 0.9097 - val_loss: 0.4510 - val_acc: 0.8272\n",
      "Epoch 87/170\n",
      "321/321 [==============================] - 0s 264us/sample - loss: 0.3407 - acc: 0.9097 - val_loss: 0.4501 - val_acc: 0.8148\n",
      "Epoch 88/170\n",
      "321/321 [==============================] - 0s 286us/sample - loss: 0.3364 - acc: 0.9097 - val_loss: 0.4376 - val_acc: 0.8642\n",
      "Epoch 89/170\n",
      "321/321 [==============================] - 0s 252us/sample - loss: 0.3310 - acc: 0.9128 - val_loss: 0.4334 - val_acc: 0.8642\n",
      "Epoch 90/170\n",
      "321/321 [==============================] - 0s 280us/sample - loss: 0.3261 - acc: 0.9128 - val_loss: 0.4284 - val_acc: 0.8642\n",
      "Epoch 91/170\n",
      "321/321 [==============================] - 0s 339us/sample - loss: 0.3221 - acc: 0.9221 - val_loss: 0.4190 - val_acc: 0.8889\n",
      "Epoch 92/170\n",
      "321/321 [==============================] - 0s 286us/sample - loss: 0.3187 - acc: 0.9283 - val_loss: 0.4104 - val_acc: 0.9012\n",
      "Epoch 93/170\n",
      "321/321 [==============================] - 0s 318us/sample - loss: 0.3147 - acc: 0.9377 - val_loss: 0.4072 - val_acc: 0.9012\n",
      "Epoch 94/170\n",
      "321/321 [==============================] - 0s 283us/sample - loss: 0.3101 - acc: 0.9377 - val_loss: 0.4073 - val_acc: 0.8889\n",
      "Epoch 95/170\n",
      "321/321 [==============================] - 0s 304us/sample - loss: 0.3048 - acc: 0.9283 - val_loss: 0.4135 - val_acc: 0.8765\n",
      "Epoch 96/170\n",
      "321/321 [==============================] - 0s 286us/sample - loss: 0.3000 - acc: 0.9190 - val_loss: 0.4124 - val_acc: 0.8642\n",
      "Epoch 97/170\n",
      "321/321 [==============================] - 0s 295us/sample - loss: 0.2961 - acc: 0.9190 - val_loss: 0.4130 - val_acc: 0.8642\n",
      "Epoch 98/170\n",
      "321/321 [==============================] - 0s 292us/sample - loss: 0.2933 - acc: 0.9128 - val_loss: 0.4212 - val_acc: 0.8395\n",
      "Epoch 99/170\n",
      "321/321 [==============================] - 0s 270us/sample - loss: 0.2898 - acc: 0.9097 - val_loss: 0.4028 - val_acc: 0.8765\n",
      "Epoch 100/170\n",
      "321/321 [==============================] - 0s 280us/sample - loss: 0.2852 - acc: 0.9346 - val_loss: 0.3928 - val_acc: 0.8889\n",
      "Epoch 101/170\n",
      "321/321 [==============================] - 0s 339us/sample - loss: 0.2818 - acc: 0.9346 - val_loss: 0.3910 - val_acc: 0.8889\n",
      "Epoch 102/170\n",
      "321/321 [==============================] - 0s 323us/sample - loss: 0.2780 - acc: 0.9377 - val_loss: 0.3931 - val_acc: 0.8889\n",
      "Epoch 103/170\n",
      "321/321 [==============================] - 0s 429us/sample - loss: 0.2741 - acc: 0.9346 - val_loss: 0.4011 - val_acc: 0.8642\n",
      "Epoch 104/170\n",
      "321/321 [==============================] - 0s 659us/sample - loss: 0.2728 - acc: 0.9159 - val_loss: 0.4168 - val_acc: 0.8272\n",
      "Epoch 105/170\n",
      "321/321 [==============================] - 0s 435us/sample - loss: 0.2723 - acc: 0.9065 - val_loss: 0.4090 - val_acc: 0.8395\n",
      "Epoch 106/170\n",
      "321/321 [==============================] - 0s 454us/sample - loss: 0.2647 - acc: 0.9159 - val_loss: 0.3843 - val_acc: 0.8889\n",
      "Epoch 107/170\n",
      "321/321 [==============================] - 0s 326us/sample - loss: 0.2614 - acc: 0.9408 - val_loss: 0.3756 - val_acc: 0.8889\n",
      "Epoch 108/170\n",
      "321/321 [==============================] - 0s 329us/sample - loss: 0.2578 - acc: 0.9346 - val_loss: 0.3858 - val_acc: 0.8642\n",
      "Epoch 109/170\n",
      "321/321 [==============================] - 0s 258us/sample - loss: 0.2558 - acc: 0.9315 - val_loss: 0.3870 - val_acc: 0.8642\n",
      "Epoch 110/170\n",
      "321/321 [==============================] - 0s 270us/sample - loss: 0.2531 - acc: 0.9283 - val_loss: 0.3861 - val_acc: 0.8642\n",
      "Epoch 111/170\n",
      "321/321 [==============================] - 0s 295us/sample - loss: 0.2508 - acc: 0.9252 - val_loss: 0.3816 - val_acc: 0.8642\n",
      "Epoch 112/170\n",
      "321/321 [==============================] - 0s 391us/sample - loss: 0.2469 - acc: 0.9346 - val_loss: 0.3662 - val_acc: 0.8889\n",
      "Epoch 113/170\n",
      "321/321 [==============================] - 0s 522us/sample - loss: 0.2438 - acc: 0.9408 - val_loss: 0.3630 - val_acc: 0.8889\n",
      "Epoch 114/170\n",
      "321/321 [==============================] - 0s 336us/sample - loss: 0.2427 - acc: 0.9470 - val_loss: 0.3541 - val_acc: 0.8889\n",
      "Epoch 115/170\n",
      "321/321 [==============================] - 0s 373us/sample - loss: 0.2396 - acc: 0.9533 - val_loss: 0.3575 - val_acc: 0.8889\n",
      "Epoch 116/170\n",
      "321/321 [==============================] - 0s 360us/sample - loss: 0.2354 - acc: 0.9439 - val_loss: 0.3593 - val_acc: 0.8889\n",
      "Epoch 117/170\n",
      "321/321 [==============================] - 0s 454us/sample - loss: 0.2330 - acc: 0.9439 - val_loss: 0.3645 - val_acc: 0.8889\n",
      "Epoch 118/170\n",
      "321/321 [==============================] - 0s 510us/sample - loss: 0.2323 - acc: 0.9346 - val_loss: 0.3788 - val_acc: 0.8642\n",
      "Epoch 119/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 0s 407us/sample - loss: 0.2307 - acc: 0.9315 - val_loss: 0.3790 - val_acc: 0.8642\n",
      "Epoch 120/170\n",
      "321/321 [==============================] - 0s 490us/sample - loss: 0.2279 - acc: 0.9377 - val_loss: 0.3704 - val_acc: 0.8642\n",
      "Epoch 121/170\n",
      "321/321 [==============================] - 0s 410us/sample - loss: 0.2235 - acc: 0.9408 - val_loss: 0.3601 - val_acc: 0.8889\n",
      "Epoch 122/170\n",
      "321/321 [==============================] - 0s 427us/sample - loss: 0.2208 - acc: 0.9439 - val_loss: 0.3528 - val_acc: 0.8889\n",
      "Epoch 123/170\n",
      "321/321 [==============================] - 0s 510us/sample - loss: 0.2186 - acc: 0.9470 - val_loss: 0.3489 - val_acc: 0.8889\n",
      "Epoch 124/170\n",
      "321/321 [==============================] - 0s 613us/sample - loss: 0.2167 - acc: 0.9502 - val_loss: 0.3466 - val_acc: 0.8889\n",
      "Epoch 125/170\n",
      "321/321 [==============================] - 0s 601us/sample - loss: 0.2147 - acc: 0.9502 - val_loss: 0.3468 - val_acc: 0.8889\n",
      "Epoch 126/170\n",
      "321/321 [==============================] - 0s 498us/sample - loss: 0.2126 - acc: 0.9470 - val_loss: 0.3498 - val_acc: 0.8889\n",
      "Epoch 127/170\n",
      "321/321 [==============================] - 0s 413us/sample - loss: 0.2105 - acc: 0.9439 - val_loss: 0.3490 - val_acc: 0.8889\n",
      "Epoch 128/170\n",
      "321/321 [==============================] - 0s 569us/sample - loss: 0.2082 - acc: 0.9502 - val_loss: 0.3425 - val_acc: 0.8889\n",
      "Epoch 129/170\n",
      "321/321 [==============================] - 0s 404us/sample - loss: 0.2064 - acc: 0.9564 - val_loss: 0.3396 - val_acc: 0.8889\n",
      "Epoch 130/170\n",
      "321/321 [==============================] - 0s 575us/sample - loss: 0.2047 - acc: 0.9595 - val_loss: 0.3379 - val_acc: 0.8889\n",
      "Epoch 131/170\n",
      "321/321 [==============================] - 0s 792us/sample - loss: 0.2029 - acc: 0.9595 - val_loss: 0.3375 - val_acc: 0.8889\n",
      "Epoch 132/170\n",
      "321/321 [==============================] - 0s 690us/sample - loss: 0.2007 - acc: 0.9595 - val_loss: 0.3371 - val_acc: 0.8889\n",
      "Epoch 133/170\n",
      "321/321 [==============================] - 0s 538us/sample - loss: 0.1992 - acc: 0.9595 - val_loss: 0.3368 - val_acc: 0.8889\n",
      "Epoch 134/170\n",
      "321/321 [==============================] - 0s 1ms/sample - loss: 0.1985 - acc: 0.9470 - val_loss: 0.3462 - val_acc: 0.8889\n",
      "Epoch 135/170\n",
      "321/321 [==============================] - 0s 447us/sample - loss: 0.1939 - acc: 0.9564 - val_loss: 0.3323 - val_acc: 0.8889\n",
      "Epoch 136/170\n",
      "321/321 [==============================] - 0s 597us/sample - loss: 0.1943 - acc: 0.9595 - val_loss: 0.3271 - val_acc: 0.8889\n",
      "Epoch 137/170\n",
      "321/321 [==============================] - 0s 407us/sample - loss: 0.1931 - acc: 0.9626 - val_loss: 0.3240 - val_acc: 0.9012\n",
      "Epoch 138/170\n",
      "321/321 [==============================] - 0s 522us/sample - loss: 0.1937 - acc: 0.9626 - val_loss: 0.3188 - val_acc: 0.9012\n",
      "Epoch 139/170\n",
      "321/321 [==============================] - 0s 525us/sample - loss: 0.1947 - acc: 0.9626 - val_loss: 0.3173 - val_acc: 0.9012\n",
      "Epoch 140/170\n",
      "321/321 [==============================] - 0s 404us/sample - loss: 0.1927 - acc: 0.9657 - val_loss: 0.3178 - val_acc: 0.9012\n",
      "Epoch 141/170\n",
      "321/321 [==============================] - 0s 454us/sample - loss: 0.1890 - acc: 0.9688 - val_loss: 0.3194 - val_acc: 0.9012\n",
      "Epoch 142/170\n",
      "321/321 [==============================] - 0s 680us/sample - loss: 0.1854 - acc: 0.9657 - val_loss: 0.3219 - val_acc: 0.8889\n",
      "Epoch 143/170\n",
      "321/321 [==============================] - 0s 643us/sample - loss: 0.1829 - acc: 0.9657 - val_loss: 0.3238 - val_acc: 0.8889\n",
      "Epoch 144/170\n",
      "321/321 [==============================] - 0s 513us/sample - loss: 0.1806 - acc: 0.9595 - val_loss: 0.3258 - val_acc: 0.8889\n",
      "Epoch 145/170\n",
      "321/321 [==============================] - 0s 626us/sample - loss: 0.1790 - acc: 0.9595 - val_loss: 0.3283 - val_acc: 0.8889\n",
      "Epoch 146/170\n",
      "321/321 [==============================] - 0s 544us/sample - loss: 0.1774 - acc: 0.9595 - val_loss: 0.3290 - val_acc: 0.8889\n",
      "Epoch 147/170\n",
      "321/321 [==============================] - 0s 603us/sample - loss: 0.1761 - acc: 0.9595 - val_loss: 0.3279 - val_acc: 0.8889\n",
      "Epoch 148/170\n",
      "321/321 [==============================] - 0s 440us/sample - loss: 0.1752 - acc: 0.9595 - val_loss: 0.3218 - val_acc: 0.8889\n",
      "Epoch 149/170\n",
      "321/321 [==============================] - 0s 391us/sample - loss: 0.1746 - acc: 0.9657 - val_loss: 0.3141 - val_acc: 0.9012\n",
      "Epoch 150/170\n",
      "321/321 [==============================] - 0s 503us/sample - loss: 0.1748 - acc: 0.9720 - val_loss: 0.3108 - val_acc: 0.9012\n",
      "Epoch 151/170\n",
      "321/321 [==============================] - 0s 367us/sample - loss: 0.1743 - acc: 0.9720 - val_loss: 0.3110 - val_acc: 0.9012\n",
      "Epoch 152/170\n",
      "321/321 [==============================] - 0s 311us/sample - loss: 0.1722 - acc: 0.9720 - val_loss: 0.3109 - val_acc: 0.9012\n",
      "Epoch 153/170\n",
      "321/321 [==============================] - 0s 314us/sample - loss: 0.1702 - acc: 0.9720 - val_loss: 0.3121 - val_acc: 0.9012\n",
      "Epoch 154/170\n",
      "321/321 [==============================] - 0s 419us/sample - loss: 0.1672 - acc: 0.9720 - val_loss: 0.3173 - val_acc: 0.8889\n",
      "Epoch 155/170\n",
      "321/321 [==============================] - 0s 367us/sample - loss: 0.1649 - acc: 0.9626 - val_loss: 0.3252 - val_acc: 0.8889\n",
      "Epoch 156/170\n",
      "321/321 [==============================] - 0s 320us/sample - loss: 0.1641 - acc: 0.9595 - val_loss: 0.3427 - val_acc: 0.8642\n",
      "Epoch 157/170\n",
      "321/321 [==============================] - 0s 435us/sample - loss: 0.1648 - acc: 0.9564 - val_loss: 0.3444 - val_acc: 0.8642\n",
      "Epoch 158/170\n",
      "321/321 [==============================] - 0s 419us/sample - loss: 0.1636 - acc: 0.9595 - val_loss: 0.3385 - val_acc: 0.8765\n",
      "Epoch 159/170\n",
      "321/321 [==============================] - 0s 351us/sample - loss: 0.1608 - acc: 0.9626 - val_loss: 0.3272 - val_acc: 0.8889\n",
      "Epoch 160/170\n",
      "321/321 [==============================] - 0s 295us/sample - loss: 0.1589 - acc: 0.9626 - val_loss: 0.3200 - val_acc: 0.8889\n",
      "Epoch 161/170\n",
      "321/321 [==============================] - 0s 255us/sample - loss: 0.1576 - acc: 0.9657 - val_loss: 0.3187 - val_acc: 0.8889\n",
      "Epoch 162/170\n",
      "321/321 [==============================] - 0s 340us/sample - loss: 0.1566 - acc: 0.9688 - val_loss: 0.3201 - val_acc: 0.8889\n",
      "Epoch 163/170\n",
      "321/321 [==============================] - 0s 301us/sample - loss: 0.1554 - acc: 0.9626 - val_loss: 0.3236 - val_acc: 0.8889\n",
      "Epoch 164/170\n",
      "321/321 [==============================] - 0s 298us/sample - loss: 0.1544 - acc: 0.9595 - val_loss: 0.3236 - val_acc: 0.8889\n",
      "Epoch 165/170\n",
      "321/321 [==============================] - 0s 270us/sample - loss: 0.1533 - acc: 0.9626 - val_loss: 0.3224 - val_acc: 0.8889\n",
      "Epoch 166/170\n",
      "321/321 [==============================] - 0s 401us/sample - loss: 0.1522 - acc: 0.9626 - val_loss: 0.3214 - val_acc: 0.8889\n",
      "Epoch 167/170\n",
      "321/321 [==============================] - 0s 401us/sample - loss: 0.1513 - acc: 0.9657 - val_loss: 0.3196 - val_acc: 0.8889\n",
      "Epoch 168/170\n",
      "321/321 [==============================] - 0s 317us/sample - loss: 0.1501 - acc: 0.9688 - val_loss: 0.3189 - val_acc: 0.8889\n",
      "Epoch 169/170\n",
      "321/321 [==============================] - 0s 283us/sample - loss: 0.1490 - acc: 0.9688 - val_loss: 0.3186 - val_acc: 0.8889\n",
      "Epoch 170/170\n",
      "321/321 [==============================] - 0s 301us/sample - loss: 0.1480 - acc: 0.9720 - val_loss: 0.3183 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44  8]\n",
      " [ 1 28]]\n",
      "None\n",
      "(0.7777777777777778, 0.8888888888888888, 0.9655172413793104, 0.8615384615384615, 0.9615384615384615, 0.9475439279132011, 0.946698030102164)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " snv_inputs (InputLayer)        [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " mRNA_inputs (InputLayer)       [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " miRNA_inputs (InputLayer)      [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " h0_snv (Biological_module)     (None, 238)          3170        ['snv_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " h0_mRNA (Biological_module)    (None, 238)          3113        ['mRNA_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " h0_miRNA (Biological_module)   (None, 238)          8124        ['miRNA_inputs[0][0]']           \n",
      "                                                                                                  \n",
      " self__attention_21 (Self_Atten  (None, 64)          45696       ['h0_snv[0][0]']                 \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_22 (Self_Atten  (None, 64)          45696       ['h0_mRNA[0][0]']                \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_23 (Self_Atten  (None, 64)          45696       ['h0_miRNA[0][0]']               \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 192)          0           ['self__attention_21[0][0]',     \n",
      "                                                                  'self__attention_22[0][0]',     \n",
      "                                                                  'self__attention_23[0][0]']     \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 32)           6176        ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1)            33          ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 157,704\n",
      "Trainable params: 157,704\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 321 samples, validate on 81 samples\n",
      "Epoch 1/170\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.8087 - acc: 0.3551"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 1s 2ms/sample - loss: 0.8087 - acc: 0.3551 - val_loss: 0.8080 - val_acc: 0.3580\n",
      "Epoch 2/170\n",
      "321/321 [==============================] - 0s 264us/sample - loss: 0.8045 - acc: 0.3551 - val_loss: 0.8049 - val_acc: 0.3580\n",
      "Epoch 3/170\n",
      "321/321 [==============================] - 0s 258us/sample - loss: 0.8008 - acc: 0.3551 - val_loss: 0.8011 - val_acc: 0.3580\n",
      "Epoch 4/170\n",
      "321/321 [==============================] - 0s 258us/sample - loss: 0.7971 - acc: 0.3551 - val_loss: 0.7970 - val_acc: 0.3580\n",
      "Epoch 5/170\n",
      "321/321 [==============================] - 0s 270us/sample - loss: 0.7935 - acc: 0.3583 - val_loss: 0.7929 - val_acc: 0.3580\n",
      "Epoch 6/170\n",
      "321/321 [==============================] - 0s 245us/sample - loss: 0.7901 - acc: 0.3645 - val_loss: 0.7889 - val_acc: 0.3827\n",
      "Epoch 7/170\n",
      "321/321 [==============================] - 0s 264us/sample - loss: 0.7868 - acc: 0.4735 - val_loss: 0.7850 - val_acc: 0.6667\n",
      "Epoch 8/170\n",
      "321/321 [==============================] - 0s 252us/sample - loss: 0.7836 - acc: 0.6791 - val_loss: 0.7812 - val_acc: 0.6420\n",
      "Epoch 9/170\n",
      "321/321 [==============================] - 0s 252us/sample - loss: 0.7805 - acc: 0.6449 - val_loss: 0.7774 - val_acc: 0.6420\n",
      "Epoch 10/170\n",
      "321/321 [==============================] - 0s 273us/sample - loss: 0.7774 - acc: 0.6449 - val_loss: 0.7738 - val_acc: 0.6420\n",
      "Epoch 11/170\n",
      "321/321 [==============================] - 0s 233us/sample - loss: 0.7744 - acc: 0.6449 - val_loss: 0.7702 - val_acc: 0.6420\n",
      "Epoch 12/170\n",
      "321/321 [==============================] - 0s 280us/sample - loss: 0.7716 - acc: 0.6449 - val_loss: 0.7665 - val_acc: 0.6420\n",
      "Epoch 13/170\n",
      "321/321 [==============================] - 0s 283us/sample - loss: 0.7689 - acc: 0.6449 - val_loss: 0.7628 - val_acc: 0.6420\n",
      "Epoch 14/170\n",
      "321/321 [==============================] - 0s 245us/sample - loss: 0.7660 - acc: 0.6449 - val_loss: 0.7590 - val_acc: 0.6420\n",
      "Epoch 15/170\n",
      "321/321 [==============================] - 0s 230us/sample - loss: 0.7635 - acc: 0.6449 - val_loss: 0.7551 - val_acc: 0.6420\n",
      "Epoch 16/170\n",
      "321/321 [==============================] - 0s 270us/sample - loss: 0.7608 - acc: 0.6449 - val_loss: 0.7511 - val_acc: 0.6420\n",
      "Epoch 17/170\n",
      "321/321 [==============================] - 0s 270us/sample - loss: 0.7581 - acc: 0.6449 - val_loss: 0.7472 - val_acc: 0.6420\n",
      "Epoch 18/170\n",
      "321/321 [==============================] - 0s 252us/sample - loss: 0.7558 - acc: 0.6449 - val_loss: 0.7429 - val_acc: 0.6420\n",
      "Epoch 19/170\n",
      "321/321 [==============================] - 0s 242us/sample - loss: 0.7531 - acc: 0.6449 - val_loss: 0.7387 - val_acc: 0.6420\n",
      "Epoch 20/170\n",
      "321/321 [==============================] - 0s 267us/sample - loss: 0.7504 - acc: 0.6449 - val_loss: 0.7353 - val_acc: 0.6420\n",
      "Epoch 21/170\n",
      "321/321 [==============================] - 0s 314us/sample - loss: 0.7474 - acc: 0.6449 - val_loss: 0.7340 - val_acc: 0.6420\n",
      "Epoch 22/170\n",
      "321/321 [==============================] - 0s 277us/sample - loss: 0.7443 - acc: 0.6449 - val_loss: 0.7313 - val_acc: 0.6420\n",
      "Epoch 23/170\n",
      "321/321 [==============================] - 0s 258us/sample - loss: 0.7413 - acc: 0.6449 - val_loss: 0.7275 - val_acc: 0.6420\n",
      "Epoch 24/170\n",
      "321/321 [==============================] - 0s 270us/sample - loss: 0.7381 - acc: 0.6449 - val_loss: 0.7235 - val_acc: 0.6420\n",
      "Epoch 25/170\n",
      "321/321 [==============================] - 0s 277us/sample - loss: 0.7350 - acc: 0.6449 - val_loss: 0.7195 - val_acc: 0.6420\n",
      "Epoch 26/170\n",
      "321/321 [==============================] - 0s 268us/sample - loss: 0.7314 - acc: 0.6480 - val_loss: 0.7176 - val_acc: 0.6420\n",
      "Epoch 27/170\n",
      "321/321 [==============================] - 0s 230us/sample - loss: 0.7279 - acc: 0.6480 - val_loss: 0.7148 - val_acc: 0.6420\n",
      "Epoch 28/170\n",
      "321/321 [==============================] - 0s 258us/sample - loss: 0.7244 - acc: 0.6511 - val_loss: 0.7132 - val_acc: 0.6420\n",
      "Epoch 29/170\n",
      "321/321 [==============================] - 0s 264us/sample - loss: 0.7205 - acc: 0.6604 - val_loss: 0.7094 - val_acc: 0.6420\n",
      "Epoch 30/170\n",
      "321/321 [==============================] - 0s 292us/sample - loss: 0.7166 - acc: 0.6667 - val_loss: 0.7048 - val_acc: 0.6420\n",
      "Epoch 31/170\n",
      "321/321 [==============================] - 0s 339us/sample - loss: 0.7125 - acc: 0.6667 - val_loss: 0.6998 - val_acc: 0.6420\n",
      "Epoch 32/170\n",
      "321/321 [==============================] - 0s 547us/sample - loss: 0.7080 - acc: 0.6822 - val_loss: 0.6960 - val_acc: 0.6543\n",
      "Epoch 33/170\n",
      "321/321 [==============================] - 0s 488us/sample - loss: 0.7030 - acc: 0.6947 - val_loss: 0.6914 - val_acc: 0.6543\n",
      "Epoch 34/170\n",
      "321/321 [==============================] - 0s 342us/sample - loss: 0.6980 - acc: 0.7414 - val_loss: 0.6899 - val_acc: 0.6667\n",
      "Epoch 35/170\n",
      "321/321 [==============================] - 0s 336us/sample - loss: 0.6929 - acc: 0.8069 - val_loss: 0.6885 - val_acc: 0.7901\n",
      "Epoch 36/170\n",
      "321/321 [==============================] - 0s 277us/sample - loss: 0.6875 - acc: 0.9034 - val_loss: 0.6847 - val_acc: 0.8272\n",
      "Epoch 37/170\n",
      "321/321 [==============================] - 0s 258us/sample - loss: 0.6815 - acc: 0.8754 - val_loss: 0.6821 - val_acc: 0.8272\n",
      "Epoch 38/170\n",
      "321/321 [==============================] - 0s 255us/sample - loss: 0.6752 - acc: 0.8598 - val_loss: 0.6778 - val_acc: 0.8395\n",
      "Epoch 39/170\n",
      "321/321 [==============================] - 0s 273us/sample - loss: 0.6687 - acc: 0.8349 - val_loss: 0.6750 - val_acc: 0.7901\n",
      "Epoch 40/170\n",
      "321/321 [==============================] - 0s 426us/sample - loss: 0.6621 - acc: 0.7913 - val_loss: 0.6701 - val_acc: 0.7778\n",
      "Epoch 41/170\n",
      "321/321 [==============================] - 0s 469us/sample - loss: 0.6548 - acc: 0.7757 - val_loss: 0.6674 - val_acc: 0.7531\n",
      "Epoch 42/170\n",
      "321/321 [==============================] - 0s 426us/sample - loss: 0.6468 - acc: 0.7664 - val_loss: 0.6602 - val_acc: 0.7531\n",
      "Epoch 43/170\n",
      "321/321 [==============================] - 0s 373us/sample - loss: 0.6386 - acc: 0.7632 - val_loss: 0.6575 - val_acc: 0.7160\n",
      "Epoch 44/170\n",
      "321/321 [==============================] - 0s 538us/sample - loss: 0.6301 - acc: 0.7040 - val_loss: 0.6553 - val_acc: 0.6914\n",
      "Epoch 45/170\n",
      "321/321 [==============================] - 0s 423us/sample - loss: 0.6222 - acc: 0.6854 - val_loss: 0.6455 - val_acc: 0.7037\n",
      "Epoch 46/170\n",
      "321/321 [==============================] - 0s 357us/sample - loss: 0.6125 - acc: 0.7477 - val_loss: 0.6302 - val_acc: 0.7531\n",
      "Epoch 47/170\n",
      "321/321 [==============================] - 0s 401us/sample - loss: 0.6021 - acc: 0.7913 - val_loss: 0.6150 - val_acc: 0.8272\n",
      "Epoch 48/170\n",
      "321/321 [==============================] - 0s 550us/sample - loss: 0.5935 - acc: 0.8754 - val_loss: 0.6021 - val_acc: 0.8642\n",
      "Epoch 49/170\n",
      "321/321 [==============================] - 0s 628us/sample - loss: 0.5841 - acc: 0.8816 - val_loss: 0.5976 - val_acc: 0.8519\n",
      "Epoch 50/170\n",
      "321/321 [==============================] - 0s 624us/sample - loss: 0.5743 - acc: 0.8349 - val_loss: 0.5965 - val_acc: 0.8025\n",
      "Epoch 51/170\n",
      "321/321 [==============================] - 0s 457us/sample - loss: 0.5641 - acc: 0.8100 - val_loss: 0.5896 - val_acc: 0.8025\n",
      "Epoch 52/170\n",
      "321/321 [==============================] - 0s 569us/sample - loss: 0.5539 - acc: 0.8131 - val_loss: 0.5778 - val_acc: 0.7901\n",
      "Epoch 53/170\n",
      "321/321 [==============================] - 0s 463us/sample - loss: 0.5440 - acc: 0.8442 - val_loss: 0.5647 - val_acc: 0.8519\n",
      "Epoch 54/170\n",
      "321/321 [==============================] - 0s 336us/sample - loss: 0.5368 - acc: 0.8847 - val_loss: 0.5526 - val_acc: 0.9012\n",
      "Epoch 55/170\n",
      "321/321 [==============================] - 0s 360us/sample - loss: 0.5272 - acc: 0.9003 - val_loss: 0.5467 - val_acc: 0.8765\n",
      "Epoch 56/170\n",
      "321/321 [==============================] - 0s 581us/sample - loss: 0.5154 - acc: 0.8816 - val_loss: 0.5465 - val_acc: 0.8272\n",
      "Epoch 57/170\n",
      "321/321 [==============================] - 0s 410us/sample - loss: 0.5074 - acc: 0.8318 - val_loss: 0.5501 - val_acc: 0.7778\n",
      "Epoch 58/170\n",
      "321/321 [==============================] - 0s 475us/sample - loss: 0.4992 - acc: 0.8131 - val_loss: 0.5436 - val_acc: 0.7778\n",
      "Epoch 59/170\n",
      "321/321 [==============================] - 0s 252us/sample - loss: 0.4910 - acc: 0.8100 - val_loss: 0.5396 - val_acc: 0.7654\n",
      "Epoch 60/170\n",
      "321/321 [==============================] - 0s 342us/sample - loss: 0.4830 - acc: 0.7913 - val_loss: 0.5364 - val_acc: 0.7531\n",
      "Epoch 61/170\n",
      "321/321 [==============================] - 0s 531us/sample - loss: 0.4734 - acc: 0.7975 - val_loss: 0.5221 - val_acc: 0.7901\n",
      "Epoch 62/170\n",
      "321/321 [==============================] - 0s 438us/sample - loss: 0.4631 - acc: 0.8505 - val_loss: 0.5053 - val_acc: 0.8519\n",
      "Epoch 63/170\n",
      "321/321 [==============================] - 0s 357us/sample - loss: 0.4530 - acc: 0.8847 - val_loss: 0.4928 - val_acc: 0.8889\n",
      "Epoch 64/170\n",
      "321/321 [==============================] - 0s 441us/sample - loss: 0.4468 - acc: 0.9065 - val_loss: 0.4834 - val_acc: 0.8889\n",
      "Epoch 65/170\n",
      "321/321 [==============================] - 0s 435us/sample - loss: 0.4408 - acc: 0.9190 - val_loss: 0.4762 - val_acc: 0.8889\n",
      "Epoch 66/170\n",
      "321/321 [==============================] - 0s 370us/sample - loss: 0.4352 - acc: 0.9252 - val_loss: 0.4700 - val_acc: 0.8765\n",
      "Epoch 67/170\n",
      "321/321 [==============================] - 0s 413us/sample - loss: 0.4287 - acc: 0.9252 - val_loss: 0.4647 - val_acc: 0.8889\n",
      "Epoch 68/170\n",
      "321/321 [==============================] - 0s 351us/sample - loss: 0.4208 - acc: 0.9283 - val_loss: 0.4596 - val_acc: 0.8889\n",
      "Epoch 69/170\n",
      "321/321 [==============================] - 0s 444us/sample - loss: 0.4107 - acc: 0.9252 - val_loss: 0.4574 - val_acc: 0.8889\n",
      "Epoch 70/170\n",
      "321/321 [==============================] - 0s 374us/sample - loss: 0.4009 - acc: 0.9097 - val_loss: 0.4566 - val_acc: 0.8765\n",
      "Epoch 71/170\n",
      "321/321 [==============================] - 0s 264us/sample - loss: 0.3930 - acc: 0.8910 - val_loss: 0.4584 - val_acc: 0.8642\n",
      "Epoch 72/170\n",
      "321/321 [==============================] - 0s 289us/sample - loss: 0.3876 - acc: 0.8660 - val_loss: 0.4623 - val_acc: 0.8148\n",
      "Epoch 73/170\n",
      "321/321 [==============================] - 0s 295us/sample - loss: 0.3843 - acc: 0.8474 - val_loss: 0.4618 - val_acc: 0.8025\n",
      "Epoch 74/170\n",
      "321/321 [==============================] - 0s 308us/sample - loss: 0.3779 - acc: 0.8442 - val_loss: 0.4522 - val_acc: 0.8148\n",
      "Epoch 75/170\n",
      "321/321 [==============================] - 0s 317us/sample - loss: 0.3713 - acc: 0.8567 - val_loss: 0.4462 - val_acc: 0.8025\n",
      "Epoch 76/170\n",
      "321/321 [==============================] - 0s 329us/sample - loss: 0.3613 - acc: 0.8816 - val_loss: 0.4291 - val_acc: 0.8889\n",
      "Epoch 77/170\n",
      "321/321 [==============================] - 0s 304us/sample - loss: 0.3531 - acc: 0.9034 - val_loss: 0.4177 - val_acc: 0.8889\n",
      "Epoch 78/170\n",
      "321/321 [==============================] - 0s 277us/sample - loss: 0.3505 - acc: 0.9283 - val_loss: 0.4110 - val_acc: 0.9012\n",
      "Epoch 79/170\n",
      "321/321 [==============================] - 0s 357us/sample - loss: 0.3447 - acc: 0.9408 - val_loss: 0.4083 - val_acc: 0.9012\n",
      "Epoch 80/170\n",
      "321/321 [==============================] - 0s 298us/sample - loss: 0.3376 - acc: 0.9346 - val_loss: 0.4053 - val_acc: 0.8889\n",
      "Epoch 81/170\n",
      "321/321 [==============================] - 0s 342us/sample - loss: 0.3319 - acc: 0.9190 - val_loss: 0.4033 - val_acc: 0.9012\n",
      "Epoch 82/170\n",
      "321/321 [==============================] - 0s 236us/sample - loss: 0.3274 - acc: 0.9034 - val_loss: 0.4059 - val_acc: 0.9012\n",
      "Epoch 83/170\n",
      "321/321 [==============================] - 0s 311us/sample - loss: 0.3226 - acc: 0.8972 - val_loss: 0.4039 - val_acc: 0.8889\n",
      "Epoch 84/170\n",
      "321/321 [==============================] - 0s 280us/sample - loss: 0.3184 - acc: 0.8972 - val_loss: 0.3971 - val_acc: 0.9136\n",
      "Epoch 85/170\n",
      "321/321 [==============================] - 0s 283us/sample - loss: 0.3132 - acc: 0.9097 - val_loss: 0.3848 - val_acc: 0.9012\n",
      "Epoch 86/170\n",
      "321/321 [==============================] - 0s 273us/sample - loss: 0.3095 - acc: 0.9470 - val_loss: 0.3795 - val_acc: 0.9012\n",
      "Epoch 87/170\n",
      "321/321 [==============================] - 0s 342us/sample - loss: 0.3034 - acc: 0.9439 - val_loss: 0.3784 - val_acc: 0.9012\n",
      "Epoch 88/170\n",
      "321/321 [==============================] - 0s 482us/sample - loss: 0.2983 - acc: 0.9283 - val_loss: 0.3793 - val_acc: 0.9136\n",
      "Epoch 89/170\n",
      "321/321 [==============================] - 0s 333us/sample - loss: 0.2945 - acc: 0.9065 - val_loss: 0.3837 - val_acc: 0.9012\n",
      "Epoch 90/170\n",
      "321/321 [==============================] - 0s 336us/sample - loss: 0.2923 - acc: 0.9003 - val_loss: 0.3760 - val_acc: 0.9136\n",
      "Epoch 91/170\n",
      "321/321 [==============================] - 0s 441us/sample - loss: 0.2867 - acc: 0.9128 - val_loss: 0.3656 - val_acc: 0.9136\n",
      "Epoch 92/170\n",
      "321/321 [==============================] - 0s 559us/sample - loss: 0.2820 - acc: 0.9377 - val_loss: 0.3599 - val_acc: 0.9012\n",
      "Epoch 93/170\n",
      "321/321 [==============================] - 0s 314us/sample - loss: 0.2809 - acc: 0.9439 - val_loss: 0.3571 - val_acc: 0.9012\n",
      "Epoch 94/170\n",
      "321/321 [==============================] - 0s 301us/sample - loss: 0.2775 - acc: 0.9470 - val_loss: 0.3542 - val_acc: 0.9012\n",
      "Epoch 95/170\n",
      "321/321 [==============================] - 0s 230us/sample - loss: 0.2727 - acc: 0.9439 - val_loss: 0.3513 - val_acc: 0.9012\n",
      "Epoch 96/170\n",
      "321/321 [==============================] - 0s 230us/sample - loss: 0.2683 - acc: 0.9439 - val_loss: 0.3484 - val_acc: 0.9012\n",
      "Epoch 97/170\n",
      "321/321 [==============================] - 0s 230us/sample - loss: 0.2639 - acc: 0.9439 - val_loss: 0.3454 - val_acc: 0.9012\n",
      "Epoch 98/170\n",
      "321/321 [==============================] - 0s 408us/sample - loss: 0.2604 - acc: 0.9439 - val_loss: 0.3423 - val_acc: 0.9012\n",
      "Epoch 99/170\n",
      "321/321 [==============================] - 0s 311us/sample - loss: 0.2568 - acc: 0.9439 - val_loss: 0.3398 - val_acc: 0.9136\n",
      "Epoch 100/170\n",
      "321/321 [==============================] - 0s 569us/sample - loss: 0.2522 - acc: 0.9470 - val_loss: 0.3380 - val_acc: 0.9136\n",
      "Epoch 101/170\n",
      "321/321 [==============================] - 0s 488us/sample - loss: 0.2484 - acc: 0.9408 - val_loss: 0.3359 - val_acc: 0.9136\n",
      "Epoch 102/170\n",
      "321/321 [==============================] - 0s 463us/sample - loss: 0.2452 - acc: 0.9439 - val_loss: 0.3347 - val_acc: 0.9259\n",
      "Epoch 103/170\n",
      "321/321 [==============================] - 0s 308us/sample - loss: 0.2427 - acc: 0.9408 - val_loss: 0.3353 - val_acc: 0.9259\n",
      "Epoch 104/170\n",
      "321/321 [==============================] - 0s 277us/sample - loss: 0.2387 - acc: 0.9439 - val_loss: 0.3303 - val_acc: 0.9259\n",
      "Epoch 105/170\n",
      "321/321 [==============================] - 0s 270us/sample - loss: 0.2352 - acc: 0.9470 - val_loss: 0.3270 - val_acc: 0.9136\n",
      "Epoch 106/170\n",
      "321/321 [==============================] - 0s 249us/sample - loss: 0.2318 - acc: 0.9439 - val_loss: 0.3255 - val_acc: 0.9259\n",
      "Epoch 107/170\n",
      "321/321 [==============================] - 0s 217us/sample - loss: 0.2290 - acc: 0.9439 - val_loss: 0.3222 - val_acc: 0.9136\n",
      "Epoch 108/170\n",
      "321/321 [==============================] - 0s 261us/sample - loss: 0.2260 - acc: 0.9502 - val_loss: 0.3194 - val_acc: 0.9136\n",
      "Epoch 109/170\n",
      "321/321 [==============================] - 0s 267us/sample - loss: 0.2237 - acc: 0.9470 - val_loss: 0.3172 - val_acc: 0.9136\n",
      "Epoch 110/170\n",
      "321/321 [==============================] - 0s 264us/sample - loss: 0.2213 - acc: 0.9470 - val_loss: 0.3160 - val_acc: 0.9259\n",
      "Epoch 111/170\n",
      "321/321 [==============================] - 0s 345us/sample - loss: 0.2176 - acc: 0.9439 - val_loss: 0.3240 - val_acc: 0.9259\n",
      "Epoch 112/170\n",
      "321/321 [==============================] - 0s 354us/sample - loss: 0.2203 - acc: 0.9252 - val_loss: 0.3250 - val_acc: 0.9136\n",
      "Epoch 113/170\n",
      "321/321 [==============================] - 0s 388us/sample - loss: 0.2153 - acc: 0.9315 - val_loss: 0.3146 - val_acc: 0.9259\n",
      "Epoch 114/170\n",
      "321/321 [==============================] - 0s 252us/sample - loss: 0.2099 - acc: 0.9502 - val_loss: 0.3102 - val_acc: 0.9136\n",
      "Epoch 115/170\n",
      "321/321 [==============================] - 0s 255us/sample - loss: 0.2077 - acc: 0.9502 - val_loss: 0.3094 - val_acc: 0.9136\n",
      "Epoch 116/170\n",
      "321/321 [==============================] - 0s 224us/sample - loss: 0.2055 - acc: 0.9502 - val_loss: 0.3083 - val_acc: 0.9136\n",
      "Epoch 117/170\n",
      "321/321 [==============================] - 0s 205us/sample - loss: 0.2032 - acc: 0.9502 - val_loss: 0.3081 - val_acc: 0.9259\n",
      "Epoch 118/170\n",
      "321/321 [==============================] - 0s 283us/sample - loss: 0.2042 - acc: 0.9377 - val_loss: 0.3211 - val_acc: 0.9136\n",
      "Epoch 119/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 0s 323us/sample - loss: 0.2083 - acc: 0.9221 - val_loss: 0.3234 - val_acc: 0.9012\n",
      "Epoch 120/170\n",
      "321/321 [==============================] - 0s 270us/sample - loss: 0.2053 - acc: 0.9221 - val_loss: 0.3157 - val_acc: 0.9136\n",
      "Epoch 121/170\n",
      "321/321 [==============================] - 0s 283us/sample - loss: 0.1990 - acc: 0.9377 - val_loss: 0.3091 - val_acc: 0.9259\n",
      "Epoch 122/170\n",
      "321/321 [==============================] - 0s 430us/sample - loss: 0.1967 - acc: 0.9439 - val_loss: 0.3105 - val_acc: 0.9259\n",
      "Epoch 123/170\n",
      "321/321 [==============================] - 0s 381us/sample - loss: 0.1941 - acc: 0.9470 - val_loss: 0.3074 - val_acc: 0.9259\n",
      "Epoch 124/170\n",
      "321/321 [==============================] - 0s 277us/sample - loss: 0.1913 - acc: 0.9533 - val_loss: 0.3022 - val_acc: 0.9259\n",
      "Epoch 125/170\n",
      "321/321 [==============================] - 0s 264us/sample - loss: 0.1875 - acc: 0.9626 - val_loss: 0.2994 - val_acc: 0.9136\n",
      "Epoch 126/170\n",
      "321/321 [==============================] - 0s 301us/sample - loss: 0.1894 - acc: 0.9626 - val_loss: 0.3007 - val_acc: 0.9012\n",
      "Epoch 127/170\n",
      "321/321 [==============================] - 0s 475us/sample - loss: 0.1891 - acc: 0.9657 - val_loss: 0.2987 - val_acc: 0.9136\n",
      "Epoch 128/170\n",
      "321/321 [==============================] - 0s 211us/sample - loss: 0.1862 - acc: 0.9688 - val_loss: 0.2950 - val_acc: 0.9012\n",
      "Epoch 129/170\n",
      "321/321 [==============================] - 0s 217us/sample - loss: 0.1811 - acc: 0.9595 - val_loss: 0.2994 - val_acc: 0.9259\n",
      "Epoch 130/170\n",
      "321/321 [==============================] - 0s 221us/sample - loss: 0.1829 - acc: 0.9564 - val_loss: 0.3044 - val_acc: 0.9259\n",
      "Epoch 131/170\n",
      "321/321 [==============================] - 0s 379us/sample - loss: 0.1821 - acc: 0.9533 - val_loss: 0.2966 - val_acc: 0.9259\n",
      "Epoch 132/170\n",
      "321/321 [==============================] - 0s 326us/sample - loss: 0.1777 - acc: 0.9595 - val_loss: 0.2909 - val_acc: 0.9012\n",
      "Epoch 133/170\n",
      "321/321 [==============================] - 0s 199us/sample - loss: 0.1757 - acc: 0.9595 - val_loss: 0.2916 - val_acc: 0.9012\n",
      "Epoch 134/170\n",
      "321/321 [==============================] - 0s 205us/sample - loss: 0.1763 - acc: 0.9626 - val_loss: 0.2915 - val_acc: 0.9136\n",
      "Epoch 135/170\n",
      "321/321 [==============================] - 0s 249us/sample - loss: 0.1742 - acc: 0.9657 - val_loss: 0.2898 - val_acc: 0.9012\n",
      "Epoch 136/170\n",
      "321/321 [==============================] - 0s 382us/sample - loss: 0.1713 - acc: 0.9595 - val_loss: 0.2888 - val_acc: 0.9012\n",
      "Epoch 137/170\n",
      "321/321 [==============================] - 0s 326us/sample - loss: 0.1693 - acc: 0.9657 - val_loss: 0.2888 - val_acc: 0.9136\n",
      "Epoch 138/170\n",
      "321/321 [==============================] - 0s 214us/sample - loss: 0.1675 - acc: 0.9657 - val_loss: 0.2884 - val_acc: 0.9259\n",
      "Epoch 139/170\n",
      "321/321 [==============================] - 0s 239us/sample - loss: 0.1660 - acc: 0.9688 - val_loss: 0.2871 - val_acc: 0.9136\n",
      "Epoch 140/170\n",
      "321/321 [==============================] - 0s 214us/sample - loss: 0.1647 - acc: 0.9657 - val_loss: 0.2864 - val_acc: 0.9012\n",
      "Epoch 141/170\n",
      "321/321 [==============================] - 0s 230us/sample - loss: 0.1635 - acc: 0.9657 - val_loss: 0.2859 - val_acc: 0.9136\n",
      "Epoch 142/170\n",
      "321/321 [==============================] - 0s 261us/sample - loss: 0.1622 - acc: 0.9657 - val_loss: 0.2856 - val_acc: 0.9136\n",
      "Epoch 143/170\n",
      "321/321 [==============================] - 0s 329us/sample - loss: 0.1603 - acc: 0.9688 - val_loss: 0.2870 - val_acc: 0.9259\n",
      "Epoch 144/170\n",
      "321/321 [==============================] - 0s 289us/sample - loss: 0.1602 - acc: 0.9688 - val_loss: 0.2844 - val_acc: 0.9259\n",
      "Epoch 145/170\n",
      "321/321 [==============================] - 0s 395us/sample - loss: 0.1580 - acc: 0.9688 - val_loss: 0.2834 - val_acc: 0.9136\n",
      "Epoch 146/170\n",
      "321/321 [==============================] - 0s 376us/sample - loss: 0.1568 - acc: 0.9688 - val_loss: 0.2824 - val_acc: 0.9012\n",
      "Epoch 147/170\n",
      "321/321 [==============================] - 0s 345us/sample - loss: 0.1559 - acc: 0.9657 - val_loss: 0.2814 - val_acc: 0.9012\n",
      "Epoch 148/170\n",
      "321/321 [==============================] - 0s 242us/sample - loss: 0.1541 - acc: 0.9688 - val_loss: 0.2812 - val_acc: 0.9259\n",
      "Epoch 149/170\n",
      "321/321 [==============================] - 0s 267us/sample - loss: 0.1528 - acc: 0.9688 - val_loss: 0.2817 - val_acc: 0.9259\n",
      "Epoch 150/170\n",
      "321/321 [==============================] - 0s 398us/sample - loss: 0.1520 - acc: 0.9688 - val_loss: 0.2816 - val_acc: 0.9259\n",
      "Epoch 151/170\n",
      "321/321 [==============================] - 0s 376us/sample - loss: 0.1509 - acc: 0.9688 - val_loss: 0.2814 - val_acc: 0.9259\n",
      "Epoch 152/170\n",
      "321/321 [==============================] - 0s 286us/sample - loss: 0.1504 - acc: 0.9657 - val_loss: 0.2834 - val_acc: 0.9259\n",
      "Epoch 153/170\n",
      "321/321 [==============================] - 0s 224us/sample - loss: 0.1500 - acc: 0.9626 - val_loss: 0.2837 - val_acc: 0.9259\n",
      "Epoch 154/170\n",
      "321/321 [==============================] - 0s 224us/sample - loss: 0.1496 - acc: 0.9626 - val_loss: 0.2833 - val_acc: 0.9259\n",
      "Epoch 155/170\n",
      "321/321 [==============================] - 0s 273us/sample - loss: 0.1468 - acc: 0.9688 - val_loss: 0.2778 - val_acc: 0.9136\n",
      "Epoch 156/170\n",
      "321/321 [==============================] - 0s 273us/sample - loss: 0.1460 - acc: 0.9688 - val_loss: 0.2790 - val_acc: 0.9012\n",
      "Epoch 157/170\n",
      "321/321 [==============================] - 0s 470us/sample - loss: 0.1509 - acc: 0.9751 - val_loss: 0.2873 - val_acc: 0.9012\n",
      "Epoch 158/170\n",
      "321/321 [==============================] - 0s 413us/sample - loss: 0.1533 - acc: 0.9782 - val_loss: 0.2857 - val_acc: 0.9012\n",
      "Epoch 159/170\n",
      "321/321 [==============================] - 0s 270us/sample - loss: 0.1501 - acc: 0.9782 - val_loss: 0.2802 - val_acc: 0.9136\n",
      "Epoch 160/170\n",
      "321/321 [==============================] - 0s 401us/sample - loss: 0.1450 - acc: 0.9751 - val_loss: 0.2764 - val_acc: 0.9012\n",
      "Epoch 161/170\n",
      "321/321 [==============================] - 0s 447us/sample - loss: 0.1411 - acc: 0.9782 - val_loss: 0.2754 - val_acc: 0.9136\n",
      "Epoch 162/170\n",
      "321/321 [==============================] - 0s 258us/sample - loss: 0.1404 - acc: 0.9688 - val_loss: 0.2797 - val_acc: 0.9259\n",
      "Epoch 163/170\n",
      "321/321 [==============================] - 0s 208us/sample - loss: 0.1404 - acc: 0.9657 - val_loss: 0.2803 - val_acc: 0.9259\n",
      "Epoch 164/170\n",
      "321/321 [==============================] - 0s 205us/sample - loss: 0.1392 - acc: 0.9657 - val_loss: 0.2773 - val_acc: 0.9259\n",
      "Epoch 165/170\n",
      "321/321 [==============================] - 0s 295us/sample - loss: 0.1370 - acc: 0.9688 - val_loss: 0.2755 - val_acc: 0.9259\n",
      "Epoch 166/170\n",
      "321/321 [==============================] - 0s 351us/sample - loss: 0.1362 - acc: 0.9688 - val_loss: 0.2751 - val_acc: 0.9259\n",
      "Epoch 167/170\n",
      "321/321 [==============================] - 0s 289us/sample - loss: 0.1366 - acc: 0.9688 - val_loss: 0.2866 - val_acc: 0.9259\n",
      "Epoch 168/170\n",
      "321/321 [==============================] - 0s 214us/sample - loss: 0.1404 - acc: 0.9564 - val_loss: 0.2961 - val_acc: 0.9259\n",
      "Epoch 169/170\n",
      "321/321 [==============================] - 0s 239us/sample - loss: 0.1466 - acc: 0.9502 - val_loss: 0.3095 - val_acc: 0.8765\n",
      "Epoch 170/170\n",
      "321/321 [==============================] - 0s 208us/sample - loss: 0.1485 - acc: 0.9470 - val_loss: 0.2994 - val_acc: 0.9136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47  5]\n",
      " [ 2 27]]\n",
      "None\n",
      "(0.84375, 0.9135802469135802, 0.9310344827586207, 0.8852459016393444, 0.9628647214854111, 0.9518986551362311, 0.9512134372919782)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " snv_inputs (InputLayer)        [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " mRNA_inputs (InputLayer)       [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " miRNA_inputs (InputLayer)      [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " h0_snv (Biological_module)     (None, 238)          3170        ['snv_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " h0_mRNA (Biological_module)    (None, 238)          3113        ['mRNA_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " h0_miRNA (Biological_module)   (None, 238)          8124        ['miRNA_inputs[0][0]']           \n",
      "                                                                                                  \n",
      " self__attention_24 (Self_Atten  (None, 64)          45696       ['h0_snv[0][0]']                 \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_25 (Self_Atten  (None, 64)          45696       ['h0_mRNA[0][0]']                \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_26 (Self_Atten  (None, 64)          45696       ['h0_miRNA[0][0]']               \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 192)          0           ['self__attention_24[0][0]',     \n",
      "                                                                  'self__attention_25[0][0]',     \n",
      "                                                                  'self__attention_26[0][0]']     \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 32)           6176        ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1)            33          ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 157,704\n",
      "Trainable params: 157,704\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 322 samples, validate on 80 samples\n",
      "Epoch 1/170\n",
      "256/322 [======================>.......] - ETA: 0s - loss: 0.8183 - acc: 0.3867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 1s 2ms/sample - loss: 0.8102 - acc: 0.3665 - val_loss: 0.8071 - val_acc: 0.3500\n",
      "Epoch 2/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.8061 - acc: 0.3571 - val_loss: 0.8034 - val_acc: 0.3500\n",
      "Epoch 3/170\n",
      "322/322 [==============================] - 0s 468us/sample - loss: 0.8020 - acc: 0.3571 - val_loss: 0.7997 - val_acc: 0.3500\n",
      "Epoch 4/170\n",
      "322/322 [==============================] - 0s 427us/sample - loss: 0.7982 - acc: 0.3571 - val_loss: 0.7956 - val_acc: 0.3500\n",
      "Epoch 5/170\n",
      "322/322 [==============================] - 0s 195us/sample - loss: 0.7944 - acc: 0.3571 - val_loss: 0.7916 - val_acc: 0.3500\n",
      "Epoch 6/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.7907 - acc: 0.3696 - val_loss: 0.7881 - val_acc: 0.3500\n",
      "Epoch 7/170\n",
      "322/322 [==============================] - 0s 300us/sample - loss: 0.7872 - acc: 0.3665 - val_loss: 0.7850 - val_acc: 0.3500\n",
      "Epoch 8/170\n",
      "322/322 [==============================] - 0s 331us/sample - loss: 0.7837 - acc: 0.3571 - val_loss: 0.7820 - val_acc: 0.3500\n",
      "Epoch 9/170\n",
      "322/322 [==============================] - 0s 220us/sample - loss: 0.7804 - acc: 0.3571 - val_loss: 0.7785 - val_acc: 0.3750\n",
      "Epoch 10/170\n",
      "322/322 [==============================] - 0s 195us/sample - loss: 0.7771 - acc: 0.4161 - val_loss: 0.7750 - val_acc: 0.5500\n",
      "Epoch 11/170\n",
      "322/322 [==============================] - 0s 192us/sample - loss: 0.7740 - acc: 0.5311 - val_loss: 0.7720 - val_acc: 0.5750\n",
      "Epoch 12/170\n",
      "322/322 [==============================] - 0s 214us/sample - loss: 0.7710 - acc: 0.5031 - val_loss: 0.7694 - val_acc: 0.4375\n",
      "Epoch 13/170\n",
      "322/322 [==============================] - 0s 390us/sample - loss: 0.7679 - acc: 0.4317 - val_loss: 0.7670 - val_acc: 0.4125\n",
      "Epoch 14/170\n",
      "322/322 [==============================] - 0s 313us/sample - loss: 0.7650 - acc: 0.4503 - val_loss: 0.7640 - val_acc: 0.4750\n",
      "Epoch 15/170\n",
      "322/322 [==============================] - 0s 201us/sample - loss: 0.7621 - acc: 0.4565 - val_loss: 0.7616 - val_acc: 0.4500\n",
      "Epoch 16/170\n",
      "322/322 [==============================] - 0s 198us/sample - loss: 0.7591 - acc: 0.4938 - val_loss: 0.7581 - val_acc: 0.6625\n",
      "Epoch 17/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.7562 - acc: 0.6770 - val_loss: 0.7542 - val_acc: 0.6500\n",
      "Epoch 18/170\n",
      "322/322 [==============================] - 0s 204us/sample - loss: 0.7534 - acc: 0.7453 - val_loss: 0.7511 - val_acc: 0.6500\n",
      "Epoch 19/170\n",
      "322/322 [==============================] - 0s 331us/sample - loss: 0.7503 - acc: 0.7733 - val_loss: 0.7472 - val_acc: 0.6750\n",
      "Epoch 20/170\n",
      "322/322 [==============================] - 0s 412us/sample - loss: 0.7472 - acc: 0.7733 - val_loss: 0.7438 - val_acc: 0.6500\n",
      "Epoch 21/170\n",
      "322/322 [==============================] - 0s 235us/sample - loss: 0.7439 - acc: 0.7671 - val_loss: 0.7392 - val_acc: 0.6375\n",
      "Epoch 22/170\n",
      "322/322 [==============================] - 0s 192us/sample - loss: 0.7403 - acc: 0.7640 - val_loss: 0.7360 - val_acc: 0.6625\n",
      "Epoch 23/170\n",
      "322/322 [==============================] - 0s 204us/sample - loss: 0.7364 - acc: 0.7702 - val_loss: 0.7320 - val_acc: 0.6750\n",
      "Epoch 24/170\n",
      "322/322 [==============================] - 0s 300us/sample - loss: 0.7325 - acc: 0.7764 - val_loss: 0.7294 - val_acc: 0.7000\n",
      "Epoch 25/170\n",
      "322/322 [==============================] - 0s 192us/sample - loss: 0.7284 - acc: 0.7516 - val_loss: 0.7315 - val_acc: 0.7000\n",
      "Epoch 26/170\n",
      "322/322 [==============================] - 0s 208us/sample - loss: 0.7241 - acc: 0.6335 - val_loss: 0.7322 - val_acc: 0.6125\n",
      "Epoch 27/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.7199 - acc: 0.5994 - val_loss: 0.7276 - val_acc: 0.6500\n",
      "Epoch 28/170\n",
      "322/322 [==============================] - 0s 291us/sample - loss: 0.7152 - acc: 0.6118 - val_loss: 0.7244 - val_acc: 0.6375\n",
      "Epoch 29/170\n",
      "322/322 [==============================] - 0s 347us/sample - loss: 0.7104 - acc: 0.5963 - val_loss: 0.7234 - val_acc: 0.6250\n",
      "Epoch 30/170\n",
      "322/322 [==============================] - 0s 291us/sample - loss: 0.7050 - acc: 0.5714 - val_loss: 0.7203 - val_acc: 0.6250\n",
      "Epoch 31/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.6991 - acc: 0.6180 - val_loss: 0.7096 - val_acc: 0.7125\n",
      "Epoch 32/170\n",
      "322/322 [==============================] - 0s 269us/sample - loss: 0.6926 - acc: 0.6708 - val_loss: 0.7022 - val_acc: 0.7250\n",
      "Epoch 33/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.6853 - acc: 0.7547 - val_loss: 0.6884 - val_acc: 0.7750\n",
      "Epoch 34/170\n",
      "322/322 [==============================] - 0s 189us/sample - loss: 0.6794 - acc: 0.8043 - val_loss: 0.6762 - val_acc: 0.7500\n",
      "Epoch 35/170\n",
      "322/322 [==============================] - 0s 214us/sample - loss: 0.6717 - acc: 0.8043 - val_loss: 0.6741 - val_acc: 0.7875\n",
      "Epoch 36/170\n",
      "322/322 [==============================] - 0s 393us/sample - loss: 0.6635 - acc: 0.8168 - val_loss: 0.6647 - val_acc: 0.7625\n",
      "Epoch 37/170\n",
      "322/322 [==============================] - 0s 517us/sample - loss: 0.6563 - acc: 0.8137 - val_loss: 0.6530 - val_acc: 0.7500\n",
      "Epoch 38/170\n",
      "322/322 [==============================] - 0s 292us/sample - loss: 0.6477 - acc: 0.8230 - val_loss: 0.6458 - val_acc: 0.7375\n",
      "Epoch 39/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.6389 - acc: 0.8261 - val_loss: 0.6354 - val_acc: 0.7375\n",
      "Epoch 40/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.6301 - acc: 0.8354 - val_loss: 0.6247 - val_acc: 0.7625\n",
      "Epoch 41/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.6222 - acc: 0.8354 - val_loss: 0.6136 - val_acc: 0.7750\n",
      "Epoch 42/170\n",
      "322/322 [==============================] - 0s 242us/sample - loss: 0.6146 - acc: 0.8416 - val_loss: 0.6046 - val_acc: 0.7750\n",
      "Epoch 43/170\n",
      "322/322 [==============================] - 0s 325us/sample - loss: 0.6048 - acc: 0.8385 - val_loss: 0.6046 - val_acc: 0.7625\n",
      "Epoch 44/170\n",
      "322/322 [==============================] - 0s 350us/sample - loss: 0.5894 - acc: 0.8478 - val_loss: 0.6118 - val_acc: 0.7750\n",
      "Epoch 45/170\n",
      "322/322 [==============================] - 0s 319us/sample - loss: 0.5789 - acc: 0.7609 - val_loss: 0.6288 - val_acc: 0.7125\n",
      "Epoch 46/170\n",
      "322/322 [==============================] - 0s 288us/sample - loss: 0.5771 - acc: 0.6801 - val_loss: 0.6297 - val_acc: 0.7000\n",
      "Epoch 47/170\n",
      "322/322 [==============================] - 0s 344us/sample - loss: 0.5699 - acc: 0.6832 - val_loss: 0.6148 - val_acc: 0.7250\n",
      "Epoch 48/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.5561 - acc: 0.7453 - val_loss: 0.5900 - val_acc: 0.7625\n",
      "Epoch 49/170\n",
      "322/322 [==============================] - 0s 248us/sample - loss: 0.5428 - acc: 0.8012 - val_loss: 0.5755 - val_acc: 0.7750\n",
      "Epoch 50/170\n",
      "322/322 [==============================] - 0s 288us/sample - loss: 0.5329 - acc: 0.8447 - val_loss: 0.5648 - val_acc: 0.7750\n",
      "Epoch 51/170\n",
      "322/322 [==============================] - 0s 285us/sample - loss: 0.5237 - acc: 0.8509 - val_loss: 0.5542 - val_acc: 0.7750\n",
      "Epoch 52/170\n",
      "322/322 [==============================] - 0s 269us/sample - loss: 0.5142 - acc: 0.8758 - val_loss: 0.5428 - val_acc: 0.7875\n",
      "Epoch 53/170\n",
      "322/322 [==============================] - 0s 269us/sample - loss: 0.5056 - acc: 0.8758 - val_loss: 0.5415 - val_acc: 0.7750\n",
      "Epoch 54/170\n",
      "322/322 [==============================] - 0s 235us/sample - loss: 0.4969 - acc: 0.8385 - val_loss: 0.5550 - val_acc: 0.7625\n",
      "Epoch 55/170\n",
      "322/322 [==============================] - 0s 353us/sample - loss: 0.4912 - acc: 0.8137 - val_loss: 0.5467 - val_acc: 0.7750\n",
      "Epoch 56/170\n",
      "322/322 [==============================] - 0s 319us/sample - loss: 0.4814 - acc: 0.8323 - val_loss: 0.5306 - val_acc: 0.7875\n",
      "Epoch 57/170\n",
      "322/322 [==============================] - 0s 201us/sample - loss: 0.4692 - acc: 0.8696 - val_loss: 0.5116 - val_acc: 0.7875\n",
      "Epoch 58/170\n",
      "322/322 [==============================] - 0s 214us/sample - loss: 0.4650 - acc: 0.9006 - val_loss: 0.5001 - val_acc: 0.8250\n",
      "Epoch 59/170\n",
      "322/322 [==============================] - 0s 310us/sample - loss: 0.4563 - acc: 0.9068 - val_loss: 0.4982 - val_acc: 0.8000\n",
      "Epoch 60/170\n",
      "322/322 [==============================] - 0s 307us/sample - loss: 0.4458 - acc: 0.9037 - val_loss: 0.4946 - val_acc: 0.8000\n",
      "Epoch 61/170\n",
      "322/322 [==============================] - 0s 235us/sample - loss: 0.4373 - acc: 0.9006 - val_loss: 0.5004 - val_acc: 0.7875\n",
      "Epoch 62/170\n",
      "322/322 [==============================] - 0s 223us/sample - loss: 0.4289 - acc: 0.8727 - val_loss: 0.5004 - val_acc: 0.7875\n",
      "Epoch 63/170\n",
      "322/322 [==============================] - 0s 387us/sample - loss: 0.4203 - acc: 0.8789 - val_loss: 0.4853 - val_acc: 0.8000\n",
      "Epoch 64/170\n",
      "322/322 [==============================] - 0s 319us/sample - loss: 0.4120 - acc: 0.9037 - val_loss: 0.4728 - val_acc: 0.8375\n",
      "Epoch 65/170\n",
      "322/322 [==============================] - 0s 229us/sample - loss: 0.4108 - acc: 0.9161 - val_loss: 0.4655 - val_acc: 0.8750\n",
      "Epoch 66/170\n",
      "322/322 [==============================] - 0s 245us/sample - loss: 0.4042 - acc: 0.9255 - val_loss: 0.4638 - val_acc: 0.8375\n",
      "Epoch 67/170\n",
      "322/322 [==============================] - 0s 412us/sample - loss: 0.3901 - acc: 0.9099 - val_loss: 0.4708 - val_acc: 0.8000\n",
      "Epoch 68/170\n",
      "322/322 [==============================] - 0s 276us/sample - loss: 0.3829 - acc: 0.8975 - val_loss: 0.4741 - val_acc: 0.8000\n",
      "Epoch 69/170\n",
      "322/322 [==============================] - 0s 204us/sample - loss: 0.3781 - acc: 0.8882 - val_loss: 0.4652 - val_acc: 0.7875\n",
      "Epoch 70/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.3695 - acc: 0.9037 - val_loss: 0.4547 - val_acc: 0.8250\n",
      "Epoch 71/170\n",
      "322/322 [==============================] - 0s 338us/sample - loss: 0.3622 - acc: 0.9068 - val_loss: 0.4557 - val_acc: 0.8000\n",
      "Epoch 72/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.3582 - acc: 0.9006 - val_loss: 0.4582 - val_acc: 0.8000\n",
      "Epoch 73/170\n",
      "322/322 [==============================] - 0s 229us/sample - loss: 0.3509 - acc: 0.9037 - val_loss: 0.4463 - val_acc: 0.8250\n",
      "Epoch 74/170\n",
      "322/322 [==============================] - 0s 344us/sample - loss: 0.3433 - acc: 0.9130 - val_loss: 0.4371 - val_acc: 0.8375\n",
      "Epoch 75/170\n",
      "322/322 [==============================] - 0s 344us/sample - loss: 0.3385 - acc: 0.9255 - val_loss: 0.4311 - val_acc: 0.8750\n",
      "Epoch 76/170\n",
      "322/322 [==============================] - 0s 220us/sample - loss: 0.3325 - acc: 0.9255 - val_loss: 0.4333 - val_acc: 0.8250\n",
      "Epoch 77/170\n",
      "322/322 [==============================] - 0s 220us/sample - loss: 0.3278 - acc: 0.9099 - val_loss: 0.4418 - val_acc: 0.8125\n",
      "Epoch 78/170\n",
      "322/322 [==============================] - 0s 223us/sample - loss: 0.3219 - acc: 0.9037 - val_loss: 0.4319 - val_acc: 0.8250\n",
      "Epoch 79/170\n",
      "322/322 [==============================] - 0s 378us/sample - loss: 0.3148 - acc: 0.9161 - val_loss: 0.4226 - val_acc: 0.8500\n",
      "Epoch 80/170\n",
      "322/322 [==============================] - 0s 446us/sample - loss: 0.3098 - acc: 0.9224 - val_loss: 0.4214 - val_acc: 0.8500\n",
      "Epoch 81/170\n",
      "322/322 [==============================] - 0s 285us/sample - loss: 0.3061 - acc: 0.9193 - val_loss: 0.4273 - val_acc: 0.8250\n",
      "Epoch 82/170\n",
      "322/322 [==============================] - 0s 527us/sample - loss: 0.3011 - acc: 0.9099 - val_loss: 0.4246 - val_acc: 0.8250\n",
      "Epoch 83/170\n",
      "322/322 [==============================] - 0s 317us/sample - loss: 0.2953 - acc: 0.9193 - val_loss: 0.4170 - val_acc: 0.8375\n",
      "Epoch 84/170\n",
      "322/322 [==============================] - 0s 226us/sample - loss: 0.2898 - acc: 0.9193 - val_loss: 0.4187 - val_acc: 0.8250\n",
      "Epoch 85/170\n",
      "322/322 [==============================] - 0s 208us/sample - loss: 0.2864 - acc: 0.9224 - val_loss: 0.4086 - val_acc: 0.8875\n",
      "Epoch 86/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.2823 - acc: 0.9410 - val_loss: 0.4069 - val_acc: 0.8875\n",
      "Epoch 87/170\n",
      "322/322 [==============================] - 0s 437us/sample - loss: 0.2781 - acc: 0.9286 - val_loss: 0.4114 - val_acc: 0.8500\n",
      "Epoch 88/170\n",
      "322/322 [==============================] - 0s 223us/sample - loss: 0.2743 - acc: 0.9317 - val_loss: 0.4040 - val_acc: 0.8750\n",
      "Epoch 89/170\n",
      "322/322 [==============================] - 0s 201us/sample - loss: 0.2698 - acc: 0.9410 - val_loss: 0.3982 - val_acc: 0.8875\n",
      "Epoch 90/170\n",
      "322/322 [==============================] - 0s 217us/sample - loss: 0.2664 - acc: 0.9441 - val_loss: 0.3980 - val_acc: 0.8875\n",
      "Epoch 91/170\n",
      "322/322 [==============================] - 0s 341us/sample - loss: 0.2613 - acc: 0.9410 - val_loss: 0.4066 - val_acc: 0.8500\n",
      "Epoch 92/170\n",
      "322/322 [==============================] - 0s 328us/sample - loss: 0.2600 - acc: 0.9286 - val_loss: 0.4095 - val_acc: 0.8375\n",
      "Epoch 93/170\n",
      "322/322 [==============================] - 0s 217us/sample - loss: 0.2574 - acc: 0.9255 - val_loss: 0.4053 - val_acc: 0.8375\n",
      "Epoch 94/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.2531 - acc: 0.9317 - val_loss: 0.4016 - val_acc: 0.8625\n",
      "Epoch 95/170\n",
      "322/322 [==============================] - 0s 204us/sample - loss: 0.2487 - acc: 0.9410 - val_loss: 0.3920 - val_acc: 0.8875\n",
      "Epoch 96/170\n",
      "322/322 [==============================] - 0s 226us/sample - loss: 0.2461 - acc: 0.9441 - val_loss: 0.3842 - val_acc: 0.9125\n",
      "Epoch 97/170\n",
      "322/322 [==============================] - 0s 316us/sample - loss: 0.2426 - acc: 0.9503 - val_loss: 0.3826 - val_acc: 0.9125\n",
      "Epoch 98/170\n",
      "322/322 [==============================] - 0s 344us/sample - loss: 0.2389 - acc: 0.9503 - val_loss: 0.3806 - val_acc: 0.9125\n",
      "Epoch 99/170\n",
      "322/322 [==============================] - 0s 226us/sample - loss: 0.2358 - acc: 0.9503 - val_loss: 0.3800 - val_acc: 0.9125\n",
      "Epoch 100/170\n",
      "322/322 [==============================] - 0s 356us/sample - loss: 0.2312 - acc: 0.9534 - val_loss: 0.3864 - val_acc: 0.8750\n",
      "Epoch 101/170\n",
      "322/322 [==============================] - 0s 356us/sample - loss: 0.2281 - acc: 0.9472 - val_loss: 0.3848 - val_acc: 0.8750\n",
      "Epoch 102/170\n",
      "322/322 [==============================] - 0s 229us/sample - loss: 0.2252 - acc: 0.9472 - val_loss: 0.3785 - val_acc: 0.9000\n",
      "Epoch 103/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.2222 - acc: 0.9534 - val_loss: 0.3752 - val_acc: 0.9125\n",
      "Epoch 104/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.2206 - acc: 0.9503 - val_loss: 0.3725 - val_acc: 0.9000\n",
      "Epoch 105/170\n",
      "322/322 [==============================] - 0s 208us/sample - loss: 0.2204 - acc: 0.9534 - val_loss: 0.3719 - val_acc: 0.9125\n",
      "Epoch 106/170\n",
      "322/322 [==============================] - 0s 232us/sample - loss: 0.2146 - acc: 0.9534 - val_loss: 0.3884 - val_acc: 0.8750\n",
      "Epoch 107/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.2177 - acc: 0.9441 - val_loss: 0.4106 - val_acc: 0.8000\n",
      "Epoch 108/170\n",
      "322/322 [==============================] - 0s 242us/sample - loss: 0.2205 - acc: 0.9348 - val_loss: 0.3923 - val_acc: 0.8625\n",
      "Epoch 109/170\n",
      "322/322 [==============================] - 0s 217us/sample - loss: 0.2087 - acc: 0.9503 - val_loss: 0.3708 - val_acc: 0.9000\n",
      "Epoch 110/170\n",
      "322/322 [==============================] - 0s 452us/sample - loss: 0.2043 - acc: 0.9565 - val_loss: 0.3675 - val_acc: 0.9125\n",
      "Epoch 111/170\n",
      "322/322 [==============================] - 0s 279us/sample - loss: 0.2020 - acc: 0.9565 - val_loss: 0.3707 - val_acc: 0.8875\n",
      "Epoch 112/170\n",
      "322/322 [==============================] - 0s 201us/sample - loss: 0.1984 - acc: 0.9534 - val_loss: 0.3713 - val_acc: 0.8875\n",
      "Epoch 113/170\n",
      "322/322 [==============================] - 0s 378us/sample - loss: 0.1976 - acc: 0.9534 - val_loss: 0.3660 - val_acc: 0.9250\n",
      "Epoch 114/170\n",
      "322/322 [==============================] - 0s 330us/sample - loss: 0.1954 - acc: 0.9627 - val_loss: 0.3676 - val_acc: 0.9000\n",
      "Epoch 115/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.1934 - acc: 0.9565 - val_loss: 0.3826 - val_acc: 0.8500\n",
      "Epoch 116/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.1986 - acc: 0.9503 - val_loss: 0.3995 - val_acc: 0.8500\n",
      "Epoch 117/170\n",
      "322/322 [==============================] - 0s 350us/sample - loss: 0.1980 - acc: 0.9503 - val_loss: 0.3816 - val_acc: 0.8625\n",
      "Epoch 118/170\n",
      "322/322 [==============================] - 0s 279us/sample - loss: 0.1863 - acc: 0.9596 - val_loss: 0.3621 - val_acc: 0.9250\n",
      "Epoch 119/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 211us/sample - loss: 0.1940 - acc: 0.9689 - val_loss: 0.3655 - val_acc: 0.9000\n",
      "Epoch 120/170\n",
      "322/322 [==============================] - 0s 220us/sample - loss: 0.1998 - acc: 0.9720 - val_loss: 0.3630 - val_acc: 0.9000\n",
      "Epoch 121/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.1940 - acc: 0.9720 - val_loss: 0.3588 - val_acc: 0.9125\n",
      "Epoch 122/170\n",
      "322/322 [==============================] - 0s 198us/sample - loss: 0.1841 - acc: 0.9658 - val_loss: 0.3583 - val_acc: 0.9250\n",
      "Epoch 123/170\n",
      "322/322 [==============================] - 0s 297us/sample - loss: 0.1767 - acc: 0.9658 - val_loss: 0.3774 - val_acc: 0.8500\n",
      "Epoch 124/170\n",
      "322/322 [==============================] - 0s 344us/sample - loss: 0.1817 - acc: 0.9596 - val_loss: 0.3852 - val_acc: 0.8625\n",
      "Epoch 125/170\n",
      "322/322 [==============================] - 0s 235us/sample - loss: 0.1819 - acc: 0.9534 - val_loss: 0.3821 - val_acc: 0.8625\n",
      "Epoch 126/170\n",
      "322/322 [==============================] - 0s 279us/sample - loss: 0.1773 - acc: 0.9596 - val_loss: 0.3689 - val_acc: 0.8750\n",
      "Epoch 127/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.1718 - acc: 0.9658 - val_loss: 0.3556 - val_acc: 0.9250\n",
      "Epoch 128/170\n",
      "322/322 [==============================] - 0s 285us/sample - loss: 0.1703 - acc: 0.9658 - val_loss: 0.3532 - val_acc: 0.9125\n",
      "Epoch 129/170\n",
      "322/322 [==============================] - 0s 409us/sample - loss: 0.1698 - acc: 0.9658 - val_loss: 0.3559 - val_acc: 0.9125\n",
      "Epoch 130/170\n",
      "322/322 [==============================] - 0s 369us/sample - loss: 0.1674 - acc: 0.9689 - val_loss: 0.3813 - val_acc: 0.8625\n",
      "Epoch 131/170\n",
      "322/322 [==============================] - 0s 229us/sample - loss: 0.1752 - acc: 0.9534 - val_loss: 0.3884 - val_acc: 0.8500\n",
      "Epoch 132/170\n",
      "322/322 [==============================] - 0s 204us/sample - loss: 0.1711 - acc: 0.9627 - val_loss: 0.3659 - val_acc: 0.8750\n",
      "Epoch 133/170\n",
      "322/322 [==============================] - 0s 220us/sample - loss: 0.1638 - acc: 0.9720 - val_loss: 0.3564 - val_acc: 0.9000\n",
      "Epoch 134/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.1608 - acc: 0.9720 - val_loss: 0.3552 - val_acc: 0.9125\n",
      "Epoch 135/170\n",
      "322/322 [==============================] - 0s 214us/sample - loss: 0.1593 - acc: 0.9720 - val_loss: 0.3573 - val_acc: 0.8875\n",
      "Epoch 136/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.1583 - acc: 0.9752 - val_loss: 0.3564 - val_acc: 0.8875\n",
      "Epoch 137/170\n",
      "322/322 [==============================] - 0s 217us/sample - loss: 0.1566 - acc: 0.9752 - val_loss: 0.3536 - val_acc: 0.9125\n",
      "Epoch 138/170\n",
      "322/322 [==============================] - 0s 248us/sample - loss: 0.1561 - acc: 0.9720 - val_loss: 0.3521 - val_acc: 0.9125\n",
      "Epoch 139/170\n",
      "322/322 [==============================] - 0s 195us/sample - loss: 0.1540 - acc: 0.9752 - val_loss: 0.3578 - val_acc: 0.8750\n",
      "Epoch 140/170\n",
      "322/322 [==============================] - 0s 223us/sample - loss: 0.1532 - acc: 0.9720 - val_loss: 0.3559 - val_acc: 0.8875\n",
      "Epoch 141/170\n",
      "322/322 [==============================] - 0s 226us/sample - loss: 0.1516 - acc: 0.9752 - val_loss: 0.3516 - val_acc: 0.9125\n",
      "Epoch 142/170\n",
      "322/322 [==============================] - 0s 220us/sample - loss: 0.1505 - acc: 0.9720 - val_loss: 0.3477 - val_acc: 0.9250\n",
      "Epoch 143/170\n",
      "322/322 [==============================] - 0s 356us/sample - loss: 0.1503 - acc: 0.9752 - val_loss: 0.3468 - val_acc: 0.9250\n",
      "Epoch 144/170\n",
      "322/322 [==============================] - 0s 365us/sample - loss: 0.1511 - acc: 0.9814 - val_loss: 0.3463 - val_acc: 0.9000\n",
      "Epoch 145/170\n",
      "322/322 [==============================] - 0s 279us/sample - loss: 0.1506 - acc: 0.9814 - val_loss: 0.3458 - val_acc: 0.9125\n",
      "Epoch 146/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.1480 - acc: 0.9814 - val_loss: 0.3478 - val_acc: 0.9125\n",
      "Epoch 147/170\n",
      "322/322 [==============================] - 0s 226us/sample - loss: 0.1448 - acc: 0.9720 - val_loss: 0.3546 - val_acc: 0.8875\n",
      "Epoch 148/170\n",
      "322/322 [==============================] - 0s 217us/sample - loss: 0.1449 - acc: 0.9720 - val_loss: 0.3618 - val_acc: 0.8750\n",
      "Epoch 149/170\n",
      "322/322 [==============================] - 0s 223us/sample - loss: 0.1479 - acc: 0.9627 - val_loss: 0.3709 - val_acc: 0.8875\n",
      "Epoch 150/170\n",
      "322/322 [==============================] - 0s 245us/sample - loss: 0.1439 - acc: 0.9627 - val_loss: 0.3506 - val_acc: 0.9000\n",
      "Epoch 151/170\n",
      "322/322 [==============================] - 0s 238us/sample - loss: 0.1398 - acc: 0.9720 - val_loss: 0.3432 - val_acc: 0.9250\n",
      "Epoch 152/170\n",
      "322/322 [==============================] - 0s 362us/sample - loss: 0.1425 - acc: 0.9783 - val_loss: 0.3426 - val_acc: 0.9000\n",
      "Epoch 153/170\n",
      "322/322 [==============================] - 0s 406us/sample - loss: 0.1422 - acc: 0.9814 - val_loss: 0.3419 - val_acc: 0.9125\n",
      "Epoch 154/170\n",
      "322/322 [==============================] - 0s 242us/sample - loss: 0.1398 - acc: 0.9814 - val_loss: 0.3419 - val_acc: 0.9250\n",
      "Epoch 155/170\n",
      "322/322 [==============================] - 0s 217us/sample - loss: 0.1375 - acc: 0.9783 - val_loss: 0.3428 - val_acc: 0.9125\n",
      "Epoch 156/170\n",
      "322/322 [==============================] - 0s 217us/sample - loss: 0.1361 - acc: 0.9752 - val_loss: 0.3456 - val_acc: 0.9000\n",
      "Epoch 157/170\n",
      "322/322 [==============================] - 0s 245us/sample - loss: 0.1344 - acc: 0.9783 - val_loss: 0.3454 - val_acc: 0.9000\n",
      "Epoch 158/170\n",
      "322/322 [==============================] - 0s 238us/sample - loss: 0.1339 - acc: 0.9783 - val_loss: 0.3420 - val_acc: 0.9125\n",
      "Epoch 159/170\n",
      "322/322 [==============================] - 0s 331us/sample - loss: 0.1330 - acc: 0.9814 - val_loss: 0.3421 - val_acc: 0.9125\n",
      "Epoch 160/170\n",
      "322/322 [==============================] - 0s 304us/sample - loss: 0.1317 - acc: 0.9845 - val_loss: 0.3442 - val_acc: 0.9000\n",
      "Epoch 161/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.1311 - acc: 0.9783 - val_loss: 0.3456 - val_acc: 0.9000\n",
      "Epoch 162/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.1300 - acc: 0.9783 - val_loss: 0.3429 - val_acc: 0.9000\n",
      "Epoch 163/170\n",
      "322/322 [==============================] - 0s 220us/sample - loss: 0.1302 - acc: 0.9814 - val_loss: 0.3393 - val_acc: 0.9250\n",
      "Epoch 164/170\n",
      "322/322 [==============================] - 0s 217us/sample - loss: 0.1292 - acc: 0.9814 - val_loss: 0.3403 - val_acc: 0.9125\n",
      "Epoch 165/170\n",
      "322/322 [==============================] - 0s 338us/sample - loss: 0.1276 - acc: 0.9845 - val_loss: 0.3406 - val_acc: 0.9125\n",
      "Epoch 166/170\n",
      "322/322 [==============================] - 0s 313us/sample - loss: 0.1265 - acc: 0.9845 - val_loss: 0.3414 - val_acc: 0.9000\n",
      "Epoch 167/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.1256 - acc: 0.9814 - val_loss: 0.3420 - val_acc: 0.9000\n",
      "Epoch 168/170\n",
      "322/322 [==============================] - 0s 201us/sample - loss: 0.1249 - acc: 0.9783 - val_loss: 0.3418 - val_acc: 0.9000\n",
      "Epoch 169/170\n",
      "322/322 [==============================] - 0s 310us/sample - loss: 0.1250 - acc: 0.9814 - val_loss: 0.3387 - val_acc: 0.9125\n",
      "Epoch 170/170\n",
      "322/322 [==============================] - 0s 362us/sample - loss: 0.1242 - acc: 0.9845 - val_loss: 0.3383 - val_acc: 0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48  4]\n",
      " [ 3 25]]\n",
      "None\n",
      "(0.8620689655172413, 0.9125, 0.8928571428571429, 0.8771929824561403, 0.9457417582417582, 0.9338531393418612, 0.9328893304337956)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " snv_inputs (InputLayer)        [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " mRNA_inputs (InputLayer)       [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " miRNA_inputs (InputLayer)      [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " h0_snv (Biological_module)     (None, 238)          3170        ['snv_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " h0_mRNA (Biological_module)    (None, 238)          3113        ['mRNA_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " h0_miRNA (Biological_module)   (None, 238)          8124        ['miRNA_inputs[0][0]']           \n",
      "                                                                                                  \n",
      " self__attention_27 (Self_Atten  (None, 64)          45696       ['h0_snv[0][0]']                 \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_28 (Self_Atten  (None, 64)          45696       ['h0_mRNA[0][0]']                \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_29 (Self_Atten  (None, 64)          45696       ['h0_miRNA[0][0]']               \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 192)          0           ['self__attention_27[0][0]',     \n",
      "                                                                  'self__attention_28[0][0]',     \n",
      "                                                                  'self__attention_29[0][0]']     \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 32)           6176        ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1)            33          ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 157,704\n",
      "Trainable params: 157,704\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 322 samples, validate on 80 samples\n",
      "Epoch 1/170\n",
      " 64/322 [====>.........................] - ETA: 0s - loss: 0.7712 - acc: 0.3594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 1s 2ms/sample - loss: 0.8097 - acc: 0.5186 - val_loss: 0.8061 - val_acc: 0.6500\n",
      "Epoch 2/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.8056 - acc: 0.5714 - val_loss: 0.8024 - val_acc: 0.4250\n",
      "Epoch 3/170\n",
      "322/322 [==============================] - 0s 189us/sample - loss: 0.8016 - acc: 0.3882 - val_loss: 0.7987 - val_acc: 0.3500\n",
      "Epoch 4/170\n",
      "322/322 [==============================] - 0s 208us/sample - loss: 0.7977 - acc: 0.3634 - val_loss: 0.7948 - val_acc: 0.3875\n",
      "Epoch 5/170\n",
      "322/322 [==============================] - 0s 350us/sample - loss: 0.7940 - acc: 0.5031 - val_loss: 0.7909 - val_acc: 0.6750\n",
      "Epoch 6/170\n",
      "322/322 [==============================] - 0s 415us/sample - loss: 0.7904 - acc: 0.6211 - val_loss: 0.7873 - val_acc: 0.6875\n",
      "Epoch 7/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.7869 - acc: 0.6304 - val_loss: 0.7839 - val_acc: 0.7125\n",
      "Epoch 8/170\n",
      "322/322 [==============================] - 0s 204us/sample - loss: 0.7835 - acc: 0.6460 - val_loss: 0.7805 - val_acc: 0.6625\n",
      "Epoch 9/170\n",
      "322/322 [==============================] - 0s 223us/sample - loss: 0.7802 - acc: 0.6460 - val_loss: 0.7773 - val_acc: 0.6875\n",
      "Epoch 10/170\n",
      "322/322 [==============================] - 0s 335us/sample - loss: 0.7770 - acc: 0.6770 - val_loss: 0.7743 - val_acc: 0.6250\n",
      "Epoch 11/170\n",
      "322/322 [==============================] - 0s 322us/sample - loss: 0.7739 - acc: 0.6770 - val_loss: 0.7714 - val_acc: 0.6375\n",
      "Epoch 12/170\n",
      "322/322 [==============================] - 0s 231us/sample - loss: 0.7710 - acc: 0.6925 - val_loss: 0.7684 - val_acc: 0.7000\n",
      "Epoch 13/170\n",
      "322/322 [==============================] - 0s 217us/sample - loss: 0.7680 - acc: 0.5683 - val_loss: 0.7660 - val_acc: 0.4500\n",
      "Epoch 14/170\n",
      "322/322 [==============================] - 0s 220us/sample - loss: 0.7652 - acc: 0.5062 - val_loss: 0.7632 - val_acc: 0.5250\n",
      "Epoch 15/170\n",
      "322/322 [==============================] - 0s 229us/sample - loss: 0.7625 - acc: 0.6398 - val_loss: 0.7602 - val_acc: 0.6875\n",
      "Epoch 16/170\n",
      "322/322 [==============================] - 0s 390us/sample - loss: 0.7598 - acc: 0.7298 - val_loss: 0.7575 - val_acc: 0.6875\n",
      "Epoch 17/170\n",
      "322/322 [==============================] - 0s 511us/sample - loss: 0.7571 - acc: 0.7795 - val_loss: 0.7548 - val_acc: 0.7625\n",
      "Epoch 18/170\n",
      "322/322 [==============================] - 0s 319us/sample - loss: 0.7546 - acc: 0.8075 - val_loss: 0.7522 - val_acc: 0.8125\n",
      "Epoch 19/170\n",
      "322/322 [==============================] - 0s 291us/sample - loss: 0.7520 - acc: 0.7640 - val_loss: 0.7494 - val_acc: 0.7750\n",
      "Epoch 20/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.7495 - acc: 0.7360 - val_loss: 0.7468 - val_acc: 0.7625\n",
      "Epoch 21/170\n",
      "322/322 [==============================] - 0s 269us/sample - loss: 0.7469 - acc: 0.7205 - val_loss: 0.7440 - val_acc: 0.7250\n",
      "Epoch 22/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.7443 - acc: 0.7143 - val_loss: 0.7416 - val_acc: 0.7750\n",
      "Epoch 23/170\n",
      "322/322 [==============================] - 0s 291us/sample - loss: 0.7416 - acc: 0.8292 - val_loss: 0.7399 - val_acc: 0.7625\n",
      "Epoch 24/170\n",
      "322/322 [==============================] - 0s 356us/sample - loss: 0.7388 - acc: 0.8261 - val_loss: 0.7375 - val_acc: 0.7625\n",
      "Epoch 25/170\n",
      "322/322 [==============================] - 0s 328us/sample - loss: 0.7358 - acc: 0.7671 - val_loss: 0.7355 - val_acc: 0.7125\n",
      "Epoch 26/170\n",
      "322/322 [==============================] - 0s 238us/sample - loss: 0.7326 - acc: 0.6770 - val_loss: 0.7349 - val_acc: 0.5125\n",
      "Epoch 27/170\n",
      "322/322 [==============================] - 0s 198us/sample - loss: 0.7291 - acc: 0.5590 - val_loss: 0.7337 - val_acc: 0.5000\n",
      "Epoch 28/170\n",
      "322/322 [==============================] - 0s 195us/sample - loss: 0.7254 - acc: 0.5528 - val_loss: 0.7298 - val_acc: 0.5375\n",
      "Epoch 29/170\n",
      "322/322 [==============================] - 0s 198us/sample - loss: 0.7217 - acc: 0.6491 - val_loss: 0.7241 - val_acc: 0.7000\n",
      "Epoch 30/170\n",
      "322/322 [==============================] - 0s 189us/sample - loss: 0.7176 - acc: 0.7547 - val_loss: 0.7182 - val_acc: 0.7875\n",
      "Epoch 31/170\n",
      "322/322 [==============================] - 0s 198us/sample - loss: 0.7135 - acc: 0.8571 - val_loss: 0.7120 - val_acc: 0.8750\n",
      "Epoch 32/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.7093 - acc: 0.8540 - val_loss: 0.7071 - val_acc: 0.8500\n",
      "Epoch 33/170\n",
      "322/322 [==============================] - 0s 192us/sample - loss: 0.7047 - acc: 0.8509 - val_loss: 0.7014 - val_acc: 0.8000\n",
      "Epoch 34/170\n",
      "322/322 [==============================] - 0s 204us/sample - loss: 0.6998 - acc: 0.8509 - val_loss: 0.6969 - val_acc: 0.8375\n",
      "Epoch 35/170\n",
      "322/322 [==============================] - 0s 208us/sample - loss: 0.6942 - acc: 0.8634 - val_loss: 0.6925 - val_acc: 0.8750\n",
      "Epoch 36/170\n",
      "322/322 [==============================] - 0s 195us/sample - loss: 0.6882 - acc: 0.8665 - val_loss: 0.6847 - val_acc: 0.8375\n",
      "Epoch 37/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.6815 - acc: 0.8571 - val_loss: 0.6769 - val_acc: 0.8000\n",
      "Epoch 38/170\n",
      "322/322 [==============================] - 0s 381us/sample - loss: 0.6748 - acc: 0.8634 - val_loss: 0.6714 - val_acc: 0.8375\n",
      "Epoch 39/170\n",
      "322/322 [==============================] - 0s 294us/sample - loss: 0.6669 - acc: 0.8665 - val_loss: 0.6636 - val_acc: 0.8375\n",
      "Epoch 40/170\n",
      "322/322 [==============================] - 0s 248us/sample - loss: 0.6598 - acc: 0.8447 - val_loss: 0.6538 - val_acc: 0.7875\n",
      "Epoch 41/170\n",
      "322/322 [==============================] - 0s 192us/sample - loss: 0.6513 - acc: 0.8602 - val_loss: 0.6482 - val_acc: 0.8375\n",
      "Epoch 42/170\n",
      "322/322 [==============================] - 0s 195us/sample - loss: 0.6418 - acc: 0.8540 - val_loss: 0.6391 - val_acc: 0.8375\n",
      "Epoch 43/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.6326 - acc: 0.8571 - val_loss: 0.6281 - val_acc: 0.8000\n",
      "Epoch 44/170\n",
      "322/322 [==============================] - 0s 316us/sample - loss: 0.6240 - acc: 0.8602 - val_loss: 0.6176 - val_acc: 0.8000\n",
      "Epoch 45/170\n",
      "322/322 [==============================] - 0s 317us/sample - loss: 0.6133 - acc: 0.8634 - val_loss: 0.6123 - val_acc: 0.8250\n",
      "Epoch 46/170\n",
      "322/322 [==============================] - 0s 220us/sample - loss: 0.6011 - acc: 0.8882 - val_loss: 0.6049 - val_acc: 0.8125\n",
      "Epoch 47/170\n",
      "322/322 [==============================] - 0s 222us/sample - loss: 0.5895 - acc: 0.8789 - val_loss: 0.5966 - val_acc: 0.8250\n",
      "Epoch 48/170\n",
      "322/322 [==============================] - 0s 204us/sample - loss: 0.5768 - acc: 0.8696 - val_loss: 0.5950 - val_acc: 0.8250\n",
      "Epoch 49/170\n",
      "322/322 [==============================] - 0s 208us/sample - loss: 0.5639 - acc: 0.8540 - val_loss: 0.5916 - val_acc: 0.8000\n",
      "Epoch 50/170\n",
      "322/322 [==============================] - 0s 192us/sample - loss: 0.5506 - acc: 0.8168 - val_loss: 0.5985 - val_acc: 0.7625\n",
      "Epoch 51/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.5418 - acc: 0.7888 - val_loss: 0.5836 - val_acc: 0.7625\n",
      "Epoch 52/170\n",
      "322/322 [==============================] - 0s 285us/sample - loss: 0.5319 - acc: 0.8230 - val_loss: 0.5572 - val_acc: 0.8500\n",
      "Epoch 53/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.5244 - acc: 0.8789 - val_loss: 0.5378 - val_acc: 0.8250\n",
      "Epoch 54/170\n",
      "322/322 [==============================] - 0s 248us/sample - loss: 0.5184 - acc: 0.8758 - val_loss: 0.5268 - val_acc: 0.8375\n",
      "Epoch 55/170\n",
      "322/322 [==============================] - 0s 242us/sample - loss: 0.5086 - acc: 0.8851 - val_loss: 0.5239 - val_acc: 0.8250\n",
      "Epoch 56/170\n",
      "322/322 [==============================] - 0s 235us/sample - loss: 0.4958 - acc: 0.8789 - val_loss: 0.5293 - val_acc: 0.8375\n",
      "Epoch 57/170\n",
      "322/322 [==============================] - 0s 226us/sample - loss: 0.4832 - acc: 0.8634 - val_loss: 0.5307 - val_acc: 0.8000\n",
      "Epoch 58/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.4738 - acc: 0.8602 - val_loss: 0.5143 - val_acc: 0.8375\n",
      "Epoch 59/170\n",
      "322/322 [==============================] - 0s 220us/sample - loss: 0.4670 - acc: 0.8913 - val_loss: 0.4977 - val_acc: 0.8625\n",
      "Epoch 60/170\n",
      "322/322 [==============================] - 0s 220us/sample - loss: 0.4611 - acc: 0.8975 - val_loss: 0.4874 - val_acc: 0.8625\n",
      "Epoch 61/170\n",
      "322/322 [==============================] - 0s 204us/sample - loss: 0.4540 - acc: 0.8975 - val_loss: 0.4800 - val_acc: 0.8625\n",
      "Epoch 62/170\n",
      "322/322 [==============================] - 0s 214us/sample - loss: 0.4464 - acc: 0.8975 - val_loss: 0.4737 - val_acc: 0.8625\n",
      "Epoch 63/170\n",
      "322/322 [==============================] - 0s 192us/sample - loss: 0.4391 - acc: 0.9006 - val_loss: 0.4657 - val_acc: 0.8500\n",
      "Epoch 64/170\n",
      "322/322 [==============================] - 0s 304us/sample - loss: 0.4336 - acc: 0.8944 - val_loss: 0.4598 - val_acc: 0.8625\n",
      "Epoch 65/170\n",
      "322/322 [==============================] - 0s 335us/sample - loss: 0.4230 - acc: 0.9037 - val_loss: 0.4610 - val_acc: 0.8625\n",
      "Epoch 66/170\n",
      "322/322 [==============================] - 0s 410us/sample - loss: 0.4121 - acc: 0.8944 - val_loss: 0.4619 - val_acc: 0.8625\n",
      "Epoch 67/170\n",
      "322/322 [==============================] - 0s 304us/sample - loss: 0.4039 - acc: 0.8944 - val_loss: 0.4649 - val_acc: 0.8375\n",
      "Epoch 68/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.3960 - acc: 0.8882 - val_loss: 0.4584 - val_acc: 0.8500\n",
      "Epoch 69/170\n",
      "322/322 [==============================] - 0s 449us/sample - loss: 0.3884 - acc: 0.8944 - val_loss: 0.4441 - val_acc: 0.8750\n",
      "Epoch 70/170\n",
      "322/322 [==============================] - 0s 362us/sample - loss: 0.3842 - acc: 0.9068 - val_loss: 0.4309 - val_acc: 0.8625\n",
      "Epoch 71/170\n",
      "322/322 [==============================] - 0s 423us/sample - loss: 0.3782 - acc: 0.9068 - val_loss: 0.4262 - val_acc: 0.8625\n",
      "Epoch 72/170\n",
      "322/322 [==============================] - 0s 211us/sample - loss: 0.3713 - acc: 0.9099 - val_loss: 0.4248 - val_acc: 0.8875\n",
      "Epoch 73/170\n",
      "322/322 [==============================] - 0s 208us/sample - loss: 0.3639 - acc: 0.9037 - val_loss: 0.4365 - val_acc: 0.8500\n",
      "Epoch 74/170\n",
      "322/322 [==============================] - 0s 204us/sample - loss: 0.3594 - acc: 0.8913 - val_loss: 0.4434 - val_acc: 0.8500\n",
      "Epoch 75/170\n",
      "322/322 [==============================] - 0s 189us/sample - loss: 0.3537 - acc: 0.8975 - val_loss: 0.4372 - val_acc: 0.8500\n",
      "Epoch 76/170\n",
      "322/322 [==============================] - 0s 239us/sample - loss: 0.3478 - acc: 0.8975 - val_loss: 0.4349 - val_acc: 0.8500\n",
      "Epoch 77/170\n",
      "322/322 [==============================] - 0s 316us/sample - loss: 0.3427 - acc: 0.9006 - val_loss: 0.4258 - val_acc: 0.8500\n",
      "Epoch 78/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.3355 - acc: 0.8975 - val_loss: 0.4117 - val_acc: 0.8625\n",
      "Epoch 79/170\n",
      "322/322 [==============================] - 0s 253us/sample - loss: 0.3279 - acc: 0.9068 - val_loss: 0.3933 - val_acc: 0.8875\n",
      "Epoch 80/170\n",
      "322/322 [==============================] - 0s 248us/sample - loss: 0.3232 - acc: 0.9224 - val_loss: 0.3795 - val_acc: 0.8875\n",
      "Epoch 81/170\n",
      "322/322 [==============================] - 0s 189us/sample - loss: 0.3296 - acc: 0.9255 - val_loss: 0.3736 - val_acc: 0.8750\n",
      "Epoch 82/170\n",
      "322/322 [==============================] - 0s 192us/sample - loss: 0.3267 - acc: 0.9255 - val_loss: 0.3723 - val_acc: 0.8875\n",
      "Epoch 83/170\n",
      "322/322 [==============================] - 0s 208us/sample - loss: 0.3117 - acc: 0.9161 - val_loss: 0.3947 - val_acc: 0.8750\n",
      "Epoch 84/170\n",
      "322/322 [==============================] - 0s 223us/sample - loss: 0.3081 - acc: 0.9068 - val_loss: 0.4056 - val_acc: 0.8500\n",
      "Epoch 85/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.3031 - acc: 0.9037 - val_loss: 0.3773 - val_acc: 0.8875\n",
      "Epoch 86/170\n",
      "322/322 [==============================] - 0s 307us/sample - loss: 0.2978 - acc: 0.9255 - val_loss: 0.3654 - val_acc: 0.8875\n",
      "Epoch 87/170\n",
      "322/322 [==============================] - 0s 353us/sample - loss: 0.2942 - acc: 0.9286 - val_loss: 0.3641 - val_acc: 0.9000\n",
      "Epoch 88/170\n",
      "322/322 [==============================] - 0s 400us/sample - loss: 0.2899 - acc: 0.9286 - val_loss: 0.3590 - val_acc: 0.9000\n",
      "Epoch 89/170\n",
      "322/322 [==============================] - 0s 294us/sample - loss: 0.2883 - acc: 0.9348 - val_loss: 0.3509 - val_acc: 0.8875\n",
      "Epoch 90/170\n",
      "322/322 [==============================] - 0s 223us/sample - loss: 0.2849 - acc: 0.9441 - val_loss: 0.3513 - val_acc: 0.9000\n",
      "Epoch 91/170\n",
      "322/322 [==============================] - 0s 396us/sample - loss: 0.2800 - acc: 0.9255 - val_loss: 0.3669 - val_acc: 0.9000\n",
      "Epoch 92/170\n",
      "322/322 [==============================] - 0s 378us/sample - loss: 0.2779 - acc: 0.9099 - val_loss: 0.3939 - val_acc: 0.8500\n",
      "Epoch 93/170\n",
      "322/322 [==============================] - 0s 378us/sample - loss: 0.2798 - acc: 0.9068 - val_loss: 0.3746 - val_acc: 0.8750\n",
      "Epoch 94/170\n",
      "322/322 [==============================] - 0s 396us/sample - loss: 0.2701 - acc: 0.9224 - val_loss: 0.3417 - val_acc: 0.9000\n",
      "Epoch 95/170\n",
      "322/322 [==============================] - 0s 331us/sample - loss: 0.2676 - acc: 0.9410 - val_loss: 0.3307 - val_acc: 0.9000\n",
      "Epoch 96/170\n",
      "322/322 [==============================] - 0s 300us/sample - loss: 0.2679 - acc: 0.9410 - val_loss: 0.3284 - val_acc: 0.9000\n",
      "Epoch 97/170\n",
      "322/322 [==============================] - 0s 300us/sample - loss: 0.2610 - acc: 0.9410 - val_loss: 0.3348 - val_acc: 0.9000\n",
      "Epoch 98/170\n",
      "322/322 [==============================] - 0s 313us/sample - loss: 0.2539 - acc: 0.9379 - val_loss: 0.3378 - val_acc: 0.9000\n",
      "Epoch 99/170\n",
      "322/322 [==============================] - 0s 455us/sample - loss: 0.2508 - acc: 0.9379 - val_loss: 0.3331 - val_acc: 0.9000\n",
      "Epoch 100/170\n",
      "322/322 [==============================] - 0s 321us/sample - loss: 0.2481 - acc: 0.9410 - val_loss: 0.3411 - val_acc: 0.9000\n",
      "Epoch 101/170\n",
      "322/322 [==============================] - 0s 291us/sample - loss: 0.2455 - acc: 0.9379 - val_loss: 0.3367 - val_acc: 0.9000\n",
      "Epoch 102/170\n",
      "322/322 [==============================] - 0s 285us/sample - loss: 0.2419 - acc: 0.9379 - val_loss: 0.3245 - val_acc: 0.9000\n",
      "Epoch 103/170\n",
      "322/322 [==============================] - 0s 297us/sample - loss: 0.2381 - acc: 0.9410 - val_loss: 0.3136 - val_acc: 0.9250\n",
      "Epoch 104/170\n",
      "322/322 [==============================] - 0s 375us/sample - loss: 0.2376 - acc: 0.9410 - val_loss: 0.3118 - val_acc: 0.9250\n",
      "Epoch 105/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.2346 - acc: 0.9410 - val_loss: 0.3100 - val_acc: 0.9250\n",
      "Epoch 106/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.2321 - acc: 0.9410 - val_loss: 0.3069 - val_acc: 0.9250\n",
      "Epoch 107/170\n",
      "322/322 [==============================] - 0s 235us/sample - loss: 0.2290 - acc: 0.9441 - val_loss: 0.3079 - val_acc: 0.9250\n",
      "Epoch 108/170\n",
      "322/322 [==============================] - 0s 344us/sample - loss: 0.2254 - acc: 0.9441 - val_loss: 0.3105 - val_acc: 0.9125\n",
      "Epoch 109/170\n",
      "322/322 [==============================] - 0s 307us/sample - loss: 0.2219 - acc: 0.9441 - val_loss: 0.3055 - val_acc: 0.9250\n",
      "Epoch 110/170\n",
      "322/322 [==============================] - 0s 331us/sample - loss: 0.2203 - acc: 0.9441 - val_loss: 0.3049 - val_acc: 0.9125\n",
      "Epoch 111/170\n",
      "322/322 [==============================] - 0s 325us/sample - loss: 0.2178 - acc: 0.9441 - val_loss: 0.3041 - val_acc: 0.9125\n",
      "Epoch 112/170\n",
      "322/322 [==============================] - 0s 477us/sample - loss: 0.2157 - acc: 0.9441 - val_loss: 0.3000 - val_acc: 0.9250\n",
      "Epoch 113/170\n",
      "322/322 [==============================] - 0s 384us/sample - loss: 0.2142 - acc: 0.9472 - val_loss: 0.2943 - val_acc: 0.9250\n",
      "Epoch 114/170\n",
      "322/322 [==============================] - 0s 412us/sample - loss: 0.2139 - acc: 0.9534 - val_loss: 0.2894 - val_acc: 0.9125\n",
      "Epoch 115/170\n",
      "322/322 [==============================] - 0s 344us/sample - loss: 0.2118 - acc: 0.9534 - val_loss: 0.2908 - val_acc: 0.9250\n",
      "Epoch 116/170\n",
      "322/322 [==============================] - 0s 335us/sample - loss: 0.2071 - acc: 0.9472 - val_loss: 0.2964 - val_acc: 0.9125\n",
      "Epoch 117/170\n",
      "322/322 [==============================] - 0s 285us/sample - loss: 0.2044 - acc: 0.9472 - val_loss: 0.2947 - val_acc: 0.9125\n",
      "Epoch 118/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.2022 - acc: 0.9472 - val_loss: 0.2917 - val_acc: 0.9250\n",
      "Epoch 119/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 276us/sample - loss: 0.1998 - acc: 0.9472 - val_loss: 0.2872 - val_acc: 0.9250\n",
      "Epoch 120/170\n",
      "322/322 [==============================] - 0s 290us/sample - loss: 0.1976 - acc: 0.9472 - val_loss: 0.2903 - val_acc: 0.9125\n",
      "Epoch 121/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.1954 - acc: 0.9472 - val_loss: 0.2813 - val_acc: 0.9250\n",
      "Epoch 122/170\n",
      "322/322 [==============================] - 0s 294us/sample - loss: 0.1946 - acc: 0.9503 - val_loss: 0.2747 - val_acc: 0.9250\n",
      "Epoch 123/170\n",
      "322/322 [==============================] - 0s 235us/sample - loss: 0.1935 - acc: 0.9534 - val_loss: 0.2761 - val_acc: 0.9250\n",
      "Epoch 124/170\n",
      "322/322 [==============================] - 0s 235us/sample - loss: 0.1902 - acc: 0.9534 - val_loss: 0.2794 - val_acc: 0.9250\n",
      "Epoch 125/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.1894 - acc: 0.9534 - val_loss: 0.2738 - val_acc: 0.9250\n",
      "Epoch 126/170\n",
      "322/322 [==============================] - 0s 276us/sample - loss: 0.1864 - acc: 0.9503 - val_loss: 0.2807 - val_acc: 0.9375\n",
      "Epoch 127/170\n",
      "322/322 [==============================] - 0s 242us/sample - loss: 0.1848 - acc: 0.9472 - val_loss: 0.2886 - val_acc: 0.9125\n",
      "Epoch 128/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.1862 - acc: 0.9534 - val_loss: 0.3093 - val_acc: 0.9000\n",
      "Epoch 129/170\n",
      "322/322 [==============================] - 0s 229us/sample - loss: 0.1905 - acc: 0.9441 - val_loss: 0.3126 - val_acc: 0.9000\n",
      "Epoch 130/170\n",
      "322/322 [==============================] - 0s 217us/sample - loss: 0.1879 - acc: 0.9503 - val_loss: 0.2950 - val_acc: 0.9000\n",
      "Epoch 131/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.1808 - acc: 0.9534 - val_loss: 0.2812 - val_acc: 0.9375\n",
      "Epoch 132/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.1780 - acc: 0.9565 - val_loss: 0.2831 - val_acc: 0.9250\n",
      "Epoch 133/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.1772 - acc: 0.9565 - val_loss: 0.2813 - val_acc: 0.9375\n",
      "Epoch 134/170\n",
      "322/322 [==============================] - 0s 245us/sample - loss: 0.1749 - acc: 0.9534 - val_loss: 0.2651 - val_acc: 0.9250\n",
      "Epoch 135/170\n",
      "322/322 [==============================] - 0s 245us/sample - loss: 0.1734 - acc: 0.9627 - val_loss: 0.2588 - val_acc: 0.9250\n",
      "Epoch 136/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.1740 - acc: 0.9658 - val_loss: 0.2578 - val_acc: 0.9250\n",
      "Epoch 137/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.1718 - acc: 0.9596 - val_loss: 0.2590 - val_acc: 0.9250\n",
      "Epoch 138/170\n",
      "322/322 [==============================] - 0s 248us/sample - loss: 0.1686 - acc: 0.9596 - val_loss: 0.2641 - val_acc: 0.9375\n",
      "Epoch 139/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.1665 - acc: 0.9627 - val_loss: 0.2597 - val_acc: 0.9375\n",
      "Epoch 140/170\n",
      "322/322 [==============================] - 0s 297us/sample - loss: 0.1654 - acc: 0.9596 - val_loss: 0.2620 - val_acc: 0.9375\n",
      "Epoch 141/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.1638 - acc: 0.9627 - val_loss: 0.2637 - val_acc: 0.9375\n",
      "Epoch 142/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.1627 - acc: 0.9627 - val_loss: 0.2633 - val_acc: 0.9375\n",
      "Epoch 143/170\n",
      "322/322 [==============================] - 0s 223us/sample - loss: 0.1613 - acc: 0.9627 - val_loss: 0.2609 - val_acc: 0.9375\n",
      "Epoch 144/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.1602 - acc: 0.9658 - val_loss: 0.2615 - val_acc: 0.9375\n",
      "Epoch 145/170\n",
      "322/322 [==============================] - 0s 322us/sample - loss: 0.1590 - acc: 0.9658 - val_loss: 0.2602 - val_acc: 0.9375\n",
      "Epoch 146/170\n",
      "322/322 [==============================] - 0s 242us/sample - loss: 0.1580 - acc: 0.9627 - val_loss: 0.2599 - val_acc: 0.9375\n",
      "Epoch 147/170\n",
      "322/322 [==============================] - 0s 276us/sample - loss: 0.1565 - acc: 0.9658 - val_loss: 0.2548 - val_acc: 0.9375\n",
      "Epoch 148/170\n",
      "322/322 [==============================] - 0s 245us/sample - loss: 0.1551 - acc: 0.9658 - val_loss: 0.2490 - val_acc: 0.9375\n",
      "Epoch 149/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.1544 - acc: 0.9658 - val_loss: 0.2468 - val_acc: 0.9375\n",
      "Epoch 150/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.1530 - acc: 0.9627 - val_loss: 0.2483 - val_acc: 0.9375\n",
      "Epoch 151/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.1516 - acc: 0.9658 - val_loss: 0.2487 - val_acc: 0.9375\n",
      "Epoch 152/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.1507 - acc: 0.9658 - val_loss: 0.2477 - val_acc: 0.9375\n",
      "Epoch 153/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.1496 - acc: 0.9658 - val_loss: 0.2505 - val_acc: 0.9375\n",
      "Epoch 154/170\n",
      "322/322 [==============================] - 0s 285us/sample - loss: 0.1488 - acc: 0.9658 - val_loss: 0.2547 - val_acc: 0.9375\n",
      "Epoch 155/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.1542 - acc: 0.9565 - val_loss: 0.2881 - val_acc: 0.9000\n",
      "Epoch 156/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.1583 - acc: 0.9503 - val_loss: 0.2870 - val_acc: 0.9000\n",
      "Epoch 157/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.1523 - acc: 0.9534 - val_loss: 0.2576 - val_acc: 0.9375\n",
      "Epoch 158/170\n",
      "322/322 [==============================] - 0s 300us/sample - loss: 0.1463 - acc: 0.9658 - val_loss: 0.2417 - val_acc: 0.9375\n",
      "Epoch 159/170\n",
      "322/322 [==============================] - 0s 365us/sample - loss: 0.1444 - acc: 0.9783 - val_loss: 0.2377 - val_acc: 0.9375\n",
      "Epoch 160/170\n",
      "322/322 [==============================] - 0s 350us/sample - loss: 0.1438 - acc: 0.9783 - val_loss: 0.2374 - val_acc: 0.9375\n",
      "Epoch 161/170\n",
      "322/322 [==============================] - 0s 308us/sample - loss: 0.1423 - acc: 0.9814 - val_loss: 0.2384 - val_acc: 0.9375\n",
      "Epoch 162/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.1410 - acc: 0.9752 - val_loss: 0.2389 - val_acc: 0.9375\n",
      "Epoch 163/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.1409 - acc: 0.9783 - val_loss: 0.2334 - val_acc: 0.9375\n",
      "Epoch 164/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.1424 - acc: 0.9814 - val_loss: 0.2314 - val_acc: 0.9250\n",
      "Epoch 165/170\n",
      "322/322 [==============================] - 0s 242us/sample - loss: 0.1415 - acc: 0.9814 - val_loss: 0.2318 - val_acc: 0.9375\n",
      "Epoch 166/170\n",
      "322/322 [==============================] - 0s 285us/sample - loss: 0.1375 - acc: 0.9783 - val_loss: 0.2385 - val_acc: 0.9375\n",
      "Epoch 167/170\n",
      "322/322 [==============================] - 0s 279us/sample - loss: 0.1358 - acc: 0.9752 - val_loss: 0.2432 - val_acc: 0.9375\n",
      "Epoch 168/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.1356 - acc: 0.9658 - val_loss: 0.2424 - val_acc: 0.9375\n",
      "Epoch 169/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.1349 - acc: 0.9689 - val_loss: 0.2450 - val_acc: 0.9375\n",
      "Epoch 170/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.1366 - acc: 0.9658 - val_loss: 0.2592 - val_acc: 0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46  6]\n",
      " [ 1 27]]\n",
      "None\n",
      "(0.8181818181818182, 0.9125, 0.9642857142857143, 0.8852459016393442, 0.9869505494505495, 0.9790862993870513, 0.9787446551019275)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " snv_inputs (InputLayer)        [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " mRNA_inputs (InputLayer)       [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " miRNA_inputs (InputLayer)      [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " h0_snv (Biological_module)     (None, 238)          3170        ['snv_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " h0_mRNA (Biological_module)    (None, 238)          3113        ['mRNA_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " h0_miRNA (Biological_module)   (None, 238)          8124        ['miRNA_inputs[0][0]']           \n",
      "                                                                                                  \n",
      " self__attention_30 (Self_Atten  (None, 64)          45696       ['h0_snv[0][0]']                 \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_31 (Self_Atten  (None, 64)          45696       ['h0_mRNA[0][0]']                \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_32 (Self_Atten  (None, 64)          45696       ['h0_miRNA[0][0]']               \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 192)          0           ['self__attention_30[0][0]',     \n",
      "                                                                  'self__attention_31[0][0]',     \n",
      "                                                                  'self__attention_32[0][0]']     \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 32)           6176        ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1)            33          ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 157,704\n",
      "Trainable params: 157,704\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 322 samples, validate on 80 samples\n",
      "Epoch 1/170\n",
      "322/322 [==============================] - ETA: 0s - loss: 0.8081 - acc: 0.4348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 1s 2ms/sample - loss: 0.8081 - acc: 0.4348 - val_loss: 0.8064 - val_acc: 0.4250\n",
      "Epoch 2/170\n",
      "322/322 [==============================] - 0s 279us/sample - loss: 0.8040 - acc: 0.3789 - val_loss: 0.8026 - val_acc: 0.3875\n",
      "Epoch 3/170\n",
      "322/322 [==============================] - 0s 338us/sample - loss: 0.8001 - acc: 0.4161 - val_loss: 0.7984 - val_acc: 0.5875\n",
      "Epoch 4/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.7963 - acc: 0.6584 - val_loss: 0.7942 - val_acc: 0.6375\n",
      "Epoch 5/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.7926 - acc: 0.6522 - val_loss: 0.7900 - val_acc: 0.6375\n",
      "Epoch 6/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.7890 - acc: 0.6460 - val_loss: 0.7859 - val_acc: 0.6375\n",
      "Epoch 7/170\n",
      "322/322 [==============================] - 0s 406us/sample - loss: 0.7855 - acc: 0.6460 - val_loss: 0.7819 - val_acc: 0.6375\n",
      "Epoch 8/170\n",
      "322/322 [==============================] - 0s 316us/sample - loss: 0.7821 - acc: 0.6460 - val_loss: 0.7784 - val_acc: 0.6375\n",
      "Epoch 9/170\n",
      "322/322 [==============================] - 0s 421us/sample - loss: 0.7788 - acc: 0.6460 - val_loss: 0.7747 - val_acc: 0.6375\n",
      "Epoch 10/170\n",
      "322/322 [==============================] - 0s 483us/sample - loss: 0.7755 - acc: 0.6460 - val_loss: 0.7715 - val_acc: 0.6375\n",
      "Epoch 11/170\n",
      "322/322 [==============================] - 0s 412us/sample - loss: 0.7724 - acc: 0.6460 - val_loss: 0.7681 - val_acc: 0.6375\n",
      "Epoch 12/170\n",
      "322/322 [==============================] - 0s 341us/sample - loss: 0.7693 - acc: 0.6460 - val_loss: 0.7649 - val_acc: 0.6375\n",
      "Epoch 13/170\n",
      "322/322 [==============================] - 0s 238us/sample - loss: 0.7662 - acc: 0.6460 - val_loss: 0.7614 - val_acc: 0.6375\n",
      "Epoch 14/170\n",
      "322/322 [==============================] - 0s 279us/sample - loss: 0.7633 - acc: 0.6460 - val_loss: 0.7576 - val_acc: 0.6375\n",
      "Epoch 15/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.7603 - acc: 0.6460 - val_loss: 0.7544 - val_acc: 0.6375\n",
      "Epoch 16/170\n",
      "322/322 [==============================] - 0s 226us/sample - loss: 0.7573 - acc: 0.6460 - val_loss: 0.7506 - val_acc: 0.6375\n",
      "Epoch 17/170\n",
      "322/322 [==============================] - 0s 229us/sample - loss: 0.7544 - acc: 0.6460 - val_loss: 0.7466 - val_acc: 0.6375\n",
      "Epoch 18/170\n",
      "322/322 [==============================] - 0s 322us/sample - loss: 0.7513 - acc: 0.6460 - val_loss: 0.7439 - val_acc: 0.6375\n",
      "Epoch 19/170\n",
      "322/322 [==============================] - 0s 294us/sample - loss: 0.7482 - acc: 0.6491 - val_loss: 0.7415 - val_acc: 0.6375\n",
      "Epoch 20/170\n",
      "322/322 [==============================] - 0s 269us/sample - loss: 0.7449 - acc: 0.6491 - val_loss: 0.7377 - val_acc: 0.6375\n",
      "Epoch 21/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.7418 - acc: 0.6491 - val_loss: 0.7335 - val_acc: 0.6375\n",
      "Epoch 22/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.7385 - acc: 0.6491 - val_loss: 0.7308 - val_acc: 0.6375\n",
      "Epoch 23/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.7348 - acc: 0.6615 - val_loss: 0.7303 - val_acc: 0.6375\n",
      "Epoch 24/170\n",
      "322/322 [==============================] - 0s 276us/sample - loss: 0.7309 - acc: 0.7236 - val_loss: 0.7294 - val_acc: 0.7000\n",
      "Epoch 25/170\n",
      "322/322 [==============================] - 0s 269us/sample - loss: 0.7268 - acc: 0.7671 - val_loss: 0.7256 - val_acc: 0.6750\n",
      "Epoch 26/170\n",
      "322/322 [==============================] - 0s 248us/sample - loss: 0.7229 - acc: 0.7453 - val_loss: 0.7206 - val_acc: 0.6875\n",
      "Epoch 27/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.7184 - acc: 0.7422 - val_loss: 0.7176 - val_acc: 0.6875\n",
      "Epoch 28/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.7135 - acc: 0.7888 - val_loss: 0.7147 - val_acc: 0.7250\n",
      "Epoch 29/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.7086 - acc: 0.8075 - val_loss: 0.7097 - val_acc: 0.7375\n",
      "Epoch 30/170\n",
      "322/322 [==============================] - 0s 322us/sample - loss: 0.7031 - acc: 0.8012 - val_loss: 0.7026 - val_acc: 0.6875\n",
      "Epoch 31/170\n",
      "322/322 [==============================] - 0s 242us/sample - loss: 0.6978 - acc: 0.7391 - val_loss: 0.6946 - val_acc: 0.6500\n",
      "Epoch 32/170\n",
      "322/322 [==============================] - 0s 276us/sample - loss: 0.6923 - acc: 0.7174 - val_loss: 0.6875 - val_acc: 0.6500\n",
      "Epoch 33/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.6850 - acc: 0.7298 - val_loss: 0.6843 - val_acc: 0.7000\n",
      "Epoch 34/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.6763 - acc: 0.8043 - val_loss: 0.6844 - val_acc: 0.7000\n",
      "Epoch 35/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.6659 - acc: 0.8509 - val_loss: 0.6880 - val_acc: 0.7375\n",
      "Epoch 36/170\n",
      "322/322 [==============================] - 0s 297us/sample - loss: 0.6563 - acc: 0.7547 - val_loss: 0.6962 - val_acc: 0.6375\n",
      "Epoch 37/170\n",
      "322/322 [==============================] - 0s 279us/sample - loss: 0.6472 - acc: 0.7205 - val_loss: 0.6890 - val_acc: 0.6875\n",
      "Epoch 38/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.6375 - acc: 0.7391 - val_loss: 0.6783 - val_acc: 0.7375\n",
      "Epoch 39/170\n",
      "322/322 [==============================] - 0s 294us/sample - loss: 0.6276 - acc: 0.8106 - val_loss: 0.6608 - val_acc: 0.7375\n",
      "Epoch 40/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.6184 - acc: 0.8727 - val_loss: 0.6468 - val_acc: 0.7125\n",
      "Epoch 41/170\n",
      "322/322 [==============================] - 0s 269us/sample - loss: 0.6107 - acc: 0.8851 - val_loss: 0.6381 - val_acc: 0.7125\n",
      "Epoch 42/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.6024 - acc: 0.8602 - val_loss: 0.6302 - val_acc: 0.7000\n",
      "Epoch 43/170\n",
      "322/322 [==============================] - 0s 269us/sample - loss: 0.5889 - acc: 0.8789 - val_loss: 0.6325 - val_acc: 0.7375\n",
      "Epoch 44/170\n",
      "322/322 [==============================] - 0s 304us/sample - loss: 0.5768 - acc: 0.8571 - val_loss: 0.6311 - val_acc: 0.7500\n",
      "Epoch 45/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.5650 - acc: 0.8385 - val_loss: 0.6319 - val_acc: 0.7500\n",
      "Epoch 46/170\n",
      "322/322 [==============================] - 0s 248us/sample - loss: 0.5548 - acc: 0.8012 - val_loss: 0.6282 - val_acc: 0.7750\n",
      "Epoch 47/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.5435 - acc: 0.8230 - val_loss: 0.6125 - val_acc: 0.7500\n",
      "Epoch 48/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.5327 - acc: 0.8447 - val_loss: 0.6032 - val_acc: 0.7625\n",
      "Epoch 49/170\n",
      "322/322 [==============================] - 0s 248us/sample - loss: 0.5216 - acc: 0.8416 - val_loss: 0.6006 - val_acc: 0.7500\n",
      "Epoch 50/170\n",
      "322/322 [==============================] - 0s 294us/sample - loss: 0.5113 - acc: 0.8323 - val_loss: 0.5992 - val_acc: 0.7750\n",
      "Epoch 51/170\n",
      "322/322 [==============================] - 0s 300us/sample - loss: 0.5018 - acc: 0.8230 - val_loss: 0.5925 - val_acc: 0.7750\n",
      "Epoch 52/170\n",
      "322/322 [==============================] - 0s 294us/sample - loss: 0.4903 - acc: 0.8354 - val_loss: 0.5725 - val_acc: 0.7875\n",
      "Epoch 53/170\n",
      "322/322 [==============================] - 0s 335us/sample - loss: 0.4801 - acc: 0.8571 - val_loss: 0.5679 - val_acc: 0.7875\n",
      "Epoch 54/170\n",
      "322/322 [==============================] - 0s 322us/sample - loss: 0.4708 - acc: 0.8540 - val_loss: 0.5736 - val_acc: 0.7750\n",
      "Epoch 55/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.4651 - acc: 0.8043 - val_loss: 0.5985 - val_acc: 0.7375\n",
      "Epoch 56/170\n",
      "322/322 [==============================] - 0s 400us/sample - loss: 0.4663 - acc: 0.7516 - val_loss: 0.6056 - val_acc: 0.7000\n",
      "Epoch 57/170\n",
      "322/322 [==============================] - 0s 421us/sample - loss: 0.4639 - acc: 0.7453 - val_loss: 0.5911 - val_acc: 0.7500\n",
      "Epoch 58/170\n",
      "322/322 [==============================] - 0s 418us/sample - loss: 0.4455 - acc: 0.7826 - val_loss: 0.5411 - val_acc: 0.8000\n",
      "Epoch 59/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.4287 - acc: 0.8789 - val_loss: 0.5183 - val_acc: 0.7875\n",
      "Epoch 60/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.4220 - acc: 0.8975 - val_loss: 0.5139 - val_acc: 0.8000\n",
      "Epoch 61/170\n",
      "322/322 [==============================] - 0s 232us/sample - loss: 0.4137 - acc: 0.8913 - val_loss: 0.5111 - val_acc: 0.7875\n",
      "Epoch 62/170\n",
      "322/322 [==============================] - 0s 307us/sample - loss: 0.4078 - acc: 0.8758 - val_loss: 0.5110 - val_acc: 0.8125\n",
      "Epoch 63/170\n",
      "322/322 [==============================] - 0s 223us/sample - loss: 0.3986 - acc: 0.8820 - val_loss: 0.4962 - val_acc: 0.7875\n",
      "Epoch 64/170\n",
      "322/322 [==============================] - 0s 291us/sample - loss: 0.3944 - acc: 0.9099 - val_loss: 0.4811 - val_acc: 0.7875\n",
      "Epoch 65/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.3976 - acc: 0.9255 - val_loss: 0.4755 - val_acc: 0.8250\n",
      "Epoch 66/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.3878 - acc: 0.9255 - val_loss: 0.4753 - val_acc: 0.7500\n",
      "Epoch 67/170\n",
      "322/322 [==============================] - 0s 245us/sample - loss: 0.3746 - acc: 0.9130 - val_loss: 0.4850 - val_acc: 0.8125\n",
      "Epoch 68/170\n",
      "322/322 [==============================] - 0s 279us/sample - loss: 0.3682 - acc: 0.9006 - val_loss: 0.4738 - val_acc: 0.8000\n",
      "Epoch 69/170\n",
      "322/322 [==============================] - 0s 294us/sample - loss: 0.3629 - acc: 0.9068 - val_loss: 0.4624 - val_acc: 0.7750\n",
      "Epoch 70/170\n",
      "322/322 [==============================] - 0s 229us/sample - loss: 0.3579 - acc: 0.9255 - val_loss: 0.4577 - val_acc: 0.7750\n",
      "Epoch 71/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.3522 - acc: 0.9224 - val_loss: 0.4605 - val_acc: 0.8125\n",
      "Epoch 72/170\n",
      "322/322 [==============================] - 0s 246us/sample - loss: 0.3464 - acc: 0.9037 - val_loss: 0.4637 - val_acc: 0.8250\n",
      "Epoch 73/170\n",
      "322/322 [==============================] - 0s 276us/sample - loss: 0.3410 - acc: 0.9006 - val_loss: 0.4561 - val_acc: 0.8250\n",
      "Epoch 74/170\n",
      "322/322 [==============================] - 0s 235us/sample - loss: 0.3345 - acc: 0.9037 - val_loss: 0.4459 - val_acc: 0.8125\n",
      "Epoch 75/170\n",
      "322/322 [==============================] - 0s 226us/sample - loss: 0.3289 - acc: 0.9224 - val_loss: 0.4343 - val_acc: 0.7875\n",
      "Epoch 76/170\n",
      "322/322 [==============================] - 0s 294us/sample - loss: 0.3253 - acc: 0.9317 - val_loss: 0.4294 - val_acc: 0.7875\n",
      "Epoch 77/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.3203 - acc: 0.9348 - val_loss: 0.4259 - val_acc: 0.8000\n",
      "Epoch 78/170\n",
      "322/322 [==============================] - 0s 338us/sample - loss: 0.3142 - acc: 0.9317 - val_loss: 0.4261 - val_acc: 0.8125\n",
      "Epoch 79/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.3083 - acc: 0.9193 - val_loss: 0.4303 - val_acc: 0.8125\n",
      "Epoch 80/170\n",
      "322/322 [==============================] - 0s 265us/sample - loss: 0.3059 - acc: 0.9099 - val_loss: 0.4317 - val_acc: 0.8125\n",
      "Epoch 81/170\n",
      "322/322 [==============================] - 0s 297us/sample - loss: 0.3008 - acc: 0.9099 - val_loss: 0.4135 - val_acc: 0.8125\n",
      "Epoch 82/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.2943 - acc: 0.9348 - val_loss: 0.4063 - val_acc: 0.8500\n",
      "Epoch 83/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.2910 - acc: 0.9379 - val_loss: 0.4088 - val_acc: 0.8250\n",
      "Epoch 84/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.2866 - acc: 0.9255 - val_loss: 0.4155 - val_acc: 0.8125\n",
      "Epoch 85/170\n",
      "322/322 [==============================] - 0s 232us/sample - loss: 0.2883 - acc: 0.9130 - val_loss: 0.4290 - val_acc: 0.8250\n",
      "Epoch 86/170\n",
      "322/322 [==============================] - 0s 232us/sample - loss: 0.2894 - acc: 0.8975 - val_loss: 0.4260 - val_acc: 0.8250\n",
      "Epoch 87/170\n",
      "322/322 [==============================] - 0s 276us/sample - loss: 0.2834 - acc: 0.9099 - val_loss: 0.4098 - val_acc: 0.8125\n",
      "Epoch 88/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.2736 - acc: 0.9255 - val_loss: 0.3961 - val_acc: 0.8250\n",
      "Epoch 89/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.2674 - acc: 0.9317 - val_loss: 0.3854 - val_acc: 0.8625\n",
      "Epoch 90/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.2643 - acc: 0.9410 - val_loss: 0.3814 - val_acc: 0.8500\n",
      "Epoch 91/170\n",
      "322/322 [==============================] - 0s 223us/sample - loss: 0.2596 - acc: 0.9441 - val_loss: 0.3860 - val_acc: 0.8375\n",
      "Epoch 92/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.2608 - acc: 0.9224 - val_loss: 0.3999 - val_acc: 0.8125\n",
      "Epoch 93/170\n",
      "322/322 [==============================] - 0s 276us/sample - loss: 0.2613 - acc: 0.9193 - val_loss: 0.3853 - val_acc: 0.8375\n",
      "Epoch 94/170\n",
      "322/322 [==============================] - 0s 285us/sample - loss: 0.2534 - acc: 0.9317 - val_loss: 0.3702 - val_acc: 0.8625\n",
      "Epoch 95/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.2491 - acc: 0.9565 - val_loss: 0.3668 - val_acc: 0.8875\n",
      "Epoch 96/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.2515 - acc: 0.9596 - val_loss: 0.3657 - val_acc: 0.8625\n",
      "Epoch 97/170\n",
      "322/322 [==============================] - 0s 276us/sample - loss: 0.2467 - acc: 0.9627 - val_loss: 0.3598 - val_acc: 0.8750\n",
      "Epoch 98/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.2374 - acc: 0.9503 - val_loss: 0.3652 - val_acc: 0.8625\n",
      "Epoch 99/170\n",
      "322/322 [==============================] - 0s 325us/sample - loss: 0.2385 - acc: 0.9286 - val_loss: 0.3783 - val_acc: 0.8250\n",
      "Epoch 100/170\n",
      "322/322 [==============================] - 0s 300us/sample - loss: 0.2418 - acc: 0.9255 - val_loss: 0.3746 - val_acc: 0.8375\n",
      "Epoch 101/170\n",
      "322/322 [==============================] - 0s 226us/sample - loss: 0.2356 - acc: 0.9255 - val_loss: 0.3602 - val_acc: 0.8625\n",
      "Epoch 102/170\n",
      "322/322 [==============================] - 0s 226us/sample - loss: 0.2272 - acc: 0.9379 - val_loss: 0.3495 - val_acc: 0.8750\n",
      "Epoch 103/170\n",
      "322/322 [==============================] - 0s 285us/sample - loss: 0.2230 - acc: 0.9565 - val_loss: 0.3461 - val_acc: 0.8875\n",
      "Epoch 104/170\n",
      "322/322 [==============================] - 0s 400us/sample - loss: 0.2200 - acc: 0.9596 - val_loss: 0.3431 - val_acc: 0.8875\n",
      "Epoch 105/170\n",
      "322/322 [==============================] - 0s 371us/sample - loss: 0.2179 - acc: 0.9565 - val_loss: 0.3414 - val_acc: 0.8750\n",
      "Epoch 106/170\n",
      "322/322 [==============================] - 0s 304us/sample - loss: 0.2176 - acc: 0.9658 - val_loss: 0.3412 - val_acc: 0.8875\n",
      "Epoch 107/170\n",
      "322/322 [==============================] - 0s 269us/sample - loss: 0.2161 - acc: 0.9689 - val_loss: 0.3380 - val_acc: 0.8875\n",
      "Epoch 108/170\n",
      "322/322 [==============================] - 0s 347us/sample - loss: 0.2119 - acc: 0.9658 - val_loss: 0.3348 - val_acc: 0.8875\n",
      "Epoch 109/170\n",
      "322/322 [==============================] - 0s 242us/sample - loss: 0.2072 - acc: 0.9596 - val_loss: 0.3338 - val_acc: 0.9000\n",
      "Epoch 110/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.2056 - acc: 0.9596 - val_loss: 0.3325 - val_acc: 0.9000\n",
      "Epoch 111/170\n",
      "322/322 [==============================] - 0s 238us/sample - loss: 0.2025 - acc: 0.9596 - val_loss: 0.3285 - val_acc: 0.9000\n",
      "Epoch 112/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.2004 - acc: 0.9596 - val_loss: 0.3264 - val_acc: 0.9000\n",
      "Epoch 113/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.1985 - acc: 0.9627 - val_loss: 0.3246 - val_acc: 0.9000\n",
      "Epoch 114/170\n",
      "322/322 [==============================] - 0s 289us/sample - loss: 0.1963 - acc: 0.9627 - val_loss: 0.3227 - val_acc: 0.9000\n",
      "Epoch 115/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.1938 - acc: 0.9596 - val_loss: 0.3219 - val_acc: 0.9000\n",
      "Epoch 116/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.1918 - acc: 0.9596 - val_loss: 0.3244 - val_acc: 0.8750\n",
      "Epoch 117/170\n",
      "322/322 [==============================] - 0s 309us/sample - loss: 0.1922 - acc: 0.9534 - val_loss: 0.3250 - val_acc: 0.8750\n",
      "Epoch 118/170\n",
      "322/322 [==============================] - 0s 245us/sample - loss: 0.1916 - acc: 0.9441 - val_loss: 0.3243 - val_acc: 0.8750\n",
      "Epoch 119/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 251us/sample - loss: 0.1892 - acc: 0.9503 - val_loss: 0.3194 - val_acc: 0.8750\n",
      "Epoch 120/170\n",
      "322/322 [==============================] - 0s 248us/sample - loss: 0.1847 - acc: 0.9596 - val_loss: 0.3145 - val_acc: 0.9125\n",
      "Epoch 121/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.1822 - acc: 0.9596 - val_loss: 0.3125 - val_acc: 0.9000\n",
      "Epoch 122/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.1802 - acc: 0.9596 - val_loss: 0.3115 - val_acc: 0.9125\n",
      "Epoch 123/170\n",
      "322/322 [==============================] - 0s 260us/sample - loss: 0.1784 - acc: 0.9596 - val_loss: 0.3108 - val_acc: 0.9000\n",
      "Epoch 124/170\n",
      "322/322 [==============================] - 0s 288us/sample - loss: 0.1767 - acc: 0.9596 - val_loss: 0.3087 - val_acc: 0.9125\n",
      "Epoch 125/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.1754 - acc: 0.9596 - val_loss: 0.3085 - val_acc: 0.9000\n",
      "Epoch 126/170\n",
      "322/322 [==============================] - 0s 248us/sample - loss: 0.1741 - acc: 0.9596 - val_loss: 0.3075 - val_acc: 0.9000\n",
      "Epoch 127/170\n",
      "322/322 [==============================] - 0s 255us/sample - loss: 0.1731 - acc: 0.9596 - val_loss: 0.3057 - val_acc: 0.9000\n",
      "Epoch 128/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.1695 - acc: 0.9627 - val_loss: 0.3029 - val_acc: 0.8875\n",
      "Epoch 129/170\n",
      "322/322 [==============================] - 0s 288us/sample - loss: 0.1684 - acc: 0.9752 - val_loss: 0.3028 - val_acc: 0.8875\n",
      "Epoch 130/170\n",
      "322/322 [==============================] - 0s 254us/sample - loss: 0.1673 - acc: 0.9814 - val_loss: 0.3009 - val_acc: 0.8875\n",
      "Epoch 131/170\n",
      "322/322 [==============================] - 0s 300us/sample - loss: 0.1646 - acc: 0.9720 - val_loss: 0.2984 - val_acc: 0.9000\n",
      "Epoch 132/170\n",
      "322/322 [==============================] - 0s 310us/sample - loss: 0.1629 - acc: 0.9658 - val_loss: 0.2973 - val_acc: 0.9125\n",
      "Epoch 133/170\n",
      "322/322 [==============================] - 0s 307us/sample - loss: 0.1620 - acc: 0.9627 - val_loss: 0.2965 - val_acc: 0.9125\n",
      "Epoch 134/170\n",
      "322/322 [==============================] - 0s 294us/sample - loss: 0.1602 - acc: 0.9627 - val_loss: 0.2955 - val_acc: 0.9125\n",
      "Epoch 135/170\n",
      "322/322 [==============================] - 0s 288us/sample - loss: 0.1598 - acc: 0.9627 - val_loss: 0.2979 - val_acc: 0.9000\n",
      "Epoch 136/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.1605 - acc: 0.9627 - val_loss: 0.2976 - val_acc: 0.9000\n",
      "Epoch 137/170\n",
      "322/322 [==============================] - 0s 246us/sample - loss: 0.1591 - acc: 0.9627 - val_loss: 0.2949 - val_acc: 0.9000\n",
      "Epoch 138/170\n",
      "322/322 [==============================] - 0s 220us/sample - loss: 0.1556 - acc: 0.9627 - val_loss: 0.2915 - val_acc: 0.9000\n",
      "Epoch 139/170\n",
      "322/322 [==============================] - 0s 245us/sample - loss: 0.1535 - acc: 0.9783 - val_loss: 0.2971 - val_acc: 0.8875\n",
      "Epoch 140/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.1549 - acc: 0.9845 - val_loss: 0.2985 - val_acc: 0.8750\n",
      "Epoch 141/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.1532 - acc: 0.9845 - val_loss: 0.2927 - val_acc: 0.8750\n",
      "Epoch 142/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.1497 - acc: 0.9845 - val_loss: 0.2904 - val_acc: 0.8875\n",
      "Epoch 143/170\n",
      "322/322 [==============================] - 0s 288us/sample - loss: 0.1480 - acc: 0.9814 - val_loss: 0.2879 - val_acc: 0.9000\n",
      "Epoch 144/170\n",
      "322/322 [==============================] - 0s 242us/sample - loss: 0.1461 - acc: 0.9783 - val_loss: 0.2858 - val_acc: 0.9125\n",
      "Epoch 145/170\n",
      "322/322 [==============================] - 0s 223us/sample - loss: 0.1466 - acc: 0.9689 - val_loss: 0.2892 - val_acc: 0.9000\n",
      "Epoch 146/170\n",
      "322/322 [==============================] - 0s 232us/sample - loss: 0.1481 - acc: 0.9596 - val_loss: 0.2898 - val_acc: 0.8875\n",
      "Epoch 147/170\n",
      "322/322 [==============================] - 0s 276us/sample - loss: 0.1461 - acc: 0.9627 - val_loss: 0.2842 - val_acc: 0.9125\n",
      "Epoch 148/170\n",
      "322/322 [==============================] - 0s 245us/sample - loss: 0.1420 - acc: 0.9783 - val_loss: 0.2891 - val_acc: 0.8875\n",
      "Epoch 149/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.1429 - acc: 0.9876 - val_loss: 0.2942 - val_acc: 0.8625\n",
      "Epoch 150/170\n",
      "322/322 [==============================] - 0s 322us/sample - loss: 0.1433 - acc: 0.9876 - val_loss: 0.2878 - val_acc: 0.8875\n",
      "Epoch 151/170\n",
      "322/322 [==============================] - 0s 372us/sample - loss: 0.1393 - acc: 0.9876 - val_loss: 0.2826 - val_acc: 0.8875\n",
      "Epoch 152/170\n",
      "322/322 [==============================] - 0s 502us/sample - loss: 0.1373 - acc: 0.9814 - val_loss: 0.2795 - val_acc: 0.9000\n",
      "Epoch 153/170\n",
      "322/322 [==============================] - 0s 291us/sample - loss: 0.1367 - acc: 0.9752 - val_loss: 0.2799 - val_acc: 0.9125\n",
      "Epoch 154/170\n",
      "322/322 [==============================] - 0s 297us/sample - loss: 0.1376 - acc: 0.9689 - val_loss: 0.2835 - val_acc: 0.9000\n",
      "Epoch 155/170\n",
      "322/322 [==============================] - 0s 242us/sample - loss: 0.1391 - acc: 0.9596 - val_loss: 0.2844 - val_acc: 0.9000\n",
      "Epoch 156/170\n",
      "322/322 [==============================] - 0s 226us/sample - loss: 0.1373 - acc: 0.9627 - val_loss: 0.2796 - val_acc: 0.9125\n",
      "Epoch 157/170\n",
      "322/322 [==============================] - 0s 245us/sample - loss: 0.1326 - acc: 0.9752 - val_loss: 0.2757 - val_acc: 0.9125\n",
      "Epoch 158/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.1292 - acc: 0.9814 - val_loss: 0.2788 - val_acc: 0.8875\n",
      "Epoch 159/170\n",
      "322/322 [==============================] - 0s 282us/sample - loss: 0.1313 - acc: 0.9845 - val_loss: 0.2915 - val_acc: 0.8750\n",
      "Epoch 160/170\n",
      "322/322 [==============================] - 0s 235us/sample - loss: 0.1320 - acc: 0.9876 - val_loss: 0.2823 - val_acc: 0.8875\n",
      "Epoch 161/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.1282 - acc: 0.9845 - val_loss: 0.2753 - val_acc: 0.8750\n",
      "Epoch 162/170\n",
      "322/322 [==============================] - 0s 257us/sample - loss: 0.1265 - acc: 0.9814 - val_loss: 0.2733 - val_acc: 0.9125\n",
      "Epoch 163/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.1254 - acc: 0.9814 - val_loss: 0.2727 - val_acc: 0.9125\n",
      "Epoch 164/170\n",
      "322/322 [==============================] - 0s 365us/sample - loss: 0.1247 - acc: 0.9814 - val_loss: 0.2725 - val_acc: 0.9125\n",
      "Epoch 165/170\n",
      "322/322 [==============================] - 0s 273us/sample - loss: 0.1233 - acc: 0.9814 - val_loss: 0.2721 - val_acc: 0.9125\n",
      "Epoch 166/170\n",
      "322/322 [==============================] - 0s 269us/sample - loss: 0.1226 - acc: 0.9814 - val_loss: 0.2724 - val_acc: 0.8750\n",
      "Epoch 167/170\n",
      "322/322 [==============================] - 0s 251us/sample - loss: 0.1216 - acc: 0.9814 - val_loss: 0.2717 - val_acc: 0.8750\n",
      "Epoch 168/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.1210 - acc: 0.9814 - val_loss: 0.2702 - val_acc: 0.9125\n",
      "Epoch 169/170\n",
      "322/322 [==============================] - 0s 263us/sample - loss: 0.1201 - acc: 0.9814 - val_loss: 0.2695 - val_acc: 0.9125\n",
      "Epoch 170/170\n",
      "322/322 [==============================] - 0s 266us/sample - loss: 0.1189 - acc: 0.9814 - val_loss: 0.2692 - val_acc: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47  4]\n",
      " [ 6 23]]\n",
      "None\n",
      "(0.8518518518518519, 0.875, 0.7931034482758621, 0.8214285714285715, 0.9716024340770791, 0.9534158462540174, 0.9526103172063547)\n",
      "Cross validated results :  ACC = 0.9004938271604939, REC = 0.90935960591133, F1 = 0.8661303637403724, AUC = 0.9657395849586518, AUPR =0.9531595736064723\n"
     ]
    }
   ],
   "source": [
    "#Five-fold cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=1029) \n",
    "\n",
    "kfscore = []\n",
    "p = 0\n",
    "for train_index, test_index in skf.split(snv_data.values,y):\n",
    "\n",
    "    snv_train_x = snv_data.values[train_index]\n",
    "    snv_test_x  = snv_data.values[test_index]\n",
    "\n",
    "    mRNA_train_x = mRNA_data.values[train_index]\n",
    "    mRNA_test_x  = mRNA_data.values[test_index]\n",
    "\n",
    "    miRNA_train_x = miRNA_data.values[train_index]\n",
    "    miRNA_test_x  = miRNA_data.values[test_index]\n",
    "\n",
    "    train_y  = y[train_index]\n",
    "    test_y   = y[test_index]\n",
    "\n",
    "    model = create_model(snv_data,mRNA_data,miRNA_data)\n",
    "    model.fit( {\"snv_inputs\": snv_train_x,  \"mRNA_inputs\": mRNA_train_x, 'miRNA_inputs':miRNA_train_x},train_y,\n",
    "                 validation_data=({\"snv_inputs\": snv_test_x, \"mRNA_inputs\": mRNA_test_x,'miRNA_inputs':miRNA_test_x},test_y),\n",
    "                 epochs=170,batch_size = 64,class_weight = {0:x_0,1:x_1})  \n",
    "\n",
    "    y_pred = model.predict({\"snv_inputs\": snv_test_x, \"mRNA_inputs\": mRNA_test_x,'miRNA_inputs':miRNA_test_x})\n",
    "\n",
    "    y_score = [1 if index>=0.5  else 0 for index in  y_pred]\n",
    "\n",
    "    evaluate_epoch = get_metrics(test_y,y_score,y_pred)\n",
    "    print(evaluate_epoch)\n",
    "#     get_weigjts(model,p)\n",
    "#     p = p + 1\n",
    "    kfscore.append(evaluate_epoch)\n",
    "    \n",
    "results = list(np.array(kfscore).sum(axis= 0)/5.0)\n",
    "print('Cross validated results :  ACC = {}, REC = {}, F1 = {}, AUC = {}, AUPR ={}'.format(results[1],results[2],results[3],results[4],results[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d19c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance\n",
    "#The average results of the five-fold crossover experiments\n",
    "\n",
    "import pandas as pd\n",
    "dirs_paths = './coef_weight/BLCA'\n",
    "dirs_genes = ['snv.csv','mRNA.csv','miRNA.csv']\n",
    "dirs = ['h0','h1','h2','h3','h4']\n",
    "\n",
    "for i in range(0,3):\n",
    "    t_gene_data = pd.DataFrame()\n",
    "    for j in dirs:\n",
    "        print(dirs_paths+'\\\\'+j+'\\\\'+dirs_genes[i])\n",
    "        genes_data = pd.read_csv(dirs_paths+'\\\\'+j+'\\\\'+dirs_genes[i])\n",
    "        t_gene_data = t_gene_data.append(genes_data)\n",
    "    temp_gene = t_gene_data.groupby('genes').mean().sort_values('values',ascending=False)\n",
    "    temp_gene.to_csv(dirs_paths+'\\\\average\\\\average_'+dirs_genes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21bd915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_single_model(inputs,omics_id):\n",
    "   \n",
    "    \n",
    "    S_inputs = Input(shape=(inputs.shape[1],), dtype='float32')\n",
    "    \n",
    "\n",
    "\n",
    "    h0 = Biological_module(gene_pathway_bp_dfs[omics_id].shape[0],mapp =gene_pathway_bp_dfs[omics_id].values.T,W_regularizer=l2(0.001))(S_inputs)\n",
    "    \n",
    "\n",
    "    atten1 = Self_Attention(64,W_regularizer=l2(0.001))(h0)\n",
    "    \n",
    "    h4 = tf.keras.layers.Dense(32,activation='tanh')(atten1)\n",
    "    \n",
    "    h5 = tf.keras.layers.Dense(1,activation='sigmoid')(h4)\n",
    "\n",
    "    model = Model(inputs=S_inputs, outputs=h5)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 0.0001,decay=0.0001) #,decay=-0.0001\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d64920d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1000)]            0         \n",
      "                                                                 \n",
      " biological_module (Biologic  (None, 238)              3170      \n",
      " al_module)                                                      \n",
      "                                                                 \n",
      " self__attention_18 (Self_At  (None, 64)               45696     \n",
      " tention)                                                        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,979\n",
      "Trainable params: 50,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/170\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "1/6 [====>.........................] - ETA: 4s - loss: 0.7679 - acc: 0.5625WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "6/6 [==============================] - 1s 73ms/step - loss: 0.7315 - acc: 0.4050 - val_loss: 0.7308 - val_acc: 0.5432\n",
      "Epoch 2/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7301 - acc: 0.5919 - val_loss: 0.7292 - val_acc: 0.6420\n",
      "Epoch 3/170\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7288 - acc: 0.6449 - val_loss: 0.7277 - val_acc: 0.6420\n",
      "Epoch 4/170\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7275 - acc: 0.6449 - val_loss: 0.7262 - val_acc: 0.6420\n",
      "Epoch 5/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7262 - acc: 0.6449 - val_loss: 0.7248 - val_acc: 0.6420\n",
      "Epoch 6/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7250 - acc: 0.6449 - val_loss: 0.7237 - val_acc: 0.6420\n",
      "Epoch 7/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7238 - acc: 0.6449 - val_loss: 0.7225 - val_acc: 0.6420\n",
      "Epoch 8/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7227 - acc: 0.6449 - val_loss: 0.7212 - val_acc: 0.6420\n",
      "Epoch 9/170\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7216 - acc: 0.6449 - val_loss: 0.7199 - val_acc: 0.6420\n",
      "Epoch 10/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7205 - acc: 0.6449 - val_loss: 0.7186 - val_acc: 0.6420\n",
      "Epoch 11/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7194 - acc: 0.6449 - val_loss: 0.7174 - val_acc: 0.6420\n",
      "Epoch 12/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7184 - acc: 0.6449 - val_loss: 0.7165 - val_acc: 0.6420\n",
      "Epoch 13/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7174 - acc: 0.6449 - val_loss: 0.7157 - val_acc: 0.6420\n",
      "Epoch 14/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7164 - acc: 0.6449 - val_loss: 0.7147 - val_acc: 0.6420\n",
      "Epoch 15/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7154 - acc: 0.6449 - val_loss: 0.7137 - val_acc: 0.6420\n",
      "Epoch 16/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7145 - acc: 0.6449 - val_loss: 0.7129 - val_acc: 0.6420\n",
      "Epoch 17/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7135 - acc: 0.6480 - val_loss: 0.7123 - val_acc: 0.6420\n",
      "Epoch 18/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7126 - acc: 0.6511 - val_loss: 0.7117 - val_acc: 0.6420\n",
      "Epoch 19/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7116 - acc: 0.6604 - val_loss: 0.7108 - val_acc: 0.6420\n",
      "Epoch 20/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7106 - acc: 0.6822 - val_loss: 0.7101 - val_acc: 0.6420\n",
      "Epoch 21/170\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7096 - acc: 0.7414 - val_loss: 0.7094 - val_acc: 0.7654\n",
      "Epoch 22/170\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7086 - acc: 0.7944 - val_loss: 0.7084 - val_acc: 0.7531\n",
      "Epoch 23/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7075 - acc: 0.8131 - val_loss: 0.7071 - val_acc: 0.7531\n",
      "Epoch 24/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7062 - acc: 0.7882 - val_loss: 0.7058 - val_acc: 0.7037\n",
      "Epoch 25/170\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7048 - acc: 0.8069 - val_loss: 0.7048 - val_acc: 0.7531\n",
      "Epoch 26/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7034 - acc: 0.8224 - val_loss: 0.7039 - val_acc: 0.7778\n",
      "Epoch 27/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7019 - acc: 0.8037 - val_loss: 0.7031 - val_acc: 0.7284\n",
      "Epoch 28/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7003 - acc: 0.8037 - val_loss: 0.7016 - val_acc: 0.7284\n",
      "Epoch 29/170\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.6984 - acc: 0.8100 - val_loss: 0.6997 - val_acc: 0.7654\n",
      "Epoch 30/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6963 - acc: 0.8193 - val_loss: 0.6975 - val_acc: 0.7778\n",
      "Epoch 31/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6941 - acc: 0.8287 - val_loss: 0.6947 - val_acc: 0.7901\n",
      "Epoch 32/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6914 - acc: 0.8536 - val_loss: 0.6915 - val_acc: 0.7778\n",
      "Epoch 33/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6884 - acc: 0.8474 - val_loss: 0.6879 - val_acc: 0.7407\n",
      "Epoch 34/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6850 - acc: 0.7882 - val_loss: 0.6840 - val_acc: 0.7037\n",
      "Epoch 35/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6815 - acc: 0.7695 - val_loss: 0.6800 - val_acc: 0.6914\n",
      "Epoch 36/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6780 - acc: 0.7757 - val_loss: 0.6774 - val_acc: 0.7037\n",
      "Epoch 37/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6744 - acc: 0.7788 - val_loss: 0.6734 - val_acc: 0.7037\n",
      "Epoch 38/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6701 - acc: 0.7788 - val_loss: 0.6686 - val_acc: 0.7037\n",
      "Epoch 39/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6652 - acc: 0.7695 - val_loss: 0.6635 - val_acc: 0.7037\n",
      "Epoch 40/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6610 - acc: 0.7695 - val_loss: 0.6586 - val_acc: 0.6914\n",
      "Epoch 41/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6566 - acc: 0.7695 - val_loss: 0.6571 - val_acc: 0.7037\n",
      "Epoch 42/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6529 - acc: 0.8069 - val_loss: 0.6561 - val_acc: 0.7531\n",
      "Epoch 43/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6488 - acc: 0.8692 - val_loss: 0.6545 - val_acc: 0.8025\n",
      "Epoch 44/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6442 - acc: 0.8598 - val_loss: 0.6513 - val_acc: 0.8148\n",
      "Epoch 45/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6393 - acc: 0.8723 - val_loss: 0.6468 - val_acc: 0.8272\n",
      "Epoch 46/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6338 - acc: 0.8723 - val_loss: 0.6418 - val_acc: 0.8272\n",
      "Epoch 47/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6277 - acc: 0.8723 - val_loss: 0.6382 - val_acc: 0.8395\n",
      "Epoch 48/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6211 - acc: 0.8816 - val_loss: 0.6330 - val_acc: 0.8395\n",
      "Epoch 49/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6140 - acc: 0.8879 - val_loss: 0.6273 - val_acc: 0.8395\n",
      "Epoch 50/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6071 - acc: 0.8910 - val_loss: 0.6216 - val_acc: 0.8395\n",
      "Epoch 51/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6000 - acc: 0.9034 - val_loss: 0.6183 - val_acc: 0.8519\n",
      "Epoch 52/170\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5920 - acc: 0.8847 - val_loss: 0.6160 - val_acc: 0.8025\n",
      "Epoch 53/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5840 - acc: 0.8629 - val_loss: 0.6143 - val_acc: 0.7778\n",
      "Epoch 54/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5761 - acc: 0.8505 - val_loss: 0.6105 - val_acc: 0.7901\n",
      "Epoch 55/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5687 - acc: 0.8349 - val_loss: 0.6078 - val_acc: 0.7407\n",
      "Epoch 56/170\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5609 - acc: 0.8224 - val_loss: 0.6022 - val_acc: 0.7407\n",
      "Epoch 57/170\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5539 - acc: 0.8380 - val_loss: 0.5954 - val_acc: 0.7901\n",
      "Epoch 58/170\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5464 - acc: 0.8505 - val_loss: 0.5882 - val_acc: 0.8148\n",
      "Epoch 59/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5395 - acc: 0.8629 - val_loss: 0.5803 - val_acc: 0.8025\n",
      "Epoch 60/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5323 - acc: 0.8754 - val_loss: 0.5736 - val_acc: 0.8025\n",
      "Epoch 61/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5245 - acc: 0.8785 - val_loss: 0.5711 - val_acc: 0.8272\n",
      "Epoch 62/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5166 - acc: 0.8567 - val_loss: 0.5701 - val_acc: 0.7901\n",
      "Epoch 63/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5092 - acc: 0.8474 - val_loss: 0.5667 - val_acc: 0.7901\n",
      "Epoch 64/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5012 - acc: 0.8318 - val_loss: 0.5647 - val_acc: 0.7407\n",
      "Epoch 65/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4941 - acc: 0.8224 - val_loss: 0.5603 - val_acc: 0.7407\n",
      "Epoch 66/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4864 - acc: 0.8193 - val_loss: 0.5571 - val_acc: 0.7407\n",
      "Epoch 67/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4791 - acc: 0.8224 - val_loss: 0.5517 - val_acc: 0.7407\n",
      "Epoch 68/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4718 - acc: 0.8193 - val_loss: 0.5494 - val_acc: 0.7407\n",
      "Epoch 69/170\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.4648 - acc: 0.8193 - val_loss: 0.5433 - val_acc: 0.7407\n",
      "Epoch 70/170\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.4579 - acc: 0.8255 - val_loss: 0.5346 - val_acc: 0.7778\n",
      "Epoch 71/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4512 - acc: 0.8442 - val_loss: 0.5256 - val_acc: 0.8395\n",
      "Epoch 72/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4449 - acc: 0.8598 - val_loss: 0.5162 - val_acc: 0.8395\n",
      "Epoch 73/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4386 - acc: 0.8879 - val_loss: 0.5088 - val_acc: 0.8025\n",
      "Epoch 74/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4325 - acc: 0.8910 - val_loss: 0.5072 - val_acc: 0.8395\n",
      "Epoch 75/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4256 - acc: 0.8660 - val_loss: 0.5092 - val_acc: 0.8272\n",
      "Epoch 76/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4196 - acc: 0.8536 - val_loss: 0.5113 - val_acc: 0.7778\n",
      "Epoch 77/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4136 - acc: 0.8411 - val_loss: 0.5072 - val_acc: 0.7778\n",
      "Epoch 78/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4075 - acc: 0.8442 - val_loss: 0.5012 - val_acc: 0.7778\n",
      "Epoch 79/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4013 - acc: 0.8567 - val_loss: 0.4976 - val_acc: 0.7778\n",
      "Epoch 80/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3955 - acc: 0.8567 - val_loss: 0.4912 - val_acc: 0.8148\n",
      "Epoch 81/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3895 - acc: 0.8629 - val_loss: 0.4840 - val_acc: 0.8272\n",
      "Epoch 82/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3837 - acc: 0.8692 - val_loss: 0.4817 - val_acc: 0.8272\n",
      "Epoch 83/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3786 - acc: 0.8692 - val_loss: 0.4774 - val_acc: 0.8272\n",
      "Epoch 84/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3736 - acc: 0.8692 - val_loss: 0.4712 - val_acc: 0.8395\n",
      "Epoch 85/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3684 - acc: 0.8723 - val_loss: 0.4695 - val_acc: 0.8395\n",
      "Epoch 86/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3632 - acc: 0.8754 - val_loss: 0.4632 - val_acc: 0.8272\n",
      "Epoch 87/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3584 - acc: 0.8785 - val_loss: 0.4535 - val_acc: 0.8272\n",
      "Epoch 88/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3537 - acc: 0.9065 - val_loss: 0.4456 - val_acc: 0.8395\n",
      "Epoch 89/170\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3500 - acc: 0.9159 - val_loss: 0.4411 - val_acc: 0.8642\n",
      "Epoch 90/170\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3455 - acc: 0.9159 - val_loss: 0.4364 - val_acc: 0.8765\n",
      "Epoch 91/170\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.3410 - acc: 0.9159 - val_loss: 0.4331 - val_acc: 0.8765\n",
      "Epoch 92/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3367 - acc: 0.9159 - val_loss: 0.4301 - val_acc: 0.8765\n",
      "Epoch 93/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3324 - acc: 0.9159 - val_loss: 0.4265 - val_acc: 0.8642\n",
      "Epoch 94/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3282 - acc: 0.9159 - val_loss: 0.4229 - val_acc: 0.8642\n",
      "Epoch 95/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3240 - acc: 0.9190 - val_loss: 0.4196 - val_acc: 0.8642\n",
      "Epoch 96/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3195 - acc: 0.9159 - val_loss: 0.4215 - val_acc: 0.8519\n",
      "Epoch 97/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3157 - acc: 0.9128 - val_loss: 0.4257 - val_acc: 0.8272\n",
      "Epoch 98/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3113 - acc: 0.8910 - val_loss: 0.4271 - val_acc: 0.8272\n",
      "Epoch 99/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3075 - acc: 0.8847 - val_loss: 0.4245 - val_acc: 0.8272\n",
      "Epoch 100/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3039 - acc: 0.8879 - val_loss: 0.4217 - val_acc: 0.8272\n",
      "Epoch 101/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2998 - acc: 0.8910 - val_loss: 0.4137 - val_acc: 0.8148\n",
      "Epoch 102/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2955 - acc: 0.9034 - val_loss: 0.4082 - val_acc: 0.8272\n",
      "Epoch 103/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2919 - acc: 0.9065 - val_loss: 0.4048 - val_acc: 0.8395\n",
      "Epoch 104/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2884 - acc: 0.9097 - val_loss: 0.4024 - val_acc: 0.8395\n",
      "Epoch 105/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2851 - acc: 0.9065 - val_loss: 0.4009 - val_acc: 0.8395\n",
      "Epoch 106/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2818 - acc: 0.9065 - val_loss: 0.3984 - val_acc: 0.8395\n",
      "Epoch 107/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2787 - acc: 0.9065 - val_loss: 0.3962 - val_acc: 0.8395\n",
      "Epoch 108/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2757 - acc: 0.9065 - val_loss: 0.3983 - val_acc: 0.8148\n",
      "Epoch 109/170\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2729 - acc: 0.9034 - val_loss: 0.3922 - val_acc: 0.8395\n",
      "Epoch 110/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2688 - acc: 0.9097 - val_loss: 0.3838 - val_acc: 0.8642\n",
      "Epoch 111/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2659 - acc: 0.9252 - val_loss: 0.3782 - val_acc: 0.8765\n",
      "Epoch 112/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2632 - acc: 0.9346 - val_loss: 0.3726 - val_acc: 0.8765\n",
      "Epoch 113/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2606 - acc: 0.9377 - val_loss: 0.3687 - val_acc: 0.8765\n",
      "Epoch 114/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2583 - acc: 0.9346 - val_loss: 0.3658 - val_acc: 0.8765\n",
      "Epoch 115/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2555 - acc: 0.9377 - val_loss: 0.3640 - val_acc: 0.8765\n",
      "Epoch 116/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2525 - acc: 0.9377 - val_loss: 0.3638 - val_acc: 0.8642\n",
      "Epoch 117/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2492 - acc: 0.9408 - val_loss: 0.3637 - val_acc: 0.8765\n",
      "Epoch 118/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2462 - acc: 0.9346 - val_loss: 0.3632 - val_acc: 0.8765\n",
      "Epoch 119/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2436 - acc: 0.9346 - val_loss: 0.3604 - val_acc: 0.8765\n",
      "Epoch 120/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2411 - acc: 0.9408 - val_loss: 0.3577 - val_acc: 0.8765\n",
      "Epoch 121/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2388 - acc: 0.9408 - val_loss: 0.3545 - val_acc: 0.8765\n",
      "Epoch 122/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2364 - acc: 0.9377 - val_loss: 0.3510 - val_acc: 0.8642\n",
      "Epoch 123/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2345 - acc: 0.9377 - val_loss: 0.3493 - val_acc: 0.8642\n",
      "Epoch 124/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2321 - acc: 0.9408 - val_loss: 0.3481 - val_acc: 0.8765\n",
      "Epoch 125/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2298 - acc: 0.9408 - val_loss: 0.3463 - val_acc: 0.8765\n",
      "Epoch 126/170\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2272 - acc: 0.9439 - val_loss: 0.3463 - val_acc: 0.8765\n",
      "Epoch 127/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2245 - acc: 0.9470 - val_loss: 0.3466 - val_acc: 0.8765\n",
      "Epoch 128/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2219 - acc: 0.9470 - val_loss: 0.3480 - val_acc: 0.8765\n",
      "Epoch 129/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2201 - acc: 0.9439 - val_loss: 0.3481 - val_acc: 0.8765\n",
      "Epoch 130/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2180 - acc: 0.9408 - val_loss: 0.3484 - val_acc: 0.8765\n",
      "Epoch 131/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2172 - acc: 0.9408 - val_loss: 0.3541 - val_acc: 0.8642\n",
      "Epoch 132/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2155 - acc: 0.9377 - val_loss: 0.3493 - val_acc: 0.8765\n",
      "Epoch 133/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2129 - acc: 0.9408 - val_loss: 0.3423 - val_acc: 0.8765\n",
      "Epoch 134/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2099 - acc: 0.9470 - val_loss: 0.3380 - val_acc: 0.8765\n",
      "Epoch 135/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2082 - acc: 0.9439 - val_loss: 0.3350 - val_acc: 0.8765\n",
      "Epoch 136/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2062 - acc: 0.9439 - val_loss: 0.3366 - val_acc: 0.8765\n",
      "Epoch 137/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2043 - acc: 0.9470 - val_loss: 0.3378 - val_acc: 0.8765\n",
      "Epoch 138/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2028 - acc: 0.9439 - val_loss: 0.3410 - val_acc: 0.8765\n",
      "Epoch 139/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2016 - acc: 0.9439 - val_loss: 0.3427 - val_acc: 0.8765\n",
      "Epoch 140/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2005 - acc: 0.9439 - val_loss: 0.3420 - val_acc: 0.8765\n",
      "Epoch 141/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1988 - acc: 0.9439 - val_loss: 0.3403 - val_acc: 0.8765\n",
      "Epoch 142/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1978 - acc: 0.9439 - val_loss: 0.3432 - val_acc: 0.8519\n",
      "Epoch 143/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1967 - acc: 0.9439 - val_loss: 0.3446 - val_acc: 0.8395\n",
      "Epoch 144/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1958 - acc: 0.9377 - val_loss: 0.3445 - val_acc: 0.8395\n",
      "Epoch 145/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1940 - acc: 0.9439 - val_loss: 0.3423 - val_acc: 0.8519\n",
      "Epoch 146/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1925 - acc: 0.9439 - val_loss: 0.3391 - val_acc: 0.8519\n",
      "Epoch 147/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1893 - acc: 0.9439 - val_loss: 0.3267 - val_acc: 0.8765\n",
      "Epoch 148/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1854 - acc: 0.9502 - val_loss: 0.3198 - val_acc: 0.8765\n",
      "Epoch 149/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1850 - acc: 0.9502 - val_loss: 0.3168 - val_acc: 0.8765\n",
      "Epoch 150/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1840 - acc: 0.9502 - val_loss: 0.3155 - val_acc: 0.8889\n",
      "Epoch 151/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1828 - acc: 0.9502 - val_loss: 0.3145 - val_acc: 0.8765\n",
      "Epoch 152/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1827 - acc: 0.9533 - val_loss: 0.3124 - val_acc: 0.8642\n",
      "Epoch 153/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1822 - acc: 0.9564 - val_loss: 0.3116 - val_acc: 0.8642\n",
      "Epoch 154/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1807 - acc: 0.9564 - val_loss: 0.3111 - val_acc: 0.8642\n",
      "Epoch 155/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1787 - acc: 0.9564 - val_loss: 0.3111 - val_acc: 0.8765\n",
      "Epoch 156/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1767 - acc: 0.9533 - val_loss: 0.3120 - val_acc: 0.8765\n",
      "Epoch 157/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1746 - acc: 0.9502 - val_loss: 0.3143 - val_acc: 0.8765\n",
      "Epoch 158/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1733 - acc: 0.9502 - val_loss: 0.3157 - val_acc: 0.8765\n",
      "Epoch 159/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1722 - acc: 0.9533 - val_loss: 0.3152 - val_acc: 0.8765\n",
      "Epoch 160/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1712 - acc: 0.9533 - val_loss: 0.3139 - val_acc: 0.8765\n",
      "Epoch 161/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1699 - acc: 0.9533 - val_loss: 0.3114 - val_acc: 0.8765\n",
      "Epoch 162/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1697 - acc: 0.9502 - val_loss: 0.3065 - val_acc: 0.8642\n",
      "Epoch 163/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1692 - acc: 0.9595 - val_loss: 0.3051 - val_acc: 0.8642\n",
      "Epoch 164/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1695 - acc: 0.9595 - val_loss: 0.3041 - val_acc: 0.8642\n",
      "Epoch 165/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1691 - acc: 0.9595 - val_loss: 0.3036 - val_acc: 0.8642\n",
      "Epoch 166/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1678 - acc: 0.9595 - val_loss: 0.3031 - val_acc: 0.8642\n",
      "Epoch 167/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1653 - acc: 0.9564 - val_loss: 0.3030 - val_acc: 0.8642\n",
      "Epoch 168/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1632 - acc: 0.9564 - val_loss: 0.3040 - val_acc: 0.8889\n",
      "Epoch 169/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1613 - acc: 0.9502 - val_loss: 0.3061 - val_acc: 0.8765\n",
      "Epoch 170/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1601 - acc: 0.9502 - val_loss: 0.3088 - val_acc: 0.8765\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000179A7C6F820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45  7]\n",
      " [ 3 26]]\n",
      "(0.7878787878787878, 0.8765432098765432, 0.896551724137931, 0.8387096774193549, 0.9565649867374004, 0.936763460705649, 0.9375869581223697)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1000)]            0         \n",
      "                                                                 \n",
      " biological_module_1 (Biolog  (None, 238)              3170      \n",
      " ical_module)                                                    \n",
      "                                                                 \n",
      " self__attention_19 (Self_At  (None, 64)               45696     \n",
      " tention)                                                        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,979\n",
      "Trainable params: 50,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/170\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "1/6 [====>.........................] - ETA: 4s - loss: 0.7340 - acc: 0.4688WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "6/6 [==============================] - 1s 52ms/step - loss: 0.7317 - acc: 0.4206 - val_loss: 0.7311 - val_acc: 0.4074\n",
      "Epoch 2/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7304 - acc: 0.5545 - val_loss: 0.7296 - val_acc: 0.6296\n",
      "Epoch 3/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7291 - acc: 0.6386 - val_loss: 0.7281 - val_acc: 0.6420\n",
      "Epoch 4/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7278 - acc: 0.6449 - val_loss: 0.7266 - val_acc: 0.6420\n",
      "Epoch 5/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7266 - acc: 0.6449 - val_loss: 0.7255 - val_acc: 0.6420\n",
      "Epoch 6/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7254 - acc: 0.6449 - val_loss: 0.7245 - val_acc: 0.6296\n",
      "Epoch 7/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7242 - acc: 0.6449 - val_loss: 0.7234 - val_acc: 0.6296\n",
      "Epoch 8/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7231 - acc: 0.6449 - val_loss: 0.7222 - val_acc: 0.6296\n",
      "Epoch 9/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7220 - acc: 0.6449 - val_loss: 0.7209 - val_acc: 0.6420\n",
      "Epoch 10/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7209 - acc: 0.6449 - val_loss: 0.7197 - val_acc: 0.6420\n",
      "Epoch 11/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7198 - acc: 0.6449 - val_loss: 0.7184 - val_acc: 0.6420\n",
      "Epoch 12/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7188 - acc: 0.6449 - val_loss: 0.7172 - val_acc: 0.6420\n",
      "Epoch 13/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7178 - acc: 0.6449 - val_loss: 0.7159 - val_acc: 0.6420\n",
      "Epoch 14/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7168 - acc: 0.6449 - val_loss: 0.7146 - val_acc: 0.6420\n",
      "Epoch 15/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7158 - acc: 0.6449 - val_loss: 0.7133 - val_acc: 0.6420\n",
      "Epoch 16/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7148 - acc: 0.6449 - val_loss: 0.7119 - val_acc: 0.6420\n",
      "Epoch 17/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7139 - acc: 0.6449 - val_loss: 0.7105 - val_acc: 0.6420\n",
      "Epoch 18/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7128 - acc: 0.6449 - val_loss: 0.7097 - val_acc: 0.6420\n",
      "Epoch 19/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7119 - acc: 0.6449 - val_loss: 0.7090 - val_acc: 0.6420\n",
      "Epoch 20/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7109 - acc: 0.6449 - val_loss: 0.7079 - val_acc: 0.6420\n",
      "Epoch 21/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7098 - acc: 0.6449 - val_loss: 0.7067 - val_acc: 0.6420\n",
      "Epoch 22/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7088 - acc: 0.6449 - val_loss: 0.7059 - val_acc: 0.6420\n",
      "Epoch 23/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7076 - acc: 0.6511 - val_loss: 0.7051 - val_acc: 0.6543\n",
      "Epoch 24/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7065 - acc: 0.6511 - val_loss: 0.7038 - val_acc: 0.6543\n",
      "Epoch 25/170\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7052 - acc: 0.6698 - val_loss: 0.7021 - val_acc: 0.6543\n",
      "Epoch 26/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7037 - acc: 0.6698 - val_loss: 0.7002 - val_acc: 0.6543\n",
      "Epoch 27/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7021 - acc: 0.6791 - val_loss: 0.6989 - val_acc: 0.6543\n",
      "Epoch 28/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7007 - acc: 0.6947 - val_loss: 0.6980 - val_acc: 0.6543\n",
      "Epoch 29/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6992 - acc: 0.7103 - val_loss: 0.6963 - val_acc: 0.6543\n",
      "Epoch 30/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6974 - acc: 0.7259 - val_loss: 0.6941 - val_acc: 0.6543\n",
      "Epoch 31/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6952 - acc: 0.7477 - val_loss: 0.6923 - val_acc: 0.6790\n",
      "Epoch 32/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6931 - acc: 0.7632 - val_loss: 0.6904 - val_acc: 0.7284\n",
      "Epoch 33/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6906 - acc: 0.8069 - val_loss: 0.6878 - val_acc: 0.7284\n",
      "Epoch 34/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6877 - acc: 0.8318 - val_loss: 0.6857 - val_acc: 0.8272\n",
      "Epoch 35/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6847 - acc: 0.8879 - val_loss: 0.6835 - val_acc: 0.7778\n",
      "Epoch 36/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6810 - acc: 0.8941 - val_loss: 0.6812 - val_acc: 0.7901\n",
      "Epoch 37/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6772 - acc: 0.8536 - val_loss: 0.6786 - val_acc: 0.7531\n",
      "Epoch 38/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6731 - acc: 0.8224 - val_loss: 0.6750 - val_acc: 0.7407\n",
      "Epoch 39/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6682 - acc: 0.8069 - val_loss: 0.6717 - val_acc: 0.7037\n",
      "Epoch 40/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6630 - acc: 0.7695 - val_loss: 0.6684 - val_acc: 0.6790\n",
      "Epoch 41/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6571 - acc: 0.7352 - val_loss: 0.6647 - val_acc: 0.6667\n",
      "Epoch 42/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6505 - acc: 0.7290 - val_loss: 0.6595 - val_acc: 0.6667\n",
      "Epoch 43/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6436 - acc: 0.7290 - val_loss: 0.6549 - val_acc: 0.6543\n",
      "Epoch 44/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6364 - acc: 0.7290 - val_loss: 0.6485 - val_acc: 0.6790\n",
      "Epoch 45/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6291 - acc: 0.7290 - val_loss: 0.6408 - val_acc: 0.7037\n",
      "Epoch 46/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6216 - acc: 0.7601 - val_loss: 0.6324 - val_acc: 0.7160\n",
      "Epoch 47/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6139 - acc: 0.7975 - val_loss: 0.6243 - val_acc: 0.7407\n",
      "Epoch 48/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6058 - acc: 0.8069 - val_loss: 0.6189 - val_acc: 0.7284\n",
      "Epoch 49/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5970 - acc: 0.7819 - val_loss: 0.6144 - val_acc: 0.7284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5893 - acc: 0.7726 - val_loss: 0.6081 - val_acc: 0.7284\n",
      "Epoch 51/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5818 - acc: 0.8006 - val_loss: 0.6002 - val_acc: 0.7407\n",
      "Epoch 52/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5742 - acc: 0.8162 - val_loss: 0.5924 - val_acc: 0.7531\n",
      "Epoch 53/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5660 - acc: 0.8287 - val_loss: 0.5876 - val_acc: 0.7407\n",
      "Epoch 54/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5578 - acc: 0.8131 - val_loss: 0.5838 - val_acc: 0.7407\n",
      "Epoch 55/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5497 - acc: 0.8037 - val_loss: 0.5782 - val_acc: 0.7407\n",
      "Epoch 56/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5415 - acc: 0.7913 - val_loss: 0.5740 - val_acc: 0.7407\n",
      "Epoch 57/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5330 - acc: 0.7819 - val_loss: 0.5681 - val_acc: 0.7407\n",
      "Epoch 58/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5244 - acc: 0.7944 - val_loss: 0.5605 - val_acc: 0.7531\n",
      "Epoch 59/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5156 - acc: 0.8069 - val_loss: 0.5551 - val_acc: 0.7531\n",
      "Epoch 60/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5064 - acc: 0.7913 - val_loss: 0.5515 - val_acc: 0.7407\n",
      "Epoch 61/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4983 - acc: 0.7819 - val_loss: 0.5488 - val_acc: 0.7160\n",
      "Epoch 62/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4901 - acc: 0.7819 - val_loss: 0.5441 - val_acc: 0.7160\n",
      "Epoch 63/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4823 - acc: 0.7788 - val_loss: 0.5416 - val_acc: 0.7160\n",
      "Epoch 64/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4750 - acc: 0.7757 - val_loss: 0.5366 - val_acc: 0.7160\n",
      "Epoch 65/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4673 - acc: 0.7788 - val_loss: 0.5315 - val_acc: 0.7160\n",
      "Epoch 66/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4596 - acc: 0.7819 - val_loss: 0.5251 - val_acc: 0.7284\n",
      "Epoch 67/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4525 - acc: 0.7819 - val_loss: 0.5232 - val_acc: 0.7284\n",
      "Epoch 68/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4461 - acc: 0.7819 - val_loss: 0.5197 - val_acc: 0.7284\n",
      "Epoch 69/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4387 - acc: 0.7850 - val_loss: 0.5124 - val_acc: 0.7531\n",
      "Epoch 70/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4317 - acc: 0.7944 - val_loss: 0.5086 - val_acc: 0.7531\n",
      "Epoch 71/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4255 - acc: 0.7975 - val_loss: 0.5048 - val_acc: 0.7531\n",
      "Epoch 72/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4184 - acc: 0.8006 - val_loss: 0.4972 - val_acc: 0.7531\n",
      "Epoch 73/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4108 - acc: 0.8255 - val_loss: 0.4889 - val_acc: 0.7778\n",
      "Epoch 74/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4041 - acc: 0.8287 - val_loss: 0.4856 - val_acc: 0.7778\n",
      "Epoch 75/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3981 - acc: 0.8287 - val_loss: 0.4818 - val_acc: 0.7778\n",
      "Epoch 76/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3920 - acc: 0.8349 - val_loss: 0.4731 - val_acc: 0.7778\n",
      "Epoch 77/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3854 - acc: 0.8660 - val_loss: 0.4651 - val_acc: 0.7778\n",
      "Epoch 78/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3800 - acc: 0.8785 - val_loss: 0.4598 - val_acc: 0.7901\n",
      "Epoch 79/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3747 - acc: 0.8879 - val_loss: 0.4537 - val_acc: 0.8025\n",
      "Epoch 80/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3696 - acc: 0.9034 - val_loss: 0.4484 - val_acc: 0.8148\n",
      "Epoch 81/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3649 - acc: 0.9034 - val_loss: 0.4474 - val_acc: 0.8025\n",
      "Epoch 82/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3598 - acc: 0.9003 - val_loss: 0.4481 - val_acc: 0.7901\n",
      "Epoch 83/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3542 - acc: 0.8816 - val_loss: 0.4476 - val_acc: 0.7778\n",
      "Epoch 84/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3506 - acc: 0.8723 - val_loss: 0.4491 - val_acc: 0.7901\n",
      "Epoch 85/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3462 - acc: 0.8660 - val_loss: 0.4463 - val_acc: 0.7901\n",
      "Epoch 86/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3413 - acc: 0.8785 - val_loss: 0.4393 - val_acc: 0.7901\n",
      "Epoch 87/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3361 - acc: 0.8910 - val_loss: 0.4330 - val_acc: 0.7901\n",
      "Epoch 88/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3316 - acc: 0.9003 - val_loss: 0.4294 - val_acc: 0.8148\n",
      "Epoch 89/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3278 - acc: 0.9003 - val_loss: 0.4303 - val_acc: 0.7901\n",
      "Epoch 90/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3237 - acc: 0.8972 - val_loss: 0.4325 - val_acc: 0.7901\n",
      "Epoch 91/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3205 - acc: 0.8910 - val_loss: 0.4316 - val_acc: 0.7901\n",
      "Epoch 92/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3172 - acc: 0.8879 - val_loss: 0.4335 - val_acc: 0.7778\n",
      "Epoch 93/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3147 - acc: 0.8692 - val_loss: 0.4350 - val_acc: 0.7778\n",
      "Epoch 94/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3117 - acc: 0.8723 - val_loss: 0.4296 - val_acc: 0.7778\n",
      "Epoch 95/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3069 - acc: 0.8785 - val_loss: 0.4236 - val_acc: 0.7901\n",
      "Epoch 96/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3019 - acc: 0.8941 - val_loss: 0.4186 - val_acc: 0.8025\n",
      "Epoch 97/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2977 - acc: 0.9034 - val_loss: 0.4159 - val_acc: 0.8025\n",
      "Epoch 98/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2941 - acc: 0.9065 - val_loss: 0.4140 - val_acc: 0.7901\n",
      "Epoch 99/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2899 - acc: 0.9097 - val_loss: 0.4089 - val_acc: 0.8025\n",
      "Epoch 100/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2857 - acc: 0.9097 - val_loss: 0.4058 - val_acc: 0.8025\n",
      "Epoch 101/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2821 - acc: 0.9097 - val_loss: 0.4026 - val_acc: 0.8148\n",
      "Epoch 102/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2787 - acc: 0.9159 - val_loss: 0.4000 - val_acc: 0.8148\n",
      "Epoch 103/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2755 - acc: 0.9159 - val_loss: 0.3981 - val_acc: 0.8272\n",
      "Epoch 104/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2724 - acc: 0.9190 - val_loss: 0.3966 - val_acc: 0.8272\n",
      "Epoch 105/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2694 - acc: 0.9190 - val_loss: 0.3961 - val_acc: 0.8148\n",
      "Epoch 106/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2670 - acc: 0.9190 - val_loss: 0.3975 - val_acc: 0.8025\n",
      "Epoch 107/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2642 - acc: 0.9190 - val_loss: 0.3939 - val_acc: 0.8025\n",
      "Epoch 108/170\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2609 - acc: 0.9221 - val_loss: 0.3898 - val_acc: 0.8272\n",
      "Epoch 109/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2576 - acc: 0.9283 - val_loss: 0.3859 - val_acc: 0.8272\n",
      "Epoch 110/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2549 - acc: 0.9283 - val_loss: 0.3822 - val_acc: 0.8519\n",
      "Epoch 111/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2518 - acc: 0.9315 - val_loss: 0.3806 - val_acc: 0.8519\n",
      "Epoch 112/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2486 - acc: 0.9315 - val_loss: 0.3802 - val_acc: 0.8272\n",
      "Epoch 113/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2461 - acc: 0.9346 - val_loss: 0.3799 - val_acc: 0.8272\n",
      "Epoch 114/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2436 - acc: 0.9315 - val_loss: 0.3805 - val_acc: 0.8272\n",
      "Epoch 115/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2411 - acc: 0.9283 - val_loss: 0.3796 - val_acc: 0.8272\n",
      "Epoch 116/170\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2387 - acc: 0.9283 - val_loss: 0.3766 - val_acc: 0.8272\n",
      "Epoch 117/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2358 - acc: 0.9315 - val_loss: 0.3733 - val_acc: 0.8272\n",
      "Epoch 118/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2327 - acc: 0.9377 - val_loss: 0.3696 - val_acc: 0.8519\n",
      "Epoch 119/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2311 - acc: 0.9470 - val_loss: 0.3671 - val_acc: 0.8642\n",
      "Epoch 120/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2297 - acc: 0.9502 - val_loss: 0.3662 - val_acc: 0.8642\n",
      "Epoch 121/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2266 - acc: 0.9502 - val_loss: 0.3669 - val_acc: 0.8519\n",
      "Epoch 122/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2236 - acc: 0.9439 - val_loss: 0.3680 - val_acc: 0.8395\n",
      "Epoch 123/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2218 - acc: 0.9346 - val_loss: 0.3690 - val_acc: 0.8272\n",
      "Epoch 124/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2194 - acc: 0.9346 - val_loss: 0.3668 - val_acc: 0.8395\n",
      "Epoch 125/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2172 - acc: 0.9377 - val_loss: 0.3658 - val_acc: 0.8395\n",
      "Epoch 126/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2154 - acc: 0.9346 - val_loss: 0.3673 - val_acc: 0.8272\n",
      "Epoch 127/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2142 - acc: 0.9283 - val_loss: 0.3665 - val_acc: 0.8272\n",
      "Epoch 128/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2122 - acc: 0.9377 - val_loss: 0.3641 - val_acc: 0.8272\n",
      "Epoch 129/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2099 - acc: 0.9408 - val_loss: 0.3622 - val_acc: 0.8395\n",
      "Epoch 130/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2079 - acc: 0.9439 - val_loss: 0.3601 - val_acc: 0.8519\n",
      "Epoch 131/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2059 - acc: 0.9502 - val_loss: 0.3586 - val_acc: 0.8519\n",
      "Epoch 132/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2042 - acc: 0.9502 - val_loss: 0.3576 - val_acc: 0.8519\n",
      "Epoch 133/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2025 - acc: 0.9502 - val_loss: 0.3567 - val_acc: 0.8519\n",
      "Epoch 134/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2008 - acc: 0.9502 - val_loss: 0.3557 - val_acc: 0.8519\n",
      "Epoch 135/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1990 - acc: 0.9533 - val_loss: 0.3540 - val_acc: 0.8642\n",
      "Epoch 136/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1977 - acc: 0.9533 - val_loss: 0.3528 - val_acc: 0.8642\n",
      "Epoch 137/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1961 - acc: 0.9533 - val_loss: 0.3522 - val_acc: 0.8642\n",
      "Epoch 138/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1946 - acc: 0.9595 - val_loss: 0.3517 - val_acc: 0.8642\n",
      "Epoch 139/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1926 - acc: 0.9533 - val_loss: 0.3517 - val_acc: 0.8519\n",
      "Epoch 140/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1909 - acc: 0.9502 - val_loss: 0.3525 - val_acc: 0.8395\n",
      "Epoch 141/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1902 - acc: 0.9470 - val_loss: 0.3541 - val_acc: 0.8395\n",
      "Epoch 142/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1887 - acc: 0.9439 - val_loss: 0.3492 - val_acc: 0.8519\n",
      "Epoch 143/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1861 - acc: 0.9533 - val_loss: 0.3470 - val_acc: 0.8519\n",
      "Epoch 144/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1848 - acc: 0.9533 - val_loss: 0.3460 - val_acc: 0.8642\n",
      "Epoch 145/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1833 - acc: 0.9533 - val_loss: 0.3453 - val_acc: 0.8642\n",
      "Epoch 146/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1821 - acc: 0.9564 - val_loss: 0.3447 - val_acc: 0.8642\n",
      "Epoch 147/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1808 - acc: 0.9595 - val_loss: 0.3443 - val_acc: 0.8642\n",
      "Epoch 148/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1796 - acc: 0.9595 - val_loss: 0.3441 - val_acc: 0.8642\n",
      "Epoch 149/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1782 - acc: 0.9595 - val_loss: 0.3437 - val_acc: 0.8642\n",
      "Epoch 150/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1770 - acc: 0.9595 - val_loss: 0.3454 - val_acc: 0.8519\n",
      "Epoch 151/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1760 - acc: 0.9502 - val_loss: 0.3492 - val_acc: 0.8519\n",
      "Epoch 152/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1757 - acc: 0.9502 - val_loss: 0.3518 - val_acc: 0.8519\n",
      "Epoch 153/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1757 - acc: 0.9470 - val_loss: 0.3569 - val_acc: 0.8395\n",
      "Epoch 154/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1762 - acc: 0.9377 - val_loss: 0.3566 - val_acc: 0.8395\n",
      "Epoch 155/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1744 - acc: 0.9470 - val_loss: 0.3530 - val_acc: 0.8395\n",
      "Epoch 156/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1716 - acc: 0.9502 - val_loss: 0.3504 - val_acc: 0.8519\n",
      "Epoch 157/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1694 - acc: 0.9502 - val_loss: 0.3473 - val_acc: 0.8519\n",
      "Epoch 158/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1674 - acc: 0.9533 - val_loss: 0.3454 - val_acc: 0.8519\n",
      "Epoch 159/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1661 - acc: 0.9595 - val_loss: 0.3445 - val_acc: 0.8519\n",
      "Epoch 160/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1650 - acc: 0.9595 - val_loss: 0.3438 - val_acc: 0.8642\n",
      "Epoch 161/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1638 - acc: 0.9595 - val_loss: 0.3428 - val_acc: 0.8642\n",
      "Epoch 162/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1630 - acc: 0.9626 - val_loss: 0.3419 - val_acc: 0.8642\n",
      "Epoch 163/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1618 - acc: 0.9626 - val_loss: 0.3415 - val_acc: 0.8642\n",
      "Epoch 164/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1608 - acc: 0.9626 - val_loss: 0.3416 - val_acc: 0.8642\n",
      "Epoch 165/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1596 - acc: 0.9595 - val_loss: 0.3423 - val_acc: 0.8642\n",
      "Epoch 166/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1589 - acc: 0.9595 - val_loss: 0.3425 - val_acc: 0.8642\n",
      "Epoch 167/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1578 - acc: 0.9595 - val_loss: 0.3417 - val_acc: 0.8642\n",
      "Epoch 168/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1567 - acc: 0.9626 - val_loss: 0.3413 - val_acc: 0.8642\n",
      "Epoch 169/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1558 - acc: 0.9626 - val_loss: 0.3412 - val_acc: 0.8642\n",
      "Epoch 170/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1549 - acc: 0.9626 - val_loss: 0.3410 - val_acc: 0.8642\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "[[45  7]\n",
      " [ 4 25]]\n",
      "(0.78125, 0.8641975308641975, 0.8620689655172413, 0.8196721311475409, 0.9383289124668436, 0.9187886283412816, 0.9190028791722518)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1000)]            0         \n",
      "                                                                 \n",
      " biological_module_2 (Biolog  (None, 238)              3170      \n",
      " ical_module)                                                    \n",
      "                                                                 \n",
      " self__attention_20 (Self_At  (None, 64)               45696     \n",
      " tention)                                                        \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,979\n",
      "Trainable params: 50,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/170\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "1/6 [====>.........................] - ETA: 4s - loss: 0.7610 - acc: 0.5312WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "6/6 [==============================] - 1s 48ms/step - loss: 0.7323 - acc: 0.4752 - val_loss: 0.7307 - val_acc: 0.5500\n",
      "Epoch 2/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7310 - acc: 0.6149 - val_loss: 0.7291 - val_acc: 0.6375\n",
      "Epoch 3/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7296 - acc: 0.6398 - val_loss: 0.7279 - val_acc: 0.6375\n",
      "Epoch 4/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7284 - acc: 0.6429 - val_loss: 0.7269 - val_acc: 0.6375\n",
      "Epoch 5/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7271 - acc: 0.5776 - val_loss: 0.7258 - val_acc: 0.5625\n",
      "Epoch 6/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7258 - acc: 0.5683 - val_loss: 0.7245 - val_acc: 0.6250\n",
      "Epoch 7/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7246 - acc: 0.6863 - val_loss: 0.7230 - val_acc: 0.7750\n",
      "Epoch 8/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7234 - acc: 0.7143 - val_loss: 0.7216 - val_acc: 0.6625\n",
      "Epoch 9/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7222 - acc: 0.6832 - val_loss: 0.7203 - val_acc: 0.6750\n",
      "Epoch 10/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7210 - acc: 0.6863 - val_loss: 0.7190 - val_acc: 0.6875\n",
      "Epoch 11/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7198 - acc: 0.6801 - val_loss: 0.7176 - val_acc: 0.6750\n",
      "Epoch 12/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7186 - acc: 0.6863 - val_loss: 0.7162 - val_acc: 0.6875\n",
      "Epoch 13/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7173 - acc: 0.6894 - val_loss: 0.7145 - val_acc: 0.6625\n",
      "Epoch 14/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7160 - acc: 0.6646 - val_loss: 0.7127 - val_acc: 0.6625\n",
      "Epoch 15/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7147 - acc: 0.6584 - val_loss: 0.7114 - val_acc: 0.6625\n",
      "Epoch 16/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7134 - acc: 0.6925 - val_loss: 0.7103 - val_acc: 0.6875\n",
      "Epoch 17/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7120 - acc: 0.7050 - val_loss: 0.7086 - val_acc: 0.6875\n",
      "Epoch 18/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7105 - acc: 0.7019 - val_loss: 0.7066 - val_acc: 0.6875\n",
      "Epoch 19/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7089 - acc: 0.6957 - val_loss: 0.7045 - val_acc: 0.6750\n",
      "Epoch 20/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7075 - acc: 0.6925 - val_loss: 0.7025 - val_acc: 0.6750\n",
      "Epoch 21/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7058 - acc: 0.6894 - val_loss: 0.7001 - val_acc: 0.6750\n",
      "Epoch 22/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7040 - acc: 0.6801 - val_loss: 0.6974 - val_acc: 0.6750\n",
      "Epoch 23/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7022 - acc: 0.6801 - val_loss: 0.6952 - val_acc: 0.6750\n",
      "Epoch 24/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7002 - acc: 0.6863 - val_loss: 0.6931 - val_acc: 0.6750\n",
      "Epoch 25/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6981 - acc: 0.7019 - val_loss: 0.6909 - val_acc: 0.7125\n",
      "Epoch 26/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6959 - acc: 0.7143 - val_loss: 0.6879 - val_acc: 0.7125\n",
      "Epoch 27/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6934 - acc: 0.7236 - val_loss: 0.6851 - val_acc: 0.7125\n",
      "Epoch 28/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6906 - acc: 0.7298 - val_loss: 0.6811 - val_acc: 0.7125\n",
      "Epoch 29/170\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6876 - acc: 0.7298 - val_loss: 0.6763 - val_acc: 0.6875\n",
      "Epoch 30/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6841 - acc: 0.7174 - val_loss: 0.6713 - val_acc: 0.6875\n",
      "Epoch 31/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6805 - acc: 0.7112 - val_loss: 0.6668 - val_acc: 0.6875\n",
      "Epoch 32/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6767 - acc: 0.7205 - val_loss: 0.6616 - val_acc: 0.7000\n",
      "Epoch 33/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6723 - acc: 0.7391 - val_loss: 0.6581 - val_acc: 0.7375\n",
      "Epoch 34/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6677 - acc: 0.7516 - val_loss: 0.6530 - val_acc: 0.7375\n",
      "Epoch 35/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6631 - acc: 0.7516 - val_loss: 0.6473 - val_acc: 0.7500\n",
      "Epoch 36/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6577 - acc: 0.7702 - val_loss: 0.6426 - val_acc: 0.7625\n",
      "Epoch 37/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6518 - acc: 0.7857 - val_loss: 0.6363 - val_acc: 0.7625\n",
      "Epoch 38/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6459 - acc: 0.7950 - val_loss: 0.6290 - val_acc: 0.7625\n",
      "Epoch 39/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6397 - acc: 0.7950 - val_loss: 0.6218 - val_acc: 0.7625\n",
      "Epoch 40/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6335 - acc: 0.8043 - val_loss: 0.6166 - val_acc: 0.7750\n",
      "Epoch 41/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6267 - acc: 0.8478 - val_loss: 0.6117 - val_acc: 0.8125\n",
      "Epoch 42/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6195 - acc: 0.8882 - val_loss: 0.6068 - val_acc: 0.8250\n",
      "Epoch 43/170\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6119 - acc: 0.8975 - val_loss: 0.6003 - val_acc: 0.8250\n",
      "Epoch 44/170\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6043 - acc: 0.9037 - val_loss: 0.5929 - val_acc: 0.8375\n",
      "Epoch 45/170\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5969 - acc: 0.9006 - val_loss: 0.5855 - val_acc: 0.8250\n",
      "Epoch 46/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5883 - acc: 0.9099 - val_loss: 0.5808 - val_acc: 0.8375\n",
      "Epoch 47/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5784 - acc: 0.9037 - val_loss: 0.5756 - val_acc: 0.8500\n",
      "Epoch 48/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5695 - acc: 0.8882 - val_loss: 0.5692 - val_acc: 0.8375\n",
      "Epoch 49/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5597 - acc: 0.8820 - val_loss: 0.5629 - val_acc: 0.8250\n",
      "Epoch 50/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5504 - acc: 0.8665 - val_loss: 0.5564 - val_acc: 0.8250\n",
      "Epoch 51/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5416 - acc: 0.8634 - val_loss: 0.5524 - val_acc: 0.8000\n",
      "Epoch 52/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5317 - acc: 0.8385 - val_loss: 0.5490 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5224 - acc: 0.8230 - val_loss: 0.5457 - val_acc: 0.7375\n",
      "Epoch 54/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5137 - acc: 0.8106 - val_loss: 0.5418 - val_acc: 0.7250\n",
      "Epoch 55/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5060 - acc: 0.8168 - val_loss: 0.5334 - val_acc: 0.7500\n",
      "Epoch 56/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4976 - acc: 0.8230 - val_loss: 0.5273 - val_acc: 0.7500\n",
      "Epoch 57/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4894 - acc: 0.8385 - val_loss: 0.5183 - val_acc: 0.8000\n",
      "Epoch 58/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4815 - acc: 0.8509 - val_loss: 0.5120 - val_acc: 0.8000\n",
      "Epoch 59/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4743 - acc: 0.8634 - val_loss: 0.5035 - val_acc: 0.8250\n",
      "Epoch 60/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4667 - acc: 0.8758 - val_loss: 0.4983 - val_acc: 0.8250\n",
      "Epoch 61/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4586 - acc: 0.8758 - val_loss: 0.4934 - val_acc: 0.8250\n",
      "Epoch 62/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4509 - acc: 0.8789 - val_loss: 0.4884 - val_acc: 0.8250\n",
      "Epoch 63/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4432 - acc: 0.8789 - val_loss: 0.4842 - val_acc: 0.8250\n",
      "Epoch 64/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4356 - acc: 0.8789 - val_loss: 0.4808 - val_acc: 0.8125\n",
      "Epoch 65/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4284 - acc: 0.8820 - val_loss: 0.4769 - val_acc: 0.8125\n",
      "Epoch 66/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4207 - acc: 0.8696 - val_loss: 0.4797 - val_acc: 0.7875\n",
      "Epoch 67/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4142 - acc: 0.8509 - val_loss: 0.4812 - val_acc: 0.7625\n",
      "Epoch 68/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4076 - acc: 0.8478 - val_loss: 0.4755 - val_acc: 0.7625\n",
      "Epoch 69/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.4011 - acc: 0.8509 - val_loss: 0.4737 - val_acc: 0.7625\n",
      "Epoch 70/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3945 - acc: 0.8509 - val_loss: 0.4700 - val_acc: 0.7625\n",
      "Epoch 71/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3881 - acc: 0.8540 - val_loss: 0.4653 - val_acc: 0.7875\n",
      "Epoch 72/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3813 - acc: 0.8571 - val_loss: 0.4571 - val_acc: 0.8125\n",
      "Epoch 73/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3743 - acc: 0.8820 - val_loss: 0.4510 - val_acc: 0.8125\n",
      "Epoch 74/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3682 - acc: 0.8851 - val_loss: 0.4462 - val_acc: 0.8250\n",
      "Epoch 75/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3621 - acc: 0.8913 - val_loss: 0.4430 - val_acc: 0.8375\n",
      "Epoch 76/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3568 - acc: 0.9037 - val_loss: 0.4361 - val_acc: 0.8375\n",
      "Epoch 77/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3513 - acc: 0.9193 - val_loss: 0.4325 - val_acc: 0.8375\n",
      "Epoch 78/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3457 - acc: 0.9224 - val_loss: 0.4299 - val_acc: 0.8375\n",
      "Epoch 79/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3401 - acc: 0.9317 - val_loss: 0.4263 - val_acc: 0.8375\n",
      "Epoch 80/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3347 - acc: 0.9317 - val_loss: 0.4239 - val_acc: 0.8375\n",
      "Epoch 81/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3295 - acc: 0.9348 - val_loss: 0.4197 - val_acc: 0.8500\n",
      "Epoch 82/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3249 - acc: 0.9348 - val_loss: 0.4151 - val_acc: 0.8500\n",
      "Epoch 83/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3211 - acc: 0.9379 - val_loss: 0.4112 - val_acc: 0.8500\n",
      "Epoch 84/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3169 - acc: 0.9410 - val_loss: 0.4086 - val_acc: 0.8500\n",
      "Epoch 85/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3121 - acc: 0.9441 - val_loss: 0.4081 - val_acc: 0.8500\n",
      "Epoch 86/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3061 - acc: 0.9348 - val_loss: 0.4129 - val_acc: 0.8375\n",
      "Epoch 87/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3006 - acc: 0.9255 - val_loss: 0.4175 - val_acc: 0.8375\n",
      "Epoch 88/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2976 - acc: 0.9099 - val_loss: 0.4195 - val_acc: 0.8250\n",
      "Epoch 89/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2938 - acc: 0.9037 - val_loss: 0.4172 - val_acc: 0.8250\n",
      "Epoch 90/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2894 - acc: 0.9193 - val_loss: 0.4137 - val_acc: 0.8375\n",
      "Epoch 91/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2856 - acc: 0.9193 - val_loss: 0.4128 - val_acc: 0.8375\n",
      "Epoch 92/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2813 - acc: 0.9224 - val_loss: 0.4089 - val_acc: 0.8375\n",
      "Epoch 93/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2779 - acc: 0.9224 - val_loss: 0.4132 - val_acc: 0.8250\n",
      "Epoch 94/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2751 - acc: 0.9193 - val_loss: 0.4103 - val_acc: 0.8250\n",
      "Epoch 95/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2706 - acc: 0.9286 - val_loss: 0.4022 - val_acc: 0.8375\n",
      "Epoch 96/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2669 - acc: 0.9348 - val_loss: 0.3979 - val_acc: 0.8500\n",
      "Epoch 97/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2632 - acc: 0.9379 - val_loss: 0.3950 - val_acc: 0.8500\n",
      "Epoch 98/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2599 - acc: 0.9410 - val_loss: 0.3940 - val_acc: 0.8500\n",
      "Epoch 99/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2569 - acc: 0.9410 - val_loss: 0.3918 - val_acc: 0.8500\n",
      "Epoch 100/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2535 - acc: 0.9410 - val_loss: 0.3927 - val_acc: 0.8500\n",
      "Epoch 101/170\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2504 - acc: 0.9410 - val_loss: 0.3940 - val_acc: 0.8375\n",
      "Epoch 102/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2477 - acc: 0.9379 - val_loss: 0.3953 - val_acc: 0.8375\n",
      "Epoch 103/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2448 - acc: 0.9348 - val_loss: 0.3967 - val_acc: 0.8375\n",
      "Epoch 104/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2423 - acc: 0.9348 - val_loss: 0.3993 - val_acc: 0.8375\n",
      "Epoch 105/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2408 - acc: 0.9317 - val_loss: 0.4015 - val_acc: 0.8250\n",
      "Epoch 106/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2378 - acc: 0.9286 - val_loss: 0.3968 - val_acc: 0.8375\n",
      "Epoch 107/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2336 - acc: 0.9410 - val_loss: 0.3869 - val_acc: 0.8500\n",
      "Epoch 108/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2304 - acc: 0.9503 - val_loss: 0.3815 - val_acc: 0.8500\n",
      "Epoch 109/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2283 - acc: 0.9534 - val_loss: 0.3803 - val_acc: 0.8500\n",
      "Epoch 110/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2258 - acc: 0.9534 - val_loss: 0.3798 - val_acc: 0.8500\n",
      "Epoch 111/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2233 - acc: 0.9534 - val_loss: 0.3802 - val_acc: 0.8500\n",
      "Epoch 112/170\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2210 - acc: 0.9503 - val_loss: 0.3804 - val_acc: 0.8500\n",
      "Epoch 113/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2186 - acc: 0.9503 - val_loss: 0.3789 - val_acc: 0.8500\n",
      "Epoch 114/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2163 - acc: 0.9503 - val_loss: 0.3798 - val_acc: 0.8500\n",
      "Epoch 115/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2141 - acc: 0.9503 - val_loss: 0.3773 - val_acc: 0.8500\n",
      "Epoch 116/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2119 - acc: 0.9534 - val_loss: 0.3738 - val_acc: 0.8500\n",
      "Epoch 117/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2095 - acc: 0.9534 - val_loss: 0.3773 - val_acc: 0.8500\n",
      "Epoch 118/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2074 - acc: 0.9534 - val_loss: 0.3758 - val_acc: 0.8500\n",
      "Epoch 119/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2053 - acc: 0.9534 - val_loss: 0.3749 - val_acc: 0.8500\n",
      "Epoch 120/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2034 - acc: 0.9534 - val_loss: 0.3747 - val_acc: 0.8500\n",
      "Epoch 121/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2021 - acc: 0.9503 - val_loss: 0.3814 - val_acc: 0.8375\n",
      "Epoch 122/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2000 - acc: 0.9503 - val_loss: 0.3830 - val_acc: 0.8250\n",
      "Epoch 123/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1982 - acc: 0.9503 - val_loss: 0.3823 - val_acc: 0.8250\n",
      "Epoch 124/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1962 - acc: 0.9503 - val_loss: 0.3801 - val_acc: 0.8375\n",
      "Epoch 125/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1942 - acc: 0.9503 - val_loss: 0.3828 - val_acc: 0.8250\n",
      "Epoch 126/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1928 - acc: 0.9503 - val_loss: 0.3801 - val_acc: 0.8375\n",
      "Epoch 127/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1899 - acc: 0.9503 - val_loss: 0.3736 - val_acc: 0.8500\n",
      "Epoch 128/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1887 - acc: 0.9565 - val_loss: 0.3700 - val_acc: 0.8500\n",
      "Epoch 129/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1874 - acc: 0.9565 - val_loss: 0.3695 - val_acc: 0.8500\n",
      "Epoch 130/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1857 - acc: 0.9565 - val_loss: 0.3729 - val_acc: 0.8500\n",
      "Epoch 131/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1848 - acc: 0.9534 - val_loss: 0.3812 - val_acc: 0.8250\n",
      "Epoch 132/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1836 - acc: 0.9503 - val_loss: 0.3891 - val_acc: 0.8250\n",
      "Epoch 133/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1842 - acc: 0.9441 - val_loss: 0.3901 - val_acc: 0.8250\n",
      "Epoch 134/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1820 - acc: 0.9472 - val_loss: 0.3852 - val_acc: 0.8250\n",
      "Epoch 135/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1793 - acc: 0.9503 - val_loss: 0.3783 - val_acc: 0.8375\n",
      "Epoch 136/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1766 - acc: 0.9503 - val_loss: 0.3724 - val_acc: 0.8500\n",
      "Epoch 137/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1748 - acc: 0.9565 - val_loss: 0.3664 - val_acc: 0.8375\n",
      "Epoch 138/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1741 - acc: 0.9565 - val_loss: 0.3683 - val_acc: 0.8500\n",
      "Epoch 139/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1725 - acc: 0.9565 - val_loss: 0.3707 - val_acc: 0.8500\n",
      "Epoch 140/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1712 - acc: 0.9534 - val_loss: 0.3768 - val_acc: 0.8375\n",
      "Epoch 141/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1703 - acc: 0.9534 - val_loss: 0.3780 - val_acc: 0.8375\n",
      "Epoch 142/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1689 - acc: 0.9534 - val_loss: 0.3762 - val_acc: 0.8375\n",
      "Epoch 143/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1674 - acc: 0.9534 - val_loss: 0.3762 - val_acc: 0.8375\n",
      "Epoch 144/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1663 - acc: 0.9534 - val_loss: 0.3742 - val_acc: 0.8375\n",
      "Epoch 145/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1648 - acc: 0.9534 - val_loss: 0.3761 - val_acc: 0.8375\n",
      "Epoch 146/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1637 - acc: 0.9534 - val_loss: 0.3782 - val_acc: 0.8375\n",
      "Epoch 147/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1637 - acc: 0.9503 - val_loss: 0.3845 - val_acc: 0.8250\n",
      "Epoch 148/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1632 - acc: 0.9503 - val_loss: 0.3846 - val_acc: 0.8250\n",
      "Epoch 149/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1617 - acc: 0.9503 - val_loss: 0.3811 - val_acc: 0.8250\n",
      "Epoch 150/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1596 - acc: 0.9534 - val_loss: 0.3748 - val_acc: 0.8375\n",
      "Epoch 151/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1576 - acc: 0.9565 - val_loss: 0.3702 - val_acc: 0.8375\n",
      "Epoch 152/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1570 - acc: 0.9565 - val_loss: 0.3675 - val_acc: 0.8375\n",
      "Epoch 153/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1561 - acc: 0.9627 - val_loss: 0.3666 - val_acc: 0.8500\n",
      "Epoch 154/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1553 - acc: 0.9627 - val_loss: 0.3660 - val_acc: 0.8500\n",
      "Epoch 155/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1544 - acc: 0.9627 - val_loss: 0.3675 - val_acc: 0.8375\n",
      "Epoch 156/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1526 - acc: 0.9627 - val_loss: 0.3756 - val_acc: 0.8375\n",
      "Epoch 157/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1518 - acc: 0.9534 - val_loss: 0.3803 - val_acc: 0.8375\n",
      "Epoch 158/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1516 - acc: 0.9534 - val_loss: 0.3830 - val_acc: 0.8250\n",
      "Epoch 159/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1519 - acc: 0.9534 - val_loss: 0.3894 - val_acc: 0.8250\n",
      "Epoch 160/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1521 - acc: 0.9503 - val_loss: 0.3870 - val_acc: 0.8250\n",
      "Epoch 161/170\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1494 - acc: 0.9565 - val_loss: 0.3737 - val_acc: 0.8375\n",
      "Epoch 162/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1472 - acc: 0.9627 - val_loss: 0.3677 - val_acc: 0.8250\n",
      "Epoch 163/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1470 - acc: 0.9627 - val_loss: 0.3643 - val_acc: 0.8500\n",
      "Epoch 164/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1469 - acc: 0.9689 - val_loss: 0.3636 - val_acc: 0.8500\n",
      "Epoch 165/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1466 - acc: 0.9720 - val_loss: 0.3636 - val_acc: 0.8500\n",
      "Epoch 166/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1454 - acc: 0.9720 - val_loss: 0.3649 - val_acc: 0.8500\n",
      "Epoch 167/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1440 - acc: 0.9689 - val_loss: 0.3655 - val_acc: 0.8500\n",
      "Epoch 168/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1434 - acc: 0.9689 - val_loss: 0.3642 - val_acc: 0.8500\n",
      "Epoch 169/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1426 - acc: 0.9720 - val_loss: 0.3649 - val_acc: 0.8500\n",
      "Epoch 170/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1415 - acc: 0.9658 - val_loss: 0.3673 - val_acc: 0.8375\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "[[43  9]\n",
      " [ 4 24]]\n",
      "(0.7272727272727273, 0.8375, 0.8571428571428571, 0.7868852459016394, 0.9368131868131868, 0.9269127389214032, 0.9260043154536636)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1000)]            0         \n",
      "                                                                 \n",
      " biological_module_3 (Biolog  (None, 238)              3170      \n",
      " ical_module)                                                    \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " self__attention_21 (Self_At  (None, 64)               45696     \n",
      " tention)                                                        \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,979\n",
      "Trainable params: 50,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/170\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "1/6 [====>.........................] - ETA: 3s - loss: 0.7067 - acc: 0.4219WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "6/6 [==============================] - 1s 49ms/step - loss: 0.7325 - acc: 0.5870 - val_loss: 0.7309 - val_acc: 0.6500\n",
      "Epoch 2/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7311 - acc: 0.5373 - val_loss: 0.7297 - val_acc: 0.3500\n",
      "Epoch 3/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7298 - acc: 0.3571 - val_loss: 0.7284 - val_acc: 0.3500\n",
      "Epoch 4/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7285 - acc: 0.3571 - val_loss: 0.7273 - val_acc: 0.3500\n",
      "Epoch 5/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7272 - acc: 0.3571 - val_loss: 0.7261 - val_acc: 0.3500\n",
      "Epoch 6/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7260 - acc: 0.3571 - val_loss: 0.7249 - val_acc: 0.3500\n",
      "Epoch 7/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7248 - acc: 0.3571 - val_loss: 0.7236 - val_acc: 0.3625\n",
      "Epoch 8/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7237 - acc: 0.3665 - val_loss: 0.7225 - val_acc: 0.3750\n",
      "Epoch 9/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7225 - acc: 0.3758 - val_loss: 0.7214 - val_acc: 0.4000\n",
      "Epoch 10/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7215 - acc: 0.4130 - val_loss: 0.7202 - val_acc: 0.5500\n",
      "Epoch 11/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7204 - acc: 0.6832 - val_loss: 0.7190 - val_acc: 0.7125\n",
      "Epoch 12/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7194 - acc: 0.6925 - val_loss: 0.7179 - val_acc: 0.7000\n",
      "Epoch 13/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7184 - acc: 0.6925 - val_loss: 0.7169 - val_acc: 0.7000\n",
      "Epoch 14/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7174 - acc: 0.6894 - val_loss: 0.7158 - val_acc: 0.6500\n",
      "Epoch 15/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7164 - acc: 0.6553 - val_loss: 0.7146 - val_acc: 0.6500\n",
      "Epoch 16/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7154 - acc: 0.6522 - val_loss: 0.7135 - val_acc: 0.6500\n",
      "Epoch 17/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7144 - acc: 0.6522 - val_loss: 0.7122 - val_acc: 0.6500\n",
      "Epoch 18/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7134 - acc: 0.6522 - val_loss: 0.7108 - val_acc: 0.6500\n",
      "Epoch 19/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7124 - acc: 0.6522 - val_loss: 0.7096 - val_acc: 0.6500\n",
      "Epoch 20/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7112 - acc: 0.6553 - val_loss: 0.7084 - val_acc: 0.6500\n",
      "Epoch 21/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7100 - acc: 0.6584 - val_loss: 0.7069 - val_acc: 0.6500\n",
      "Epoch 22/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7087 - acc: 0.6615 - val_loss: 0.7055 - val_acc: 0.6500\n",
      "Epoch 23/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7073 - acc: 0.6770 - val_loss: 0.7044 - val_acc: 0.6750\n",
      "Epoch 24/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7057 - acc: 0.7019 - val_loss: 0.7026 - val_acc: 0.6750\n",
      "Epoch 25/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7040 - acc: 0.7081 - val_loss: 0.7002 - val_acc: 0.6750\n",
      "Epoch 26/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7018 - acc: 0.7081 - val_loss: 0.6976 - val_acc: 0.6750\n",
      "Epoch 27/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6993 - acc: 0.7081 - val_loss: 0.6946 - val_acc: 0.6750\n",
      "Epoch 28/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6966 - acc: 0.7081 - val_loss: 0.6919 - val_acc: 0.6750\n",
      "Epoch 29/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6938 - acc: 0.7236 - val_loss: 0.6897 - val_acc: 0.7125\n",
      "Epoch 30/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6906 - acc: 0.7453 - val_loss: 0.6860 - val_acc: 0.7250\n",
      "Epoch 31/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6871 - acc: 0.7484 - val_loss: 0.6818 - val_acc: 0.7125\n",
      "Epoch 32/170\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6831 - acc: 0.7484 - val_loss: 0.6778 - val_acc: 0.7250\n",
      "Epoch 33/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6790 - acc: 0.7733 - val_loss: 0.6742 - val_acc: 0.7375\n",
      "Epoch 34/170\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6743 - acc: 0.8168 - val_loss: 0.6703 - val_acc: 0.7875\n",
      "Epoch 35/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6690 - acc: 0.8571 - val_loss: 0.6659 - val_acc: 0.8625\n",
      "Epoch 36/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6634 - acc: 0.8696 - val_loss: 0.6601 - val_acc: 0.8625\n",
      "Epoch 37/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6572 - acc: 0.8882 - val_loss: 0.6562 - val_acc: 0.8625\n",
      "Epoch 38/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6509 - acc: 0.8758 - val_loss: 0.6502 - val_acc: 0.8625\n",
      "Epoch 39/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6445 - acc: 0.8789 - val_loss: 0.6436 - val_acc: 0.8625\n",
      "Epoch 40/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6370 - acc: 0.8789 - val_loss: 0.6384 - val_acc: 0.8875\n",
      "Epoch 41/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6294 - acc: 0.8696 - val_loss: 0.6314 - val_acc: 0.8750\n",
      "Epoch 42/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6215 - acc: 0.8727 - val_loss: 0.6235 - val_acc: 0.8875\n",
      "Epoch 43/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6136 - acc: 0.8851 - val_loss: 0.6153 - val_acc: 0.8875\n",
      "Epoch 44/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6054 - acc: 0.8820 - val_loss: 0.6087 - val_acc: 0.8875\n",
      "Epoch 45/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5969 - acc: 0.8820 - val_loss: 0.6032 - val_acc: 0.8750\n",
      "Epoch 46/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5885 - acc: 0.8789 - val_loss: 0.5988 - val_acc: 0.8250\n",
      "Epoch 47/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5794 - acc: 0.8820 - val_loss: 0.5947 - val_acc: 0.7875\n",
      "Epoch 48/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5702 - acc: 0.8727 - val_loss: 0.5912 - val_acc: 0.7500\n",
      "Epoch 49/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5611 - acc: 0.8602 - val_loss: 0.5881 - val_acc: 0.7375\n",
      "Epoch 50/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5532 - acc: 0.7950 - val_loss: 0.5874 - val_acc: 0.7000\n",
      "Epoch 51/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5439 - acc: 0.7640 - val_loss: 0.5847 - val_acc: 0.7000\n",
      "Epoch 52/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5352 - acc: 0.7516 - val_loss: 0.5787 - val_acc: 0.7125\n",
      "Epoch 53/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5265 - acc: 0.7640 - val_loss: 0.5713 - val_acc: 0.7000\n",
      "Epoch 54/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5177 - acc: 0.7671 - val_loss: 0.5663 - val_acc: 0.7125\n",
      "Epoch 55/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5086 - acc: 0.7702 - val_loss: 0.5567 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4994 - acc: 0.7888 - val_loss: 0.5458 - val_acc: 0.7250\n",
      "Epoch 57/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4906 - acc: 0.8292 - val_loss: 0.5355 - val_acc: 0.7375\n",
      "Epoch 58/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4820 - acc: 0.8571 - val_loss: 0.5274 - val_acc: 0.7500\n",
      "Epoch 59/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4741 - acc: 0.8696 - val_loss: 0.5180 - val_acc: 0.7875\n",
      "Epoch 60/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4669 - acc: 0.8851 - val_loss: 0.5133 - val_acc: 0.7750\n",
      "Epoch 61/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4590 - acc: 0.8727 - val_loss: 0.5142 - val_acc: 0.7375\n",
      "Epoch 62/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4518 - acc: 0.8571 - val_loss: 0.5126 - val_acc: 0.7375\n",
      "Epoch 63/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4448 - acc: 0.8602 - val_loss: 0.5045 - val_acc: 0.7375\n",
      "Epoch 64/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4376 - acc: 0.8727 - val_loss: 0.4943 - val_acc: 0.7750\n",
      "Epoch 65/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4321 - acc: 0.8882 - val_loss: 0.4855 - val_acc: 0.8250\n",
      "Epoch 66/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4247 - acc: 0.8913 - val_loss: 0.4814 - val_acc: 0.8125\n",
      "Epoch 67/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4181 - acc: 0.8944 - val_loss: 0.4765 - val_acc: 0.8250\n",
      "Epoch 68/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4112 - acc: 0.8975 - val_loss: 0.4728 - val_acc: 0.8125\n",
      "Epoch 69/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4042 - acc: 0.8975 - val_loss: 0.4698 - val_acc: 0.8125\n",
      "Epoch 70/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3976 - acc: 0.8944 - val_loss: 0.4683 - val_acc: 0.7875\n",
      "Epoch 71/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3910 - acc: 0.8913 - val_loss: 0.4658 - val_acc: 0.7750\n",
      "Epoch 72/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3848 - acc: 0.8851 - val_loss: 0.4659 - val_acc: 0.7625\n",
      "Epoch 73/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3796 - acc: 0.8789 - val_loss: 0.4643 - val_acc: 0.7500\n",
      "Epoch 74/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3735 - acc: 0.8758 - val_loss: 0.4630 - val_acc: 0.7500\n",
      "Epoch 75/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3682 - acc: 0.8758 - val_loss: 0.4611 - val_acc: 0.7500\n",
      "Epoch 76/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3632 - acc: 0.8789 - val_loss: 0.4560 - val_acc: 0.7500\n",
      "Epoch 77/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3574 - acc: 0.8789 - val_loss: 0.4550 - val_acc: 0.7500\n",
      "Epoch 78/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3525 - acc: 0.8789 - val_loss: 0.4505 - val_acc: 0.7500\n",
      "Epoch 79/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3476 - acc: 0.8820 - val_loss: 0.4477 - val_acc: 0.7625\n",
      "Epoch 80/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3423 - acc: 0.8882 - val_loss: 0.4407 - val_acc: 0.7750\n",
      "Epoch 81/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3371 - acc: 0.8913 - val_loss: 0.4319 - val_acc: 0.8125\n",
      "Epoch 82/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3315 - acc: 0.9037 - val_loss: 0.4230 - val_acc: 0.8250\n",
      "Epoch 83/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3275 - acc: 0.9068 - val_loss: 0.4184 - val_acc: 0.8250\n",
      "Epoch 84/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3229 - acc: 0.9037 - val_loss: 0.4150 - val_acc: 0.8250\n",
      "Epoch 85/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3181 - acc: 0.9068 - val_loss: 0.4133 - val_acc: 0.8250\n",
      "Epoch 86/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3135 - acc: 0.9037 - val_loss: 0.4070 - val_acc: 0.8250\n",
      "Epoch 87/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3092 - acc: 0.9037 - val_loss: 0.4023 - val_acc: 0.8375\n",
      "Epoch 88/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3052 - acc: 0.9099 - val_loss: 0.4007 - val_acc: 0.8250\n",
      "Epoch 89/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3007 - acc: 0.9068 - val_loss: 0.4044 - val_acc: 0.8250\n",
      "Epoch 90/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2971 - acc: 0.9068 - val_loss: 0.4082 - val_acc: 0.8250\n",
      "Epoch 91/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2937 - acc: 0.9037 - val_loss: 0.4038 - val_acc: 0.8250\n",
      "Epoch 92/170\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2896 - acc: 0.9068 - val_loss: 0.3965 - val_acc: 0.8250\n",
      "Epoch 93/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2863 - acc: 0.9130 - val_loss: 0.3877 - val_acc: 0.8375\n",
      "Epoch 94/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2834 - acc: 0.9161 - val_loss: 0.3833 - val_acc: 0.8625\n",
      "Epoch 95/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2799 - acc: 0.9193 - val_loss: 0.3841 - val_acc: 0.8375\n",
      "Epoch 96/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2759 - acc: 0.9193 - val_loss: 0.3853 - val_acc: 0.8250\n",
      "Epoch 97/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2725 - acc: 0.9193 - val_loss: 0.3799 - val_acc: 0.8375\n",
      "Epoch 98/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2696 - acc: 0.9224 - val_loss: 0.3752 - val_acc: 0.8625\n",
      "Epoch 99/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2675 - acc: 0.9224 - val_loss: 0.3729 - val_acc: 0.8750\n",
      "Epoch 100/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2639 - acc: 0.9224 - val_loss: 0.3736 - val_acc: 0.8500\n",
      "Epoch 101/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2612 - acc: 0.9224 - val_loss: 0.3710 - val_acc: 0.8500\n",
      "Epoch 102/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2577 - acc: 0.9224 - val_loss: 0.3720 - val_acc: 0.8250\n",
      "Epoch 103/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2546 - acc: 0.9193 - val_loss: 0.3735 - val_acc: 0.8250\n",
      "Epoch 104/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2523 - acc: 0.9161 - val_loss: 0.3760 - val_acc: 0.8250\n",
      "Epoch 105/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2499 - acc: 0.9161 - val_loss: 0.3767 - val_acc: 0.8375\n",
      "Epoch 106/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2474 - acc: 0.9130 - val_loss: 0.3733 - val_acc: 0.8375\n",
      "Epoch 107/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2445 - acc: 0.9161 - val_loss: 0.3711 - val_acc: 0.8375\n",
      "Epoch 108/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2417 - acc: 0.9193 - val_loss: 0.3687 - val_acc: 0.8375\n",
      "Epoch 109/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2389 - acc: 0.9224 - val_loss: 0.3652 - val_acc: 0.8250\n",
      "Epoch 110/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2365 - acc: 0.9193 - val_loss: 0.3632 - val_acc: 0.8375\n",
      "Epoch 111/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2337 - acc: 0.9255 - val_loss: 0.3519 - val_acc: 0.8500\n",
      "Epoch 112/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2314 - acc: 0.9255 - val_loss: 0.3422 - val_acc: 0.8875\n",
      "Epoch 113/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2333 - acc: 0.9379 - val_loss: 0.3367 - val_acc: 0.9125\n",
      "Epoch 114/170\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2340 - acc: 0.9379 - val_loss: 0.3344 - val_acc: 0.9000\n",
      "Epoch 115/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2302 - acc: 0.9410 - val_loss: 0.3346 - val_acc: 0.9125\n",
      "Epoch 116/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2253 - acc: 0.9379 - val_loss: 0.3361 - val_acc: 0.8875\n",
      "Epoch 117/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2218 - acc: 0.9379 - val_loss: 0.3359 - val_acc: 0.8750\n",
      "Epoch 118/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2192 - acc: 0.9379 - val_loss: 0.3369 - val_acc: 0.8625\n",
      "Epoch 119/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2174 - acc: 0.9286 - val_loss: 0.3419 - val_acc: 0.8375\n",
      "Epoch 120/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2151 - acc: 0.9286 - val_loss: 0.3443 - val_acc: 0.8375\n",
      "Epoch 121/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2133 - acc: 0.9317 - val_loss: 0.3439 - val_acc: 0.8375\n",
      "Epoch 122/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2117 - acc: 0.9286 - val_loss: 0.3429 - val_acc: 0.8375\n",
      "Epoch 123/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2098 - acc: 0.9317 - val_loss: 0.3394 - val_acc: 0.8375\n",
      "Epoch 124/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2080 - acc: 0.9286 - val_loss: 0.3360 - val_acc: 0.8625\n",
      "Epoch 125/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2066 - acc: 0.9317 - val_loss: 0.3318 - val_acc: 0.8625\n",
      "Epoch 126/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2051 - acc: 0.9379 - val_loss: 0.3250 - val_acc: 0.8750\n",
      "Epoch 127/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2048 - acc: 0.9410 - val_loss: 0.3217 - val_acc: 0.8875\n",
      "Epoch 128/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2036 - acc: 0.9410 - val_loss: 0.3209 - val_acc: 0.8875\n",
      "Epoch 129/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2008 - acc: 0.9410 - val_loss: 0.3231 - val_acc: 0.8625\n",
      "Epoch 130/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1992 - acc: 0.9379 - val_loss: 0.3271 - val_acc: 0.8750\n",
      "Epoch 131/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1967 - acc: 0.9410 - val_loss: 0.3314 - val_acc: 0.8375\n",
      "Epoch 132/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1959 - acc: 0.9348 - val_loss: 0.3351 - val_acc: 0.8375\n",
      "Epoch 133/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1949 - acc: 0.9286 - val_loss: 0.3355 - val_acc: 0.8375\n",
      "Epoch 134/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1932 - acc: 0.9348 - val_loss: 0.3256 - val_acc: 0.8750\n",
      "Epoch 135/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1911 - acc: 0.9441 - val_loss: 0.3169 - val_acc: 0.8750\n",
      "Epoch 136/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1901 - acc: 0.9441 - val_loss: 0.3134 - val_acc: 0.8750\n",
      "Epoch 137/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1890 - acc: 0.9410 - val_loss: 0.3154 - val_acc: 0.8750\n",
      "Epoch 138/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1867 - acc: 0.9441 - val_loss: 0.3159 - val_acc: 0.8750\n",
      "Epoch 139/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1856 - acc: 0.9410 - val_loss: 0.3170 - val_acc: 0.8750\n",
      "Epoch 140/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1841 - acc: 0.9441 - val_loss: 0.3175 - val_acc: 0.8750\n",
      "Epoch 141/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1823 - acc: 0.9410 - val_loss: 0.3311 - val_acc: 0.8375\n",
      "Epoch 142/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1840 - acc: 0.9348 - val_loss: 0.3368 - val_acc: 0.8375\n",
      "Epoch 143/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1838 - acc: 0.9317 - val_loss: 0.3358 - val_acc: 0.8375\n",
      "Epoch 144/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1821 - acc: 0.9348 - val_loss: 0.3309 - val_acc: 0.8375\n",
      "Epoch 145/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1800 - acc: 0.9379 - val_loss: 0.3286 - val_acc: 0.8375\n",
      "Epoch 146/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1782 - acc: 0.9410 - val_loss: 0.3234 - val_acc: 0.8375\n",
      "Epoch 147/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1764 - acc: 0.9441 - val_loss: 0.3217 - val_acc: 0.8375\n",
      "Epoch 148/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1750 - acc: 0.9472 - val_loss: 0.3202 - val_acc: 0.8375\n",
      "Epoch 149/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1741 - acc: 0.9472 - val_loss: 0.3202 - val_acc: 0.8375\n",
      "Epoch 150/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1727 - acc: 0.9472 - val_loss: 0.3136 - val_acc: 0.8750\n",
      "Epoch 151/170\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1709 - acc: 0.9503 - val_loss: 0.3106 - val_acc: 0.8750\n",
      "Epoch 152/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1698 - acc: 0.9472 - val_loss: 0.3081 - val_acc: 0.8750\n",
      "Epoch 153/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1689 - acc: 0.9441 - val_loss: 0.3054 - val_acc: 0.8750\n",
      "Epoch 154/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1679 - acc: 0.9441 - val_loss: 0.3020 - val_acc: 0.8875\n",
      "Epoch 155/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1674 - acc: 0.9441 - val_loss: 0.3003 - val_acc: 0.8875\n",
      "Epoch 156/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1663 - acc: 0.9441 - val_loss: 0.3003 - val_acc: 0.8875\n",
      "Epoch 157/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1652 - acc: 0.9472 - val_loss: 0.3006 - val_acc: 0.8750\n",
      "Epoch 158/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1642 - acc: 0.9472 - val_loss: 0.3026 - val_acc: 0.8750\n",
      "Epoch 159/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1632 - acc: 0.9472 - val_loss: 0.3031 - val_acc: 0.8750\n",
      "Epoch 160/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1623 - acc: 0.9472 - val_loss: 0.3019 - val_acc: 0.8750\n",
      "Epoch 161/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1613 - acc: 0.9472 - val_loss: 0.2988 - val_acc: 0.8750\n",
      "Epoch 162/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1606 - acc: 0.9472 - val_loss: 0.2927 - val_acc: 0.8875\n",
      "Epoch 163/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1606 - acc: 0.9503 - val_loss: 0.2912 - val_acc: 0.8875\n",
      "Epoch 164/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1597 - acc: 0.9503 - val_loss: 0.2922 - val_acc: 0.8875\n",
      "Epoch 165/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1585 - acc: 0.9472 - val_loss: 0.2991 - val_acc: 0.8875\n",
      "Epoch 166/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1570 - acc: 0.9472 - val_loss: 0.3068 - val_acc: 0.8875\n",
      "Epoch 167/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1571 - acc: 0.9503 - val_loss: 0.3089 - val_acc: 0.8750\n",
      "Epoch 168/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1565 - acc: 0.9503 - val_loss: 0.3093 - val_acc: 0.8750\n",
      "Epoch 169/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1564 - acc: 0.9503 - val_loss: 0.3131 - val_acc: 0.8625\n",
      "Epoch 170/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1555 - acc: 0.9503 - val_loss: 0.3085 - val_acc: 0.8750\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "[[43  9]\n",
      " [ 1 27]]\n",
      "(0.75, 0.875, 0.9642857142857143, 0.8437499999999999, 0.963598901098901, 0.9452489732882279, 0.9443589591076411)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1000)]            0         \n",
      "                                                                 \n",
      " biological_module_4 (Biolog  (None, 238)              3170      \n",
      " ical_module)                                                    \n",
      "                                                                 \n",
      " self__attention_22 (Self_At  (None, 64)               45696     \n",
      " tention)                                                        \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 33        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,979\n",
      "Trainable params: 50,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/170\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "1/6 [====>.........................] - ETA: 3s - loss: 0.7543 - acc: 0.6094WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "6/6 [==============================] - 1s 50ms/step - loss: 0.7311 - acc: 0.4565 - val_loss: 0.7310 - val_acc: 0.4250\n",
      "Epoch 2/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7298 - acc: 0.3882 - val_loss: 0.7299 - val_acc: 0.3875\n",
      "Epoch 3/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7284 - acc: 0.3540 - val_loss: 0.7287 - val_acc: 0.3750\n",
      "Epoch 4/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7271 - acc: 0.3665 - val_loss: 0.7273 - val_acc: 0.4125\n",
      "Epoch 5/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7258 - acc: 0.3913 - val_loss: 0.7260 - val_acc: 0.4500\n",
      "Epoch 6/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7246 - acc: 0.5000 - val_loss: 0.7246 - val_acc: 0.4500\n",
      "Epoch 7/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7234 - acc: 0.6615 - val_loss: 0.7231 - val_acc: 0.6375\n",
      "Epoch 8/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7222 - acc: 0.6429 - val_loss: 0.7216 - val_acc: 0.6375\n",
      "Epoch 9/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7210 - acc: 0.6460 - val_loss: 0.7201 - val_acc: 0.6375\n",
      "Epoch 10/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7198 - acc: 0.6460 - val_loss: 0.7185 - val_acc: 0.6375\n",
      "Epoch 11/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7186 - acc: 0.6460 - val_loss: 0.7170 - val_acc: 0.6375\n",
      "Epoch 12/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7175 - acc: 0.6460 - val_loss: 0.7157 - val_acc: 0.6375\n",
      "Epoch 13/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7163 - acc: 0.6460 - val_loss: 0.7143 - val_acc: 0.6375\n",
      "Epoch 14/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7151 - acc: 0.6460 - val_loss: 0.7130 - val_acc: 0.6375\n",
      "Epoch 15/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7139 - acc: 0.6491 - val_loss: 0.7119 - val_acc: 0.6375\n",
      "Epoch 16/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7126 - acc: 0.6491 - val_loss: 0.7108 - val_acc: 0.6375\n",
      "Epoch 17/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7113 - acc: 0.6522 - val_loss: 0.7095 - val_acc: 0.6375\n",
      "Epoch 18/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7098 - acc: 0.6522 - val_loss: 0.7078 - val_acc: 0.6375\n",
      "Epoch 19/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7083 - acc: 0.6522 - val_loss: 0.7063 - val_acc: 0.6375\n",
      "Epoch 20/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7067 - acc: 0.6739 - val_loss: 0.7054 - val_acc: 0.6625\n",
      "Epoch 21/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7050 - acc: 0.7143 - val_loss: 0.7041 - val_acc: 0.6875\n",
      "Epoch 22/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7030 - acc: 0.7360 - val_loss: 0.7021 - val_acc: 0.6875\n",
      "Epoch 23/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7009 - acc: 0.7547 - val_loss: 0.7001 - val_acc: 0.6875\n",
      "Epoch 24/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6986 - acc: 0.7888 - val_loss: 0.6982 - val_acc: 0.7125\n",
      "Epoch 25/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6960 - acc: 0.8323 - val_loss: 0.6962 - val_acc: 0.7250\n",
      "Epoch 26/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6932 - acc: 0.8913 - val_loss: 0.6938 - val_acc: 0.7000\n",
      "Epoch 27/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6899 - acc: 0.8913 - val_loss: 0.6903 - val_acc: 0.7375\n",
      "Epoch 28/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6863 - acc: 0.8696 - val_loss: 0.6864 - val_acc: 0.7375\n",
      "Epoch 29/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6827 - acc: 0.8540 - val_loss: 0.6828 - val_acc: 0.7250\n",
      "Epoch 30/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6785 - acc: 0.8416 - val_loss: 0.6780 - val_acc: 0.7250\n",
      "Epoch 31/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6740 - acc: 0.8168 - val_loss: 0.6730 - val_acc: 0.7125\n",
      "Epoch 32/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6695 - acc: 0.7888 - val_loss: 0.6674 - val_acc: 0.7000\n",
      "Epoch 33/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6644 - acc: 0.7640 - val_loss: 0.6619 - val_acc: 0.7000\n",
      "Epoch 34/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6591 - acc: 0.7578 - val_loss: 0.6571 - val_acc: 0.7000\n",
      "Epoch 35/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6532 - acc: 0.7764 - val_loss: 0.6536 - val_acc: 0.7125\n",
      "Epoch 36/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6469 - acc: 0.8323 - val_loss: 0.6509 - val_acc: 0.7375\n",
      "Epoch 37/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6400 - acc: 0.8727 - val_loss: 0.6460 - val_acc: 0.7250\n",
      "Epoch 38/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6331 - acc: 0.8758 - val_loss: 0.6399 - val_acc: 0.7250\n",
      "Epoch 39/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6255 - acc: 0.8727 - val_loss: 0.6334 - val_acc: 0.7250\n",
      "Epoch 40/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6177 - acc: 0.8913 - val_loss: 0.6278 - val_acc: 0.7500\n",
      "Epoch 41/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6091 - acc: 0.8975 - val_loss: 0.6215 - val_acc: 0.7625\n",
      "Epoch 42/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6005 - acc: 0.9037 - val_loss: 0.6155 - val_acc: 0.7750\n",
      "Epoch 43/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5918 - acc: 0.9130 - val_loss: 0.6087 - val_acc: 0.7750\n",
      "Epoch 44/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5834 - acc: 0.9161 - val_loss: 0.6016 - val_acc: 0.7750\n",
      "Epoch 45/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5753 - acc: 0.9037 - val_loss: 0.5944 - val_acc: 0.7500\n",
      "Epoch 46/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5672 - acc: 0.9006 - val_loss: 0.5871 - val_acc: 0.7500\n",
      "Epoch 47/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5598 - acc: 0.8851 - val_loss: 0.5800 - val_acc: 0.7375\n",
      "Epoch 48/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5523 - acc: 0.8820 - val_loss: 0.5734 - val_acc: 0.7250\n",
      "Epoch 49/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5447 - acc: 0.8820 - val_loss: 0.5672 - val_acc: 0.7375\n",
      "Epoch 50/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5356 - acc: 0.8975 - val_loss: 0.5628 - val_acc: 0.7750\n",
      "Epoch 51/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5256 - acc: 0.9255 - val_loss: 0.5580 - val_acc: 0.8000\n",
      "Epoch 52/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5157 - acc: 0.9068 - val_loss: 0.5530 - val_acc: 0.8375\n",
      "Epoch 53/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5061 - acc: 0.9099 - val_loss: 0.5503 - val_acc: 0.8375\n",
      "Epoch 54/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4950 - acc: 0.9006 - val_loss: 0.5481 - val_acc: 0.8250\n",
      "Epoch 55/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4860 - acc: 0.8696 - val_loss: 0.5467 - val_acc: 0.8250\n",
      "Epoch 56/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4772 - acc: 0.8478 - val_loss: 0.5419 - val_acc: 0.8125\n",
      "Epoch 57/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4691 - acc: 0.8509 - val_loss: 0.5332 - val_acc: 0.8375\n",
      "Epoch 58/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4615 - acc: 0.8789 - val_loss: 0.5251 - val_acc: 0.8375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4536 - acc: 0.8789 - val_loss: 0.5225 - val_acc: 0.8250\n",
      "Epoch 60/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4449 - acc: 0.8478 - val_loss: 0.5229 - val_acc: 0.8125\n",
      "Epoch 61/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4382 - acc: 0.8323 - val_loss: 0.5204 - val_acc: 0.8125\n",
      "Epoch 62/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4321 - acc: 0.8261 - val_loss: 0.5165 - val_acc: 0.8125\n",
      "Epoch 63/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4246 - acc: 0.8292 - val_loss: 0.5071 - val_acc: 0.8125\n",
      "Epoch 64/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4169 - acc: 0.8447 - val_loss: 0.4955 - val_acc: 0.8375\n",
      "Epoch 65/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4099 - acc: 0.8789 - val_loss: 0.4872 - val_acc: 0.8375\n",
      "Epoch 66/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4036 - acc: 0.8882 - val_loss: 0.4813 - val_acc: 0.8500\n",
      "Epoch 67/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3977 - acc: 0.9037 - val_loss: 0.4739 - val_acc: 0.8375\n",
      "Epoch 68/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3918 - acc: 0.9068 - val_loss: 0.4688 - val_acc: 0.8500\n",
      "Epoch 69/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3859 - acc: 0.9099 - val_loss: 0.4642 - val_acc: 0.8500\n",
      "Epoch 70/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3808 - acc: 0.9099 - val_loss: 0.4587 - val_acc: 0.8750\n",
      "Epoch 71/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3744 - acc: 0.9099 - val_loss: 0.4568 - val_acc: 0.8375\n",
      "Epoch 72/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3679 - acc: 0.9068 - val_loss: 0.4560 - val_acc: 0.8500\n",
      "Epoch 73/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3621 - acc: 0.8882 - val_loss: 0.4570 - val_acc: 0.8375\n",
      "Epoch 74/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3573 - acc: 0.8789 - val_loss: 0.4535 - val_acc: 0.8375\n",
      "Epoch 75/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3520 - acc: 0.8789 - val_loss: 0.4486 - val_acc: 0.8375\n",
      "Epoch 76/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3467 - acc: 0.8820 - val_loss: 0.4443 - val_acc: 0.8375\n",
      "Epoch 77/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3416 - acc: 0.8851 - val_loss: 0.4438 - val_acc: 0.8375\n",
      "Epoch 78/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3380 - acc: 0.8696 - val_loss: 0.4447 - val_acc: 0.8250\n",
      "Epoch 79/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3334 - acc: 0.8696 - val_loss: 0.4377 - val_acc: 0.8375\n",
      "Epoch 80/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3273 - acc: 0.8851 - val_loss: 0.4289 - val_acc: 0.8375\n",
      "Epoch 81/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3217 - acc: 0.9037 - val_loss: 0.4201 - val_acc: 0.8750\n",
      "Epoch 82/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3167 - acc: 0.9130 - val_loss: 0.4166 - val_acc: 0.8750\n",
      "Epoch 83/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3123 - acc: 0.9130 - val_loss: 0.4143 - val_acc: 0.8750\n",
      "Epoch 84/170\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3082 - acc: 0.9099 - val_loss: 0.4128 - val_acc: 0.8500\n",
      "Epoch 85/170\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3040 - acc: 0.9068 - val_loss: 0.4082 - val_acc: 0.8750\n",
      "Epoch 86/170\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2998 - acc: 0.9130 - val_loss: 0.4032 - val_acc: 0.8625\n",
      "Epoch 87/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2955 - acc: 0.9161 - val_loss: 0.3993 - val_acc: 0.8750\n",
      "Epoch 88/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2918 - acc: 0.9193 - val_loss: 0.3952 - val_acc: 0.8750\n",
      "Epoch 89/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2889 - acc: 0.9255 - val_loss: 0.3918 - val_acc: 0.8875\n",
      "Epoch 90/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2846 - acc: 0.9255 - val_loss: 0.3902 - val_acc: 0.8750\n",
      "Epoch 91/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2807 - acc: 0.9224 - val_loss: 0.3896 - val_acc: 0.8750\n",
      "Epoch 92/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2763 - acc: 0.9193 - val_loss: 0.3876 - val_acc: 0.8750\n",
      "Epoch 93/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2728 - acc: 0.9193 - val_loss: 0.3857 - val_acc: 0.8750\n",
      "Epoch 94/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2693 - acc: 0.9161 - val_loss: 0.3837 - val_acc: 0.8750\n",
      "Epoch 95/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2668 - acc: 0.9161 - val_loss: 0.3787 - val_acc: 0.8875\n",
      "Epoch 96/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2629 - acc: 0.9348 - val_loss: 0.3757 - val_acc: 0.8875\n",
      "Epoch 97/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2607 - acc: 0.9410 - val_loss: 0.3735 - val_acc: 0.8750\n",
      "Epoch 98/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2582 - acc: 0.9441 - val_loss: 0.3716 - val_acc: 0.8750\n",
      "Epoch 99/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2544 - acc: 0.9410 - val_loss: 0.3701 - val_acc: 0.8750\n",
      "Epoch 100/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2506 - acc: 0.9348 - val_loss: 0.3688 - val_acc: 0.8750\n",
      "Epoch 101/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2472 - acc: 0.9317 - val_loss: 0.3693 - val_acc: 0.8875\n",
      "Epoch 102/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2441 - acc: 0.9224 - val_loss: 0.3714 - val_acc: 0.8625\n",
      "Epoch 103/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2435 - acc: 0.9161 - val_loss: 0.3698 - val_acc: 0.8625\n",
      "Epoch 104/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2404 - acc: 0.9161 - val_loss: 0.3664 - val_acc: 0.8625\n",
      "Epoch 105/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2373 - acc: 0.9193 - val_loss: 0.3648 - val_acc: 0.8625\n",
      "Epoch 106/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2348 - acc: 0.9193 - val_loss: 0.3626 - val_acc: 0.8625\n",
      "Epoch 107/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2320 - acc: 0.9224 - val_loss: 0.3606 - val_acc: 0.8625\n",
      "Epoch 108/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2294 - acc: 0.9255 - val_loss: 0.3589 - val_acc: 0.8625\n",
      "Epoch 109/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2269 - acc: 0.9255 - val_loss: 0.3565 - val_acc: 0.8625\n",
      "Epoch 110/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2238 - acc: 0.9286 - val_loss: 0.3533 - val_acc: 0.8750\n",
      "Epoch 111/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2210 - acc: 0.9317 - val_loss: 0.3516 - val_acc: 0.8750\n",
      "Epoch 112/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2184 - acc: 0.9317 - val_loss: 0.3493 - val_acc: 0.8875\n",
      "Epoch 113/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2156 - acc: 0.9348 - val_loss: 0.3465 - val_acc: 0.8750\n",
      "Epoch 114/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2128 - acc: 0.9379 - val_loss: 0.3443 - val_acc: 0.8750\n",
      "Epoch 115/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2107 - acc: 0.9472 - val_loss: 0.3430 - val_acc: 0.8750\n",
      "Epoch 116/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2094 - acc: 0.9441 - val_loss: 0.3428 - val_acc: 0.8750\n",
      "Epoch 117/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2061 - acc: 0.9410 - val_loss: 0.3402 - val_acc: 0.8750\n",
      "Epoch 118/170\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2037 - acc: 0.9503 - val_loss: 0.3389 - val_acc: 0.8875\n",
      "Epoch 119/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2027 - acc: 0.9472 - val_loss: 0.3383 - val_acc: 0.8750\n",
      "Epoch 120/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2011 - acc: 0.9534 - val_loss: 0.3374 - val_acc: 0.8625\n",
      "Epoch 121/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1991 - acc: 0.9534 - val_loss: 0.3359 - val_acc: 0.8750\n",
      "Epoch 122/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1966 - acc: 0.9472 - val_loss: 0.3347 - val_acc: 0.8875\n",
      "Epoch 123/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1944 - acc: 0.9472 - val_loss: 0.3337 - val_acc: 0.8750\n",
      "Epoch 124/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1926 - acc: 0.9503 - val_loss: 0.3328 - val_acc: 0.8750\n",
      "Epoch 125/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1911 - acc: 0.9503 - val_loss: 0.3322 - val_acc: 0.8750\n",
      "Epoch 126/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1891 - acc: 0.9503 - val_loss: 0.3309 - val_acc: 0.8750\n",
      "Epoch 127/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1873 - acc: 0.9503 - val_loss: 0.3300 - val_acc: 0.8875\n",
      "Epoch 128/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1856 - acc: 0.9472 - val_loss: 0.3292 - val_acc: 0.8625\n",
      "Epoch 129/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1844 - acc: 0.9627 - val_loss: 0.3282 - val_acc: 0.8625\n",
      "Epoch 130/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1818 - acc: 0.9534 - val_loss: 0.3270 - val_acc: 0.8750\n",
      "Epoch 131/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1821 - acc: 0.9472 - val_loss: 0.3280 - val_acc: 0.8875\n",
      "Epoch 132/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1806 - acc: 0.9410 - val_loss: 0.3271 - val_acc: 0.8875\n",
      "Epoch 133/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1782 - acc: 0.9472 - val_loss: 0.3247 - val_acc: 0.8750\n",
      "Epoch 134/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1759 - acc: 0.9503 - val_loss: 0.3232 - val_acc: 0.8875\n",
      "Epoch 135/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1743 - acc: 0.9503 - val_loss: 0.3225 - val_acc: 0.8875\n",
      "Epoch 136/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1730 - acc: 0.9503 - val_loss: 0.3218 - val_acc: 0.8875\n",
      "Epoch 137/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1717 - acc: 0.9503 - val_loss: 0.3212 - val_acc: 0.8750\n",
      "Epoch 138/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1700 - acc: 0.9596 - val_loss: 0.3206 - val_acc: 0.8625\n",
      "Epoch 139/170\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1688 - acc: 0.9689 - val_loss: 0.3201 - val_acc: 0.8750\n",
      "Epoch 140/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1679 - acc: 0.9658 - val_loss: 0.3195 - val_acc: 0.8750\n",
      "Epoch 141/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1663 - acc: 0.9658 - val_loss: 0.3181 - val_acc: 0.8750\n",
      "Epoch 142/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1650 - acc: 0.9689 - val_loss: 0.3170 - val_acc: 0.8875\n",
      "Epoch 143/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1634 - acc: 0.9658 - val_loss: 0.3162 - val_acc: 0.8875\n",
      "Epoch 144/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1625 - acc: 0.9689 - val_loss: 0.3162 - val_acc: 0.8875\n",
      "Epoch 145/170\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1614 - acc: 0.9689 - val_loss: 0.3159 - val_acc: 0.8750\n",
      "Epoch 146/170\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1603 - acc: 0.9689 - val_loss: 0.3146 - val_acc: 0.8875\n",
      "Epoch 147/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1592 - acc: 0.9596 - val_loss: 0.3130 - val_acc: 0.9000\n",
      "Epoch 148/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1575 - acc: 0.9534 - val_loss: 0.3124 - val_acc: 0.8875\n",
      "Epoch 149/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1564 - acc: 0.9534 - val_loss: 0.3119 - val_acc: 0.8875\n",
      "Epoch 150/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1554 - acc: 0.9534 - val_loss: 0.3113 - val_acc: 0.8875\n",
      "Epoch 151/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1541 - acc: 0.9534 - val_loss: 0.3106 - val_acc: 0.9000\n",
      "Epoch 152/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1529 - acc: 0.9565 - val_loss: 0.3101 - val_acc: 0.8875\n",
      "Epoch 153/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1519 - acc: 0.9689 - val_loss: 0.3097 - val_acc: 0.8750\n",
      "Epoch 154/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1508 - acc: 0.9627 - val_loss: 0.3091 - val_acc: 0.8875\n",
      "Epoch 155/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1504 - acc: 0.9689 - val_loss: 0.3092 - val_acc: 0.8875\n",
      "Epoch 156/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1490 - acc: 0.9627 - val_loss: 0.3080 - val_acc: 0.8875\n",
      "Epoch 157/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1481 - acc: 0.9534 - val_loss: 0.3077 - val_acc: 0.8875\n",
      "Epoch 158/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1474 - acc: 0.9534 - val_loss: 0.3074 - val_acc: 0.8875\n",
      "Epoch 159/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1466 - acc: 0.9534 - val_loss: 0.3070 - val_acc: 0.8875\n",
      "Epoch 160/170\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1454 - acc: 0.9534 - val_loss: 0.3062 - val_acc: 0.8875\n",
      "Epoch 161/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1441 - acc: 0.9565 - val_loss: 0.3057 - val_acc: 0.8750\n",
      "Epoch 162/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1432 - acc: 0.9689 - val_loss: 0.3055 - val_acc: 0.8625\n",
      "Epoch 163/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1422 - acc: 0.9689 - val_loss: 0.3052 - val_acc: 0.8750\n",
      "Epoch 164/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1414 - acc: 0.9689 - val_loss: 0.3058 - val_acc: 0.9000\n",
      "Epoch 165/170\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1408 - acc: 0.9689 - val_loss: 0.3046 - val_acc: 0.8750\n",
      "Epoch 166/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1394 - acc: 0.9689 - val_loss: 0.3042 - val_acc: 0.8750\n",
      "Epoch 167/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1385 - acc: 0.9689 - val_loss: 0.3036 - val_acc: 0.8625\n",
      "Epoch 168/170\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1378 - acc: 0.9627 - val_loss: 0.3038 - val_acc: 0.9000\n",
      "Epoch 169/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1376 - acc: 0.9534 - val_loss: 0.3032 - val_acc: 0.9000\n",
      "Epoch 170/170\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1357 - acc: 0.9689 - val_loss: 0.3033 - val_acc: 0.8875\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "[[46  5]\n",
      " [ 4 25]]\n",
      "(0.8333333333333334, 0.8875, 0.8620689655172413, 0.847457627118644, 0.9546991210277214, 0.9290617794485442, 0.9276380632009116)\n",
      "Cross validated results :  ACC = 0.8681481481481482, REC = 0.888423645320197, F1 = 0.8272949363174359, AUC = 0.9500010216288107, AUPR =0.9313551161410212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=1029)\n",
    "\n",
    "kfscore = []\n",
    "for train_index, test_index in skf.split(snv_data.values,y):\n",
    "\n",
    "    single_train_x = snv_data.values[train_index]\n",
    "    single_test_x  = snv_data.values[test_index]\n",
    "\n",
    "    train_y  = y[train_index]\n",
    "    test_y   = y[test_index]\n",
    "\n",
    "\n",
    "    single_model = create_single_model(single_train_x,0)\n",
    "\n",
    "\n",
    "    single_model.fit(single_train_x,train_y,validation_data=(single_test_x,test_y),\n",
    "                      epochs=170,batch_size = 64,class_weight = {0:x_0,1:x_1}) \n",
    "\n",
    "    y_pred = single_model.predict(single_test_x)\n",
    "\n",
    "    evaluate_epoch = evaluates(test_y,y_pred)\n",
    "    print(evaluate_epoch)\n",
    "    kfscore.append(evaluate_epoch)\n",
    "    \n",
    "results = list(np.array(kfscore).sum(axis= 0)/5.0)   \n",
    "print('Cross validated results :  ACC = {}, REC = {}, F1 = {}, AUC = {}, AUPR ={}'.format(results[1],results[2],results[3],results[4],results[5]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e535d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnet_env",
   "language": "python",
   "name": "pnet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
