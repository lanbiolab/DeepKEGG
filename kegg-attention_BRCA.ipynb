{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094868a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ed8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genes-pathways annotation\n",
    "\n",
    "path = './KEGG_pathways/20230205_kegg_hsa.gmt'\n",
    "\n",
    "files = open(path,encoding='utf-8')\n",
    "\n",
    "files = files.readlines()\n",
    "\n",
    "paways_genes_dict = {}\n",
    "for i in files:  \n",
    "    paways_genes_dict[i.split('\\t')[0].split('_')[0]] = i.replace('\\n','').split('\\t')[2:] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376544fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mirna-pathways annotation\n",
    "path = './KEGG_pathways/kegg_anano.txt'\n",
    "\n",
    "files = open(path,encoding='utf-8')\n",
    "\n",
    "files = files.readlines()\n",
    "\n",
    "paways_mirna_dict = {}\n",
    "for i in files:\n",
    "     keys = i.split(',')[0].split('|')[1]\n",
    "     values1 = i.split(',')[1:-1]\n",
    "     values2 =  i.split(',')[-1].replace('\\n','')\n",
    "     values1.append(values2)\n",
    "     values1 =list(set(values1)) \n",
    "     paways_mirna_dict[keys] = values1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27293b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_kegg = list(set(paways_genes_dict.keys()).intersection(set(paways_mirna_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cde7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "paways_genes_dicts ={}\n",
    "paways_mirna_dicts ={}\n",
    "\n",
    "for i in union_kegg:\n",
    "    paways_genes_dicts[i] = paways_genes_dict[i]\n",
    "    \n",
    "for i in union_kegg:\n",
    "    paways_mirna_dicts[i] = paways_mirna_dict[i]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fe7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genes_existed_pathway = []\n",
    "\n",
    "mirna_existed_pathway = []\n",
    "\n",
    "\n",
    "for index in paways_genes_dicts.keys():\n",
    "    genes_existed_pathway = genes_existed_pathway+ list(paways_genes_dicts[index])\n",
    "genes_existed_pathway = set(genes_existed_pathway)\n",
    "\n",
    "\n",
    "for index in paways_mirna_dicts.keys():\n",
    "    mirna_existed_pathway = mirna_existed_pathway+ list(paways_mirna_dicts[index])\n",
    "mirna_existed_pathway = set(mirna_existed_pathway)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d8c874f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7768\n",
      "812\n"
     ]
    }
   ],
   "source": [
    "print(len(genes_existed_pathway))\n",
    "print(len(mirna_existed_pathway))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948c50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3877bbba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading data\n",
    "snv_data = pd.read_csv(\"./BRCA_data/snv_data.csv\",index_col = 0)\n",
    "\n",
    "miRNA_data = pd.read_csv(\"./BRCA_data/miRNA_data.csv\",index_col = 0)\n",
    "\n",
    "mRNA_data = pd.read_csv(\"./BRCA_data/mRNA_data.csv\",index_col = 0)\n",
    "\n",
    "example_case = pd.read_csv('./BRCA_data/response.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8a004d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211, 1000)\n",
      "(211, 1000)\n",
      "(211, 100)\n"
     ]
    }
   ],
   "source": [
    "print(snv_data.shape)\n",
    "print(mRNA_data.shape)\n",
    "print(miRNA_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5295fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_gene_snv = list(snv_data.columns)\n",
    "union_gene_miRNA = list(miRNA_data.columns)\n",
    "union_gene_mRNA = list(mRNA_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0b65eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathway_union = list(paways_genes_dicts.keys())\n",
    "len(pathway_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0608bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_list = [union_gene_snv,union_gene_mRNA]\n",
    "\n",
    "gene_pathway_bp_dfs = []\n",
    "\n",
    "\n",
    "for i in range(len(mask_list)):\n",
    "    pathways_genes = np.zeros((len(pathway_union), len(mask_list[i]))) \n",
    "    for p  in pathway_union:\n",
    "        gs = paways_genes_dicts[p]\n",
    "        g_inds = [mask_list[i].index(g) for g in gs if g in mask_list[i]]\n",
    "        p_ind = pathway_union.index(p)\n",
    "        pathways_genes[p_ind, g_inds] = 1\n",
    "    gene_pathway_bp = pd.DataFrame(pathways_genes, index=pathway_union, columns=mask_list[i])\n",
    "    \n",
    "#     gene_pathway_bp = gene_pathway_bp.loc[:, (gene_pathway_bp != 0).any(axis=0)]\n",
    "    gene_pathway_bp_dfs.append(gene_pathway_bp)\n",
    "    \n",
    "\n",
    "pathways_genes = np.zeros((len(pathway_union), len(union_gene_miRNA))) \n",
    "for p  in pathway_union:\n",
    "    gs = paways_mirna_dicts[p]\n",
    "    g_inds = [union_gene_miRNA.index(g) for g in gs if g in union_gene_miRNA]\n",
    "    p_ind = pathway_union.index(p)\n",
    "    pathways_genes[p_ind, g_inds] = 1\n",
    "gene_pathway_bp = pd.DataFrame(pathways_genes, index=pathway_union, columns=union_gene_miRNA)\n",
    "\n",
    "\n",
    "#     gene_pathway_bp = gene_pathway_bp.loc[:, (gene_pathway_bp != 0).any(axis=0)]\n",
    "gene_pathway_bp_dfs.append(gene_pathway_bp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "125e5848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import glorot_uniform, Initializer\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, GlobalAveragePooling1D,Layer\n",
    "from tensorflow.keras import initializers,activations,regularizers\n",
    "from tensorflow.keras.regularizers import Regularizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11f21ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Biological_module(Layer):\n",
    "    def __init__(self, units, mapp=None, nonzero_ind=None, kernel_initializer='glorot_uniform', W_regularizer=None,\n",
    "                 activation='tanh', use_bias=True,bias_initializer='zeros', bias_regularizer=None,\n",
    "                 bias_constraint=None,**kwargs):\n",
    "        \n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.mapp = mapp\n",
    "        self.nonzero_ind = nonzero_ind\n",
    "        self.use_bias = use_bias\n",
    "        \n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(W_regularizer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activation_fn = activations.get(activation)\n",
    "        super(Biological_module, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        input_dim = input_shape[1]\n",
    "   \n",
    "\n",
    "        if not self.mapp is None:\n",
    "            self.mapp = self.mapp.astype(np.float32)\n",
    "\n",
    "   \n",
    "        if self.nonzero_ind is None:\n",
    "            nonzero_ind = np.array(np.nonzero(self.mapp)).T\n",
    "            self.nonzero_ind = nonzero_ind\n",
    "\n",
    "        self.kernel_shape = (input_dim, self.units)\n",
    "        \n",
    "\n",
    "        nonzero_count = self.nonzero_ind.shape[0]   # node and node  connection nunber \n",
    "\n",
    "\n",
    "        self.kernel_vector = self.add_weight(name='kernel_vector',\n",
    "                                             shape=(nonzero_count,),\n",
    "                                             initializer=self.kernel_initializer,\n",
    "                                             regularizer=self.kernel_regularizer,\n",
    "                                             trainable=True)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer\n",
    "                                        )\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        super(Biological_module, self).build(input_shape)  \n",
    "      \n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        \n",
    "        trans = tf.scatter_nd(tf.constant(self.nonzero_ind, tf.int32), self.kernel_vector,\n",
    "                           tf.constant(list(self.kernel_shape)))\n",
    "    \n",
    "        output = K.dot(inputs, trans)\n",
    "        \n",
    "    \n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias)\n",
    "            \n",
    "        if self.activation_fn is not None:\n",
    "            output = self.activation_fn(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'activation': self.activation,\n",
    "            'use_bias': self.use_bias,\n",
    "            'nonzero_ind': np.array(self.nonzero_ind),\n",
    "          \n",
    "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "\n",
    "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "            'W_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "\n",
    "        }\n",
    "        base_config = super(Biological_module, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "      \n",
    "        return (input_shape[0], self.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c438cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attention(Layer):\n",
    " \n",
    "    def __init__(self, output_dim,  W_regularizer=None,**kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.kernel_regularizer = regularizers.get(W_regularizer)\n",
    "        super(Self_Attention, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(3,input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      trainable=True)\n",
    " \n",
    "        super(Self_Attention, self).build(input_shape) \n",
    " \n",
    "    def call(self, x):\n",
    "        WQ = K.dot(x, self.kernel[0])\n",
    "        WK = K.dot(x, self.kernel[1])\n",
    "        WV = K.dot(x, self.kernel[2])\n",
    " \n",
    "        print(\"WQ.shape\",WQ.shape)\n",
    " \n",
    "        print(\"K.permute_dimensions(WK.shape\",(K.permute_dimensions(WK,[1,0]).shape))\n",
    " \n",
    "        QK =  K.dot(K.permute_dimensions(WK,[1,0]),WQ)\n",
    "    \n",
    " \n",
    "        QK = QK / (64**0.5)\n",
    " \n",
    "        QK = K.softmax(QK)\n",
    " \n",
    "        print(\"QK.shape\",QK.shape)\n",
    " \n",
    "        V = K.dot(WV,QK)\n",
    "        \n",
    "        print(V.shape)\n",
    " \n",
    "        return V\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          \n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "\n",
    "\n",
    "        }\n",
    "        base_config = super(Self_Attention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    " \n",
    "        return (input_shape[0],input_shape[1],self.output_dim)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab00da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "020e30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(snv_data,mRNA_data,miRNA_data):\n",
    "\n",
    "    \n",
    "    S_inputs_snv = Input(shape=(snv_data.shape[1],), dtype='float32',name= 'snv_inputs')\n",
    "    \n",
    "    S_inputs_mRNA = Input(shape=(mRNA_data.shape[1],), dtype='float32',name= 'mRNA_inputs')\n",
    "  \n",
    "    S_inputs_miRNA = Input(shape=(miRNA_data.shape[1],), dtype='float32',name= 'miRNA_inputs')\n",
    "    \n",
    "\n",
    "    h0_snv = Biological_module(gene_pathway_bp_dfs[0].shape[0],mapp =gene_pathway_bp_dfs[0].values.T, name = 'h0_snv',W_regularizer=l2(0.001))(S_inputs_snv)\n",
    "\n",
    "    \n",
    "    h0_mRNA = Biological_module(gene_pathway_bp_dfs[1].shape[0],mapp =gene_pathway_bp_dfs[1].values.T, name = 'h0_mRNA',W_regularizer=l2(0.001))(S_inputs_mRNA)\n",
    "\n",
    "    \n",
    "    h0_miRNA = Biological_module(gene_pathway_bp_dfs[2].shape[0],mapp =gene_pathway_bp_dfs[2].values.T, name = 'h0_miRNA',W_regularizer=l2(0.001))(S_inputs_miRNA)\n",
    "\n",
    "\n",
    "    atten1 = Self_Attention(64,W_regularizer=l2(0.001))(h0_snv)\n",
    "    atten2 = Self_Attention(64,W_regularizer=l2(0.01))(h0_mRNA)\n",
    "    atten3 = Self_Attention(64,W_regularizer=l2(0.01))(h0_miRNA)\n",
    "    \n",
    "    feature_tal = tf.keras.layers.concatenate([atten1,atten2,atten3])\n",
    "\n",
    "    \n",
    "    h4 = tf.keras.layers.Dense(32,activation='tanh')(feature_tal)\n",
    "    \n",
    "    h5 = tf.keras.layers.Dense(1,activation='sigmoid')(h4)\n",
    "    \n",
    "\n",
    "    model = Model(inputs=[S_inputs_snv,S_inputs_mRNA,S_inputs_miRNA], outputs=h5)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 0.0001,decay=0.0001) \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8181c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1044dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluation function\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "   \n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "\n",
    "def get_metrics(true_score,pre_score,pre_probe):\n",
    "    \n",
    "  \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_score, pre_probe, pos_label=1)\n",
    "   \n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    aupr = average_precision_score(true_score, pre_probe)\n",
    "    \n",
    "    pre, rec, thresholds = precision_recall_curve(true_score, pre_probe)    \n",
    "    auprc  = metrics.auc(rec, pre)\n",
    "    \n",
    "    \n",
    "    accuracy = accuracy_score(true_score,pre_score)\n",
    "    \n",
    "    f1 = metrics.f1_score(true_score, pre_score)\n",
    "    \n",
    "    precision = metrics.precision_score(true_score,pre_score)\n",
    "    \n",
    "    recall = metrics.recall_score(true_score,pre_score)\n",
    "    \n",
    "     \n",
    "    print( print(confusion_matrix(true_score,pre_score)))\n",
    "    return precision,accuracy,recall,f1,auc,aupr,auprc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluates(y_test, y_pred):\n",
    "    \n",
    "    auc = metrics.roc_auc_score(y_test,y_pred)\n",
    "    \n",
    "    aupr = average_precision_score(y_test, y_pred)\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)    \n",
    "    auprc  = metrics.auc(recall, precision)\n",
    "    \n",
    "    pp = [1 if index>=0.5  else 0 for index in  y_pred ]\n",
    "    \n",
    "    pre = metrics.precision_score(y_test,pp)\n",
    "    \n",
    "    f1 = metrics.f1_score(y_test,pp)\n",
    "    \n",
    "    rec = metrics.recall_score(y_test,pp)\n",
    "    \n",
    "    acc = metrics.accuracy_score(y_test,pp)\n",
    "    \n",
    "    print(confusion_matrix(y_test,pp))\n",
    "    return pre,acc,rec,f1,auc,aupr,auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "825824f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_data = snv_data.loc[example_case.index]\n",
    "\n",
    "miRNA_data = miRNA_data.loc[example_case.index]\n",
    "\n",
    "mRNA_data = mRNA_data.loc[example_case.index]\n",
    "\n",
    "example_case = example_case.loc[example_case.index]\n",
    "\n",
    "y = example_case['response'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cad9be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 82 129\n",
      "0.8178294573643411 1.2865853658536586\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_samples =example_case['response'].values\n",
    "\n",
    "print(len(n_samples),n_samples.sum(),(len(n_samples) -n_samples.sum()))\n",
    "\n",
    "x_0 =  len(n_samples) / (2*  (len(n_samples) -n_samples.sum()))\n",
    "x_1 =  len(n_samples) / (2*  n_samples.sum())\n",
    "\n",
    "print(x_0,x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f75a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80621e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b58a98f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " snv_inputs (InputLayer)        [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " mRNA_inputs (InputLayer)       [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " miRNA_inputs (InputLayer)      [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " h0_snv (Biological_module)     (None, 238)          3387        ['snv_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " h0_mRNA (Biological_module)    (None, 238)          3276        ['mRNA_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " h0_miRNA (Biological_module)   (None, 238)          8973        ['miRNA_inputs[0][0]']           \n",
      "                                                                                                  \n",
      " self__attention (Self_Attentio  (None, 64)          45696       ['h0_snv[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " self__attention_1 (Self_Attent  (None, 64)          45696       ['h0_mRNA[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " self__attention_2 (Self_Attent  (None, 64)          45696       ['h0_miRNA[0][0]']               \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 192)          0           ['self__attention[0][0]',        \n",
      "                                                                  'self__attention_1[0][0]',      \n",
      "                                                                  'self__attention_2[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           6176        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            33          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 158,933\n",
      "Trainable params: 158,933\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "1/3 [=========>....................] - ETA: 3s - loss: 1.4978 - acc: 0.4219WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "3/3 [==============================] - 2s 223ms/step - loss: 1.4875 - acc: 0.3988 - val_loss: 1.4780 - val_acc: 0.3953\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.4732 - acc: 0.3988 - val_loss: 1.4639 - val_acc: 0.3953\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.4591 - acc: 0.3929 - val_loss: 1.4499 - val_acc: 0.3721\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.4452 - acc: 0.4107 - val_loss: 1.4362 - val_acc: 0.3953\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4315 - acc: 0.4167 - val_loss: 1.4226 - val_acc: 0.4419\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4180 - acc: 0.4583 - val_loss: 1.4092 - val_acc: 0.4651\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.4046 - acc: 0.5357 - val_loss: 1.3960 - val_acc: 0.6047\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3915 - acc: 0.5893 - val_loss: 1.3830 - val_acc: 0.6279\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.3786 - acc: 0.6190 - val_loss: 1.3703 - val_acc: 0.6279\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3658 - acc: 0.6190 - val_loss: 1.3578 - val_acc: 0.6512\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.3533 - acc: 0.6548 - val_loss: 1.3454 - val_acc: 0.6279\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3409 - acc: 0.6786 - val_loss: 1.3332 - val_acc: 0.6512\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3287 - acc: 0.6964 - val_loss: 1.3213 - val_acc: 0.6512\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.3167 - acc: 0.6607 - val_loss: 1.3096 - val_acc: 0.6744\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.3049 - acc: 0.6667 - val_loss: 1.2980 - val_acc: 0.6512\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.2932 - acc: 0.6905 - val_loss: 1.2867 - val_acc: 0.6512\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.2818 - acc: 0.6786 - val_loss: 1.2757 - val_acc: 0.6512\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.2705 - acc: 0.6369 - val_loss: 1.2649 - val_acc: 0.6279\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.2594 - acc: 0.5952 - val_loss: 1.2542 - val_acc: 0.6047\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.2484 - acc: 0.5952 - val_loss: 1.2436 - val_acc: 0.6512\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.2376 - acc: 0.6131 - val_loss: 1.2331 - val_acc: 0.6512\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.2269 - acc: 0.6369 - val_loss: 1.2228 - val_acc: 0.6279\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.2164 - acc: 0.6310 - val_loss: 1.2129 - val_acc: 0.6279\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.2060 - acc: 0.6250 - val_loss: 1.2030 - val_acc: 0.6512\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.1959 - acc: 0.6190 - val_loss: 1.1934 - val_acc: 0.6512\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.1855 - acc: 0.6131 - val_loss: 1.1839 - val_acc: 0.6512\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.1756 - acc: 0.6012 - val_loss: 1.1746 - val_acc: 0.6512\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.1656 - acc: 0.6250 - val_loss: 1.1651 - val_acc: 0.6279\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1558 - acc: 0.6429 - val_loss: 1.1558 - val_acc: 0.6512\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.1459 - acc: 0.6429 - val_loss: 1.1466 - val_acc: 0.6512\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.1362 - acc: 0.6667 - val_loss: 1.1374 - val_acc: 0.6279\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.1265 - acc: 0.6905 - val_loss: 1.1280 - val_acc: 0.6279\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.1169 - acc: 0.7083 - val_loss: 1.1192 - val_acc: 0.6047\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1073 - acc: 0.7024 - val_loss: 1.1100 - val_acc: 0.6047\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.0975 - acc: 0.7143 - val_loss: 1.1011 - val_acc: 0.6047\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0878 - acc: 0.7262 - val_loss: 1.0921 - val_acc: 0.6279\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.0780 - acc: 0.7321 - val_loss: 1.0833 - val_acc: 0.6512\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0683 - acc: 0.7321 - val_loss: 1.0747 - val_acc: 0.6512\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0583 - acc: 0.7321 - val_loss: 1.0660 - val_acc: 0.6512\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.0482 - acc: 0.7202 - val_loss: 1.0567 - val_acc: 0.6744\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0382 - acc: 0.7262 - val_loss: 1.0480 - val_acc: 0.6744\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.0281 - acc: 0.7321 - val_loss: 1.0398 - val_acc: 0.6744\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0176 - acc: 0.7262 - val_loss: 1.0320 - val_acc: 0.6744\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0072 - acc: 0.7262 - val_loss: 1.0231 - val_acc: 0.6744\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9966 - acc: 0.7202 - val_loss: 1.0145 - val_acc: 0.6744\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9861 - acc: 0.7262 - val_loss: 1.0068 - val_acc: 0.6977\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9754 - acc: 0.7262 - val_loss: 0.9979 - val_acc: 0.6744\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9643 - acc: 0.7262 - val_loss: 0.9878 - val_acc: 0.6977\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9530 - acc: 0.7381 - val_loss: 0.9783 - val_acc: 0.6977\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9421 - acc: 0.7500 - val_loss: 0.9693 - val_acc: 0.6744\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.9312 - acc: 0.7500 - val_loss: 0.9598 - val_acc: 0.6744\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9194 - acc: 0.7500 - val_loss: 0.9520 - val_acc: 0.6744\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9083 - acc: 0.7440 - val_loss: 0.9456 - val_acc: 0.6977\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8970 - acc: 0.7560 - val_loss: 0.9373 - val_acc: 0.6977\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8854 - acc: 0.7560 - val_loss: 0.9286 - val_acc: 0.6977\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8738 - acc: 0.7500 - val_loss: 0.9203 - val_acc: 0.6977\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8629 - acc: 0.7440 - val_loss: 0.9118 - val_acc: 0.6977\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8510 - acc: 0.7500 - val_loss: 0.9050 - val_acc: 0.6977\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8405 - acc: 0.7619 - val_loss: 0.8989 - val_acc: 0.6977\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8289 - acc: 0.7679 - val_loss: 0.8905 - val_acc: 0.6977\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8174 - acc: 0.7619 - val_loss: 0.8831 - val_acc: 0.6977\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8068 - acc: 0.7679 - val_loss: 0.8760 - val_acc: 0.6977\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7960 - acc: 0.7738 - val_loss: 0.8705 - val_acc: 0.7209\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7855 - acc: 0.7738 - val_loss: 0.8636 - val_acc: 0.7209\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7745 - acc: 0.7738 - val_loss: 0.8551 - val_acc: 0.6977\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7634 - acc: 0.8036 - val_loss: 0.8474 - val_acc: 0.6977\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7527 - acc: 0.7976 - val_loss: 0.8408 - val_acc: 0.6977\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7427 - acc: 0.8036 - val_loss: 0.8335 - val_acc: 0.6977\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7323 - acc: 0.8036 - val_loss: 0.8276 - val_acc: 0.6977\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7222 - acc: 0.8095 - val_loss: 0.8228 - val_acc: 0.7209\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7120 - acc: 0.8274 - val_loss: 0.8163 - val_acc: 0.7209\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7021 - acc: 0.8274 - val_loss: 0.8102 - val_acc: 0.7209\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6918 - acc: 0.8274 - val_loss: 0.8031 - val_acc: 0.6977\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6821 - acc: 0.8214 - val_loss: 0.7970 - val_acc: 0.6977\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6726 - acc: 0.8274 - val_loss: 0.7911 - val_acc: 0.6977\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6633 - acc: 0.8333 - val_loss: 0.7855 - val_acc: 0.6977\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6543 - acc: 0.8512 - val_loss: 0.7809 - val_acc: 0.6977\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6440 - acc: 0.8512 - val_loss: 0.7757 - val_acc: 0.7209\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6343 - acc: 0.8512 - val_loss: 0.7699 - val_acc: 0.7209\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6250 - acc: 0.8631 - val_loss: 0.7641 - val_acc: 0.7209\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6161 - acc: 0.8750 - val_loss: 0.7588 - val_acc: 0.7209\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6077 - acc: 0.8750 - val_loss: 0.7535 - val_acc: 0.7209\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5976 - acc: 0.8810 - val_loss: 0.7486 - val_acc: 0.7209\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5891 - acc: 0.8750 - val_loss: 0.7437 - val_acc: 0.7209\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5802 - acc: 0.8869 - val_loss: 0.7399 - val_acc: 0.7442\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5715 - acc: 0.8988 - val_loss: 0.7349 - val_acc: 0.7442\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5624 - acc: 0.8988 - val_loss: 0.7296 - val_acc: 0.7674\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5538 - acc: 0.8810 - val_loss: 0.7239 - val_acc: 0.7674\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5475 - acc: 0.8690 - val_loss: 0.7190 - val_acc: 0.7442\n",
      "Epoch 90/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5380 - acc: 0.8810 - val_loss: 0.7150 - val_acc: 0.7674\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5290 - acc: 0.8988 - val_loss: 0.7133 - val_acc: 0.7674\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5210 - acc: 0.9048 - val_loss: 0.7118 - val_acc: 0.7442\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5141 - acc: 0.9107 - val_loss: 0.7090 - val_acc: 0.7209\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5052 - acc: 0.9107 - val_loss: 0.7013 - val_acc: 0.7674\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4979 - acc: 0.9048 - val_loss: 0.6944 - val_acc: 0.7674\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4900 - acc: 0.9048 - val_loss: 0.6905 - val_acc: 0.7674\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4825 - acc: 0.9048 - val_loss: 0.6882 - val_acc: 0.7674\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4746 - acc: 0.9048 - val_loss: 0.6888 - val_acc: 0.7209\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4672 - acc: 0.9345 - val_loss: 0.6885 - val_acc: 0.7209\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4601 - acc: 0.9345 - val_loss: 0.6848 - val_acc: 0.7209\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4529 - acc: 0.9405 - val_loss: 0.6818 - val_acc: 0.7209\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4458 - acc: 0.9405 - val_loss: 0.6769 - val_acc: 0.7209\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4388 - acc: 0.9405 - val_loss: 0.6732 - val_acc: 0.7209\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4320 - acc: 0.9345 - val_loss: 0.6718 - val_acc: 0.7209\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4255 - acc: 0.9405 - val_loss: 0.6698 - val_acc: 0.7209\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4188 - acc: 0.9464 - val_loss: 0.6667 - val_acc: 0.7209\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4126 - acc: 0.9464 - val_loss: 0.6645 - val_acc: 0.7209\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4062 - acc: 0.9464 - val_loss: 0.6672 - val_acc: 0.6977\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4002 - acc: 0.9405 - val_loss: 0.6677 - val_acc: 0.6977\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3943 - acc: 0.9524 - val_loss: 0.6596 - val_acc: 0.6977\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3884 - acc: 0.9524 - val_loss: 0.6559 - val_acc: 0.6977\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3821 - acc: 0.9583 - val_loss: 0.6588 - val_acc: 0.7209\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3765 - acc: 0.9524 - val_loss: 0.6633 - val_acc: 0.7209\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3716 - acc: 0.9524 - val_loss: 0.6640 - val_acc: 0.7209\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3653 - acc: 0.9524 - val_loss: 0.6567 - val_acc: 0.7209\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3595 - acc: 0.9583 - val_loss: 0.6475 - val_acc: 0.7209\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3545 - acc: 0.9702 - val_loss: 0.6420 - val_acc: 0.7442\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3499 - acc: 0.9643 - val_loss: 0.6416 - val_acc: 0.7442\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3447 - acc: 0.9702 - val_loss: 0.6453 - val_acc: 0.7209\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3394 - acc: 0.9702 - val_loss: 0.6493 - val_acc: 0.7209\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3348 - acc: 0.9643 - val_loss: 0.6592 - val_acc: 0.7209\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3300 - acc: 0.9643 - val_loss: 0.6603 - val_acc: 0.7209\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3250 - acc: 0.9643 - val_loss: 0.6519 - val_acc: 0.7209\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3203 - acc: 0.9643 - val_loss: 0.6458 - val_acc: 0.7209\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3159 - acc: 0.9643 - val_loss: 0.6452 - val_acc: 0.7209\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3115 - acc: 0.9643 - val_loss: 0.6429 - val_acc: 0.7209\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3073 - acc: 0.9702 - val_loss: 0.6412 - val_acc: 0.7209\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3031 - acc: 0.9702 - val_loss: 0.6473 - val_acc: 0.7209\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2990 - acc: 0.9643 - val_loss: 0.6525 - val_acc: 0.7442\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2947 - acc: 0.9643 - val_loss: 0.6506 - val_acc: 0.7442\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2908 - acc: 0.9643 - val_loss: 0.6422 - val_acc: 0.7209\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2868 - acc: 0.9702 - val_loss: 0.6430 - val_acc: 0.7442\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2830 - acc: 0.9702 - val_loss: 0.6464 - val_acc: 0.7442\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2790 - acc: 0.9762 - val_loss: 0.6457 - val_acc: 0.7442\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2756 - acc: 0.9702 - val_loss: 0.6488 - val_acc: 0.7442\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2717 - acc: 0.9762 - val_loss: 0.6450 - val_acc: 0.7442\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2686 - acc: 0.9821 - val_loss: 0.6420 - val_acc: 0.7442\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2649 - acc: 0.9821 - val_loss: 0.6517 - val_acc: 0.7442\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2612 - acc: 0.9762 - val_loss: 0.6547 - val_acc: 0.7442\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2579 - acc: 0.9762 - val_loss: 0.6552 - val_acc: 0.7442\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2547 - acc: 0.9821 - val_loss: 0.6575 - val_acc: 0.7442\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2514 - acc: 0.9821 - val_loss: 0.6535 - val_acc: 0.7442\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2483 - acc: 0.9881 - val_loss: 0.6438 - val_acc: 0.7442\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2454 - acc: 0.9821 - val_loss: 0.6436 - val_acc: 0.7442\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2430 - acc: 0.9821 - val_loss: 0.6361 - val_acc: 0.7442\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2396 - acc: 0.9821 - val_loss: 0.6456 - val_acc: 0.7442\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2362 - acc: 0.9881 - val_loss: 0.6571 - val_acc: 0.7442\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2335 - acc: 0.9940 - val_loss: 0.6671 - val_acc: 0.7442\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2309 - acc: 0.9881 - val_loss: 0.6683 - val_acc: 0.7442\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2286 - acc: 0.9881 - val_loss: 0.6606 - val_acc: 0.7442\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  0]\n",
      " [11  6]]\n",
      "None\n",
      "(1.0, 0.7441860465116279, 0.35294117647058826, 0.5217391304347826, 0.8642533936651583, 0.8381287540326443, 0.8337422010640241)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " snv_inputs (InputLayer)        [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " mRNA_inputs (InputLayer)       [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " miRNA_inputs (InputLayer)      [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " h0_snv (Biological_module)     (None, 238)          3387        ['snv_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " h0_mRNA (Biological_module)    (None, 238)          3276        ['mRNA_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " h0_miRNA (Biological_module)   (None, 238)          8973        ['miRNA_inputs[0][0]']           \n",
      "                                                                                                  \n",
      " self__attention_3 (Self_Attent  (None, 64)          45696       ['h0_snv[0][0]']                 \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " self__attention_4 (Self_Attent  (None, 64)          45696       ['h0_mRNA[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " self__attention_5 (Self_Attent  (None, 64)          45696       ['h0_miRNA[0][0]']               \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 192)          0           ['self__attention_3[0][0]',      \n",
      "                                                                  'self__attention_4[0][0]',      \n",
      "                                                                  'self__attention_5[0][0]']      \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           6176        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            33          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 158,933\n",
      "Trainable params: 158,933\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "1/3 [=========>....................] - ETA: 3s - loss: 1.4862 - acc: 0.5938WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "3/3 [==============================] - 2s 179ms/step - loss: 1.4923 - acc: 0.5917 - val_loss: 1.4814 - val_acc: 0.6190\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.4780 - acc: 0.6272 - val_loss: 1.4672 - val_acc: 0.6190\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4639 - acc: 0.6272 - val_loss: 1.4532 - val_acc: 0.6190\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4500 - acc: 0.6154 - val_loss: 1.4395 - val_acc: 0.6190\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4362 - acc: 0.6331 - val_loss: 1.4259 - val_acc: 0.6429\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4227 - acc: 0.6568 - val_loss: 1.4125 - val_acc: 0.6667\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4094 - acc: 0.6923 - val_loss: 1.3994 - val_acc: 0.6667\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3963 - acc: 0.6923 - val_loss: 1.3864 - val_acc: 0.6905\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3833 - acc: 0.7101 - val_loss: 1.3736 - val_acc: 0.6905\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.3706 - acc: 0.6923 - val_loss: 1.3611 - val_acc: 0.6429\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3581 - acc: 0.6509 - val_loss: 1.3488 - val_acc: 0.6190\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3458 - acc: 0.5207 - val_loss: 1.3367 - val_acc: 0.5238\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3337 - acc: 0.5325 - val_loss: 1.3248 - val_acc: 0.5714\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.3218 - acc: 0.5089 - val_loss: 1.3131 - val_acc: 0.5714\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.3100 - acc: 0.5148 - val_loss: 1.3016 - val_acc: 0.5714\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.2985 - acc: 0.5207 - val_loss: 1.2903 - val_acc: 0.5714\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.2872 - acc: 0.5148 - val_loss: 1.2792 - val_acc: 0.5714\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.2760 - acc: 0.5444 - val_loss: 1.2682 - val_acc: 0.5952\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.2650 - acc: 0.5621 - val_loss: 1.2575 - val_acc: 0.5714\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.2541 - acc: 0.5444 - val_loss: 1.2470 - val_acc: 0.5476\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2434 - acc: 0.5325 - val_loss: 1.2366 - val_acc: 0.5476\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.2329 - acc: 0.5325 - val_loss: 1.2264 - val_acc: 0.5476\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.2225 - acc: 0.5325 - val_loss: 1.2165 - val_acc: 0.5476\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2123 - acc: 0.5266 - val_loss: 1.2067 - val_acc: 0.5238\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.2023 - acc: 0.5207 - val_loss: 1.1970 - val_acc: 0.5000\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1923 - acc: 0.5148 - val_loss: 1.1877 - val_acc: 0.5000\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.1826 - acc: 0.4852 - val_loss: 1.1785 - val_acc: 0.5000\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.1729 - acc: 0.4793 - val_loss: 1.1694 - val_acc: 0.5000\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.1633 - acc: 0.4911 - val_loss: 1.1603 - val_acc: 0.5000\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.1539 - acc: 0.4970 - val_loss: 1.1514 - val_acc: 0.5000\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.1445 - acc: 0.4970 - val_loss: 1.1426 - val_acc: 0.5000\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.1354 - acc: 0.5089 - val_loss: 1.1342 - val_acc: 0.5000\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1262 - acc: 0.5207 - val_loss: 1.1256 - val_acc: 0.5000\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.1171 - acc: 0.5385 - val_loss: 1.1168 - val_acc: 0.5714\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.1081 - acc: 0.5503 - val_loss: 1.1083 - val_acc: 0.5714\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0991 - acc: 0.5740 - val_loss: 1.0996 - val_acc: 0.5952\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0902 - acc: 0.5976 - val_loss: 1.0907 - val_acc: 0.5952\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0813 - acc: 0.6450 - val_loss: 1.0821 - val_acc: 0.5714\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0725 - acc: 0.6509 - val_loss: 1.0740 - val_acc: 0.5714\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0635 - acc: 0.6509 - val_loss: 1.0654 - val_acc: 0.6190\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0546 - acc: 0.6746 - val_loss: 1.0571 - val_acc: 0.6190\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0456 - acc: 0.6805 - val_loss: 1.0485 - val_acc: 0.5952\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0367 - acc: 0.6805 - val_loss: 1.0402 - val_acc: 0.5952\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0276 - acc: 0.6923 - val_loss: 1.0315 - val_acc: 0.6429\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0184 - acc: 0.7160 - val_loss: 1.0230 - val_acc: 0.6667\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0092 - acc: 0.7041 - val_loss: 1.0147 - val_acc: 0.6667\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9999 - acc: 0.7101 - val_loss: 1.0061 - val_acc: 0.6429\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9903 - acc: 0.7101 - val_loss: 0.9968 - val_acc: 0.6667\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9811 - acc: 0.7219 - val_loss: 0.9871 - val_acc: 0.7381\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9712 - acc: 0.7278 - val_loss: 0.9783 - val_acc: 0.7143\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9617 - acc: 0.7337 - val_loss: 0.9688 - val_acc: 0.7381\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9518 - acc: 0.7515 - val_loss: 0.9596 - val_acc: 0.7381\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9420 - acc: 0.7515 - val_loss: 0.9510 - val_acc: 0.7381\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9315 - acc: 0.7574 - val_loss: 0.9415 - val_acc: 0.7143\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9213 - acc: 0.7574 - val_loss: 0.9318 - val_acc: 0.7381\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9111 - acc: 0.7574 - val_loss: 0.9224 - val_acc: 0.7381\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9001 - acc: 0.7633 - val_loss: 0.9136 - val_acc: 0.7381\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8899 - acc: 0.7633 - val_loss: 0.9050 - val_acc: 0.7381\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8792 - acc: 0.7633 - val_loss: 0.8962 - val_acc: 0.7381\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8684 - acc: 0.7633 - val_loss: 0.8873 - val_acc: 0.7381\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8590 - acc: 0.7515 - val_loss: 0.8767 - val_acc: 0.7381\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8476 - acc: 0.7633 - val_loss: 0.8692 - val_acc: 0.7619\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8368 - acc: 0.7692 - val_loss: 0.8599 - val_acc: 0.7619\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8260 - acc: 0.7692 - val_loss: 0.8515 - val_acc: 0.7619\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8157 - acc: 0.7692 - val_loss: 0.8443 - val_acc: 0.7381\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8057 - acc: 0.7751 - val_loss: 0.8364 - val_acc: 0.7381\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7954 - acc: 0.7751 - val_loss: 0.8286 - val_acc: 0.7143\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7856 - acc: 0.7692 - val_loss: 0.8196 - val_acc: 0.7381\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7753 - acc: 0.7751 - val_loss: 0.8108 - val_acc: 0.7619\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7650 - acc: 0.7751 - val_loss: 0.8016 - val_acc: 0.7857\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7551 - acc: 0.7751 - val_loss: 0.7922 - val_acc: 0.7619\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7464 - acc: 0.7751 - val_loss: 0.7838 - val_acc: 0.7381\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7368 - acc: 0.7692 - val_loss: 0.7765 - val_acc: 0.7381\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7272 - acc: 0.7751 - val_loss: 0.7705 - val_acc: 0.7857\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7169 - acc: 0.7811 - val_loss: 0.7643 - val_acc: 0.7857\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7080 - acc: 0.7870 - val_loss: 0.7584 - val_acc: 0.7619\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6988 - acc: 0.7811 - val_loss: 0.7515 - val_acc: 0.7619\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6901 - acc: 0.7929 - val_loss: 0.7440 - val_acc: 0.7619\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6807 - acc: 0.7811 - val_loss: 0.7372 - val_acc: 0.7619\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6717 - acc: 0.7811 - val_loss: 0.7311 - val_acc: 0.7619\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6628 - acc: 0.7929 - val_loss: 0.7245 - val_acc: 0.7619\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6541 - acc: 0.7988 - val_loss: 0.7173 - val_acc: 0.7619\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6451 - acc: 0.8107 - val_loss: 0.7112 - val_acc: 0.7619\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6361 - acc: 0.8107 - val_loss: 0.7053 - val_acc: 0.7619\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6282 - acc: 0.8225 - val_loss: 0.6992 - val_acc: 0.7619\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6190 - acc: 0.8343 - val_loss: 0.6942 - val_acc: 0.7619\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6121 - acc: 0.8343 - val_loss: 0.6897 - val_acc: 0.7857\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6022 - acc: 0.8521 - val_loss: 0.6827 - val_acc: 0.7619\n",
      "Epoch 89/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5936 - acc: 0.8580 - val_loss: 0.6766 - val_acc: 0.7619\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5851 - acc: 0.8521 - val_loss: 0.6709 - val_acc: 0.7381\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5774 - acc: 0.8402 - val_loss: 0.6656 - val_acc: 0.7381\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5695 - acc: 0.8402 - val_loss: 0.6603 - val_acc: 0.7381\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5615 - acc: 0.8580 - val_loss: 0.6549 - val_acc: 0.7381\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5528 - acc: 0.8580 - val_loss: 0.6502 - val_acc: 0.7381\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5459 - acc: 0.8757 - val_loss: 0.6464 - val_acc: 0.7857\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5378 - acc: 0.8698 - val_loss: 0.6410 - val_acc: 0.7619\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5294 - acc: 0.8817 - val_loss: 0.6349 - val_acc: 0.7381\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5213 - acc: 0.8817 - val_loss: 0.6299 - val_acc: 0.7381\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5140 - acc: 0.8876 - val_loss: 0.6252 - val_acc: 0.7619\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5073 - acc: 0.8994 - val_loss: 0.6205 - val_acc: 0.7619\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4994 - acc: 0.8994 - val_loss: 0.6155 - val_acc: 0.7381\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4915 - acc: 0.8935 - val_loss: 0.6112 - val_acc: 0.8095\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4842 - acc: 0.8994 - val_loss: 0.6069 - val_acc: 0.8571\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4773 - acc: 0.8994 - val_loss: 0.6028 - val_acc: 0.8571\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4705 - acc: 0.8994 - val_loss: 0.5982 - val_acc: 0.8571\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4631 - acc: 0.9053 - val_loss: 0.5936 - val_acc: 0.8571\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4561 - acc: 0.9112 - val_loss: 0.5894 - val_acc: 0.8810\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4506 - acc: 0.9112 - val_loss: 0.5855 - val_acc: 0.8571\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4430 - acc: 0.9112 - val_loss: 0.5813 - val_acc: 0.8810\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4374 - acc: 0.9112 - val_loss: 0.5776 - val_acc: 0.8810\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4304 - acc: 0.9172 - val_loss: 0.5734 - val_acc: 0.8810\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4236 - acc: 0.9172 - val_loss: 0.5695 - val_acc: 0.8810\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4178 - acc: 0.9172 - val_loss: 0.5658 - val_acc: 0.8810\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4117 - acc: 0.9172 - val_loss: 0.5619 - val_acc: 0.8810\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4055 - acc: 0.9172 - val_loss: 0.5581 - val_acc: 0.8810\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3996 - acc: 0.9231 - val_loss: 0.5545 - val_acc: 0.8810\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3938 - acc: 0.9231 - val_loss: 0.5508 - val_acc: 0.8810\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3883 - acc: 0.9290 - val_loss: 0.5472 - val_acc: 0.8810\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3826 - acc: 0.9290 - val_loss: 0.5438 - val_acc: 0.8810\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3777 - acc: 0.9349 - val_loss: 0.5406 - val_acc: 0.8810\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3721 - acc: 0.9349 - val_loss: 0.5370 - val_acc: 0.8810\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3664 - acc: 0.9467 - val_loss: 0.5336 - val_acc: 0.8571\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3622 - acc: 0.9527 - val_loss: 0.5309 - val_acc: 0.8571\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3571 - acc: 0.9586 - val_loss: 0.5277 - val_acc: 0.8571\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3516 - acc: 0.9527 - val_loss: 0.5247 - val_acc: 0.8571\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3463 - acc: 0.9467 - val_loss: 0.5228 - val_acc: 0.8810\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3425 - acc: 0.9408 - val_loss: 0.5213 - val_acc: 0.8810\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3378 - acc: 0.9467 - val_loss: 0.5176 - val_acc: 0.8810\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3327 - acc: 0.9467 - val_loss: 0.5142 - val_acc: 0.8571\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3278 - acc: 0.9467 - val_loss: 0.5112 - val_acc: 0.8571\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3239 - acc: 0.9586 - val_loss: 0.5089 - val_acc: 0.8571\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3197 - acc: 0.9645 - val_loss: 0.5063 - val_acc: 0.8571\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3158 - acc: 0.9645 - val_loss: 0.5037 - val_acc: 0.8571\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3108 - acc: 0.9645 - val_loss: 0.5014 - val_acc: 0.8571\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3071 - acc: 0.9586 - val_loss: 0.4992 - val_acc: 0.8571\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3027 - acc: 0.9586 - val_loss: 0.4966 - val_acc: 0.8571\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2989 - acc: 0.9645 - val_loss: 0.4942 - val_acc: 0.8571\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2949 - acc: 0.9645 - val_loss: 0.4920 - val_acc: 0.8571\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2911 - acc: 0.9645 - val_loss: 0.4899 - val_acc: 0.8571\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2875 - acc: 0.9645 - val_loss: 0.4881 - val_acc: 0.8333\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2839 - acc: 0.9645 - val_loss: 0.4860 - val_acc: 0.8333\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2806 - acc: 0.9645 - val_loss: 0.4834 - val_acc: 0.8571\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2769 - acc: 0.9645 - val_loss: 0.4811 - val_acc: 0.8571\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2732 - acc: 0.9645 - val_loss: 0.4791 - val_acc: 0.8571\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2702 - acc: 0.9645 - val_loss: 0.4779 - val_acc: 0.8333\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2670 - acc: 0.9645 - val_loss: 0.4751 - val_acc: 0.8333\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2636 - acc: 0.9704 - val_loss: 0.4736 - val_acc: 0.8333\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2609 - acc: 0.9704 - val_loss: 0.4710 - val_acc: 0.8571\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2568 - acc: 0.9704 - val_loss: 0.4694 - val_acc: 0.8333\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2542 - acc: 0.9704 - val_loss: 0.4681 - val_acc: 0.8333\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "[[22  4]\n",
      " [ 3 13]]\n",
      "None\n",
      "(0.7647058823529411, 0.8333333333333334, 0.8125, 0.787878787878788, 0.9254807692307693, 0.912604190400243, 0.9101652599663194)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " snv_inputs (InputLayer)        [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " mRNA_inputs (InputLayer)       [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " miRNA_inputs (InputLayer)      [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " h0_snv (Biological_module)     (None, 238)          3387        ['snv_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " h0_mRNA (Biological_module)    (None, 238)          3276        ['mRNA_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " h0_miRNA (Biological_module)   (None, 238)          8973        ['miRNA_inputs[0][0]']           \n",
      "                                                                                                  \n",
      " self__attention_6 (Self_Attent  (None, 64)          45696       ['h0_snv[0][0]']                 \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " self__attention_7 (Self_Attent  (None, 64)          45696       ['h0_mRNA[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " self__attention_8 (Self_Attent  (None, 64)          45696       ['h0_miRNA[0][0]']               \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 192)          0           ['self__attention_6[0][0]',      \n",
      "                                                                  'self__attention_7[0][0]',      \n",
      "                                                                  'self__attention_8[0][0]']      \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 32)           6176        ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            33          ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 158,933\n",
      "Trainable params: 158,933\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "1/3 [=========>....................] - ETA: 2s - loss: 1.4590 - acc: 0.5938WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "3/3 [==============================] - 2s 176ms/step - loss: 1.4906 - acc: 0.5621 - val_loss: 1.4796 - val_acc: 0.6190\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.4763 - acc: 0.6272 - val_loss: 1.4656 - val_acc: 0.5952\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4622 - acc: 0.6331 - val_loss: 1.4518 - val_acc: 0.5714\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4483 - acc: 0.6509 - val_loss: 1.4381 - val_acc: 0.4762\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4345 - acc: 0.5976 - val_loss: 1.4246 - val_acc: 0.4524\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.4210 - acc: 0.5207 - val_loss: 1.4114 - val_acc: 0.4524\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4076 - acc: 0.4852 - val_loss: 1.3983 - val_acc: 0.4524\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.3944 - acc: 0.4793 - val_loss: 1.3854 - val_acc: 0.4524\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.3814 - acc: 0.4734 - val_loss: 1.3728 - val_acc: 0.4286\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3686 - acc: 0.4438 - val_loss: 1.3604 - val_acc: 0.4286\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3561 - acc: 0.4438 - val_loss: 1.3482 - val_acc: 0.4286\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.3436 - acc: 0.4379 - val_loss: 1.3362 - val_acc: 0.4286\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3315 - acc: 0.4379 - val_loss: 1.3244 - val_acc: 0.4286\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3194 - acc: 0.4379 - val_loss: 1.3129 - val_acc: 0.4286\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3076 - acc: 0.4320 - val_loss: 1.3017 - val_acc: 0.4286\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.2960 - acc: 0.4142 - val_loss: 1.2906 - val_acc: 0.4048\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.2846 - acc: 0.4083 - val_loss: 1.2799 - val_acc: 0.3810\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.2733 - acc: 0.4024 - val_loss: 1.2694 - val_acc: 0.3810\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.2622 - acc: 0.4024 - val_loss: 1.2589 - val_acc: 0.3810\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.2513 - acc: 0.4024 - val_loss: 1.2486 - val_acc: 0.3810\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.2406 - acc: 0.4024 - val_loss: 1.2384 - val_acc: 0.3810\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.2299 - acc: 0.4083 - val_loss: 1.2284 - val_acc: 0.3810\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.2196 - acc: 0.4083 - val_loss: 1.2188 - val_acc: 0.3810\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.2092 - acc: 0.4083 - val_loss: 1.2091 - val_acc: 0.4286\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1991 - acc: 0.4083 - val_loss: 1.1998 - val_acc: 0.4286\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.1891 - acc: 0.4142 - val_loss: 1.1904 - val_acc: 0.4286\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.1792 - acc: 0.4379 - val_loss: 1.1814 - val_acc: 0.4286\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1694 - acc: 0.4379 - val_loss: 1.1724 - val_acc: 0.4286\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.1598 - acc: 0.4556 - val_loss: 1.1635 - val_acc: 0.4286\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1502 - acc: 0.4675 - val_loss: 1.1542 - val_acc: 0.4524\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1409 - acc: 0.4793 - val_loss: 1.1451 - val_acc: 0.4762\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.1314 - acc: 0.5030 - val_loss: 1.1368 - val_acc: 0.5000\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1222 - acc: 0.5089 - val_loss: 1.1284 - val_acc: 0.5000\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.1131 - acc: 0.5266 - val_loss: 1.1200 - val_acc: 0.5238\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.1038 - acc: 0.5562 - val_loss: 1.1113 - val_acc: 0.5476\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0949 - acc: 0.5680 - val_loss: 1.1029 - val_acc: 0.5714\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0856 - acc: 0.5680 - val_loss: 1.0947 - val_acc: 0.5714\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0767 - acc: 0.5917 - val_loss: 1.0860 - val_acc: 0.5952\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0676 - acc: 0.6331 - val_loss: 1.0774 - val_acc: 0.5952\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0587 - acc: 0.6568 - val_loss: 1.0687 - val_acc: 0.6429\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0495 - acc: 0.6509 - val_loss: 1.0607 - val_acc: 0.6429\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0403 - acc: 0.6509 - val_loss: 1.0528 - val_acc: 0.6190\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0312 - acc: 0.6450 - val_loss: 1.0451 - val_acc: 0.6190\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0220 - acc: 0.6450 - val_loss: 1.0370 - val_acc: 0.5476\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0126 - acc: 0.6509 - val_loss: 1.0288 - val_acc: 0.5238\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0030 - acc: 0.6864 - val_loss: 1.0200 - val_acc: 0.5714\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9940 - acc: 0.6923 - val_loss: 1.0104 - val_acc: 0.5952\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9838 - acc: 0.7278 - val_loss: 1.0024 - val_acc: 0.6429\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9740 - acc: 0.7278 - val_loss: 0.9948 - val_acc: 0.6429\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9640 - acc: 0.7278 - val_loss: 0.9872 - val_acc: 0.6429\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9540 - acc: 0.7337 - val_loss: 0.9802 - val_acc: 0.6429\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9435 - acc: 0.7396 - val_loss: 0.9724 - val_acc: 0.6667\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9332 - acc: 0.7515 - val_loss: 0.9646 - val_acc: 0.6667\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9229 - acc: 0.7337 - val_loss: 0.9576 - val_acc: 0.6667\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9120 - acc: 0.7456 - val_loss: 0.9488 - val_acc: 0.6905\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9014 - acc: 0.7456 - val_loss: 0.9392 - val_acc: 0.7143\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8904 - acc: 0.7515 - val_loss: 0.9315 - val_acc: 0.7143\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8794 - acc: 0.7574 - val_loss: 0.9246 - val_acc: 0.7143\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8685 - acc: 0.7574 - val_loss: 0.9181 - val_acc: 0.7143\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8577 - acc: 0.7574 - val_loss: 0.9109 - val_acc: 0.7143\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8464 - acc: 0.7692 - val_loss: 0.9018 - val_acc: 0.7143\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8359 - acc: 0.7692 - val_loss: 0.8930 - val_acc: 0.7381\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.8248 - acc: 0.7633 - val_loss: 0.8860 - val_acc: 0.6905\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8144 - acc: 0.7633 - val_loss: 0.8791 - val_acc: 0.6905\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8034 - acc: 0.7692 - val_loss: 0.8753 - val_acc: 0.7381\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7928 - acc: 0.7692 - val_loss: 0.8707 - val_acc: 0.7143\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7826 - acc: 0.7692 - val_loss: 0.8670 - val_acc: 0.7143\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7724 - acc: 0.7692 - val_loss: 0.8603 - val_acc: 0.7143\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7623 - acc: 0.7692 - val_loss: 0.8550 - val_acc: 0.7143\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7525 - acc: 0.7751 - val_loss: 0.8475 - val_acc: 0.7381\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7421 - acc: 0.7811 - val_loss: 0.8433 - val_acc: 0.7381\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7323 - acc: 0.7811 - val_loss: 0.8385 - val_acc: 0.7381\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7224 - acc: 0.7870 - val_loss: 0.8335 - val_acc: 0.7381\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7135 - acc: 0.7929 - val_loss: 0.8282 - val_acc: 0.7381\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7035 - acc: 0.7988 - val_loss: 0.8244 - val_acc: 0.7381\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6942 - acc: 0.7988 - val_loss: 0.8210 - val_acc: 0.7381\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6851 - acc: 0.7988 - val_loss: 0.8160 - val_acc: 0.7381\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6755 - acc: 0.7988 - val_loss: 0.8118 - val_acc: 0.7381\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6667 - acc: 0.7988 - val_loss: 0.8062 - val_acc: 0.7381\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6578 - acc: 0.8047 - val_loss: 0.8009 - val_acc: 0.7381\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6485 - acc: 0.8047 - val_loss: 0.7966 - val_acc: 0.7381\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6404 - acc: 0.8166 - val_loss: 0.7955 - val_acc: 0.7381\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6309 - acc: 0.8225 - val_loss: 0.7897 - val_acc: 0.7381\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6221 - acc: 0.8284 - val_loss: 0.7833 - val_acc: 0.7381\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6127 - acc: 0.8343 - val_loss: 0.7787 - val_acc: 0.7381\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6043 - acc: 0.8343 - val_loss: 0.7739 - val_acc: 0.7381\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5957 - acc: 0.8402 - val_loss: 0.7706 - val_acc: 0.7381\n",
      "Epoch 88/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5869 - acc: 0.8462 - val_loss: 0.7655 - val_acc: 0.7381\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5790 - acc: 0.8462 - val_loss: 0.7613 - val_acc: 0.7381\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5703 - acc: 0.8343 - val_loss: 0.7557 - val_acc: 0.7381\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5618 - acc: 0.8402 - val_loss: 0.7506 - val_acc: 0.7143\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5536 - acc: 0.8580 - val_loss: 0.7466 - val_acc: 0.7143\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5451 - acc: 0.8580 - val_loss: 0.7435 - val_acc: 0.7381\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5377 - acc: 0.8462 - val_loss: 0.7404 - val_acc: 0.7381\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5296 - acc: 0.8462 - val_loss: 0.7352 - val_acc: 0.7381\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5217 - acc: 0.8876 - val_loss: 0.7300 - val_acc: 0.7381\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5141 - acc: 0.8935 - val_loss: 0.7261 - val_acc: 0.7381\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5059 - acc: 0.8876 - val_loss: 0.7218 - val_acc: 0.7143\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4988 - acc: 0.8876 - val_loss: 0.7175 - val_acc: 0.7143\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4909 - acc: 0.8876 - val_loss: 0.7140 - val_acc: 0.7381\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4846 - acc: 0.8876 - val_loss: 0.7106 - val_acc: 0.7381\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4780 - acc: 0.8935 - val_loss: 0.7057 - val_acc: 0.7143\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4695 - acc: 0.8994 - val_loss: 0.7021 - val_acc: 0.7143\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4625 - acc: 0.8994 - val_loss: 0.6984 - val_acc: 0.7143\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4554 - acc: 0.8994 - val_loss: 0.6949 - val_acc: 0.7143\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4489 - acc: 0.9053 - val_loss: 0.6913 - val_acc: 0.7381\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4422 - acc: 0.9053 - val_loss: 0.6878 - val_acc: 0.7381\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4356 - acc: 0.9053 - val_loss: 0.6842 - val_acc: 0.7143\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4306 - acc: 0.9112 - val_loss: 0.6812 - val_acc: 0.7143\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4232 - acc: 0.9231 - val_loss: 0.6777 - val_acc: 0.7143\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4171 - acc: 0.9112 - val_loss: 0.6739 - val_acc: 0.7143\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4108 - acc: 0.9053 - val_loss: 0.6703 - val_acc: 0.7143\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4053 - acc: 0.9112 - val_loss: 0.6670 - val_acc: 0.7143\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3990 - acc: 0.9172 - val_loss: 0.6641 - val_acc: 0.7143\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3933 - acc: 0.9290 - val_loss: 0.6616 - val_acc: 0.7143\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3879 - acc: 0.9467 - val_loss: 0.6588 - val_acc: 0.7143\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3824 - acc: 0.9467 - val_loss: 0.6550 - val_acc: 0.7143\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3766 - acc: 0.9527 - val_loss: 0.6520 - val_acc: 0.7143\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3714 - acc: 0.9527 - val_loss: 0.6489 - val_acc: 0.7143\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3661 - acc: 0.9467 - val_loss: 0.6455 - val_acc: 0.7143\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3611 - acc: 0.9467 - val_loss: 0.6427 - val_acc: 0.7143\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3563 - acc: 0.9527 - val_loss: 0.6406 - val_acc: 0.6905\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3511 - acc: 0.9586 - val_loss: 0.6389 - val_acc: 0.6905\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3466 - acc: 0.9645 - val_loss: 0.6368 - val_acc: 0.6905\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3418 - acc: 0.9645 - val_loss: 0.6334 - val_acc: 0.6905\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3371 - acc: 0.9645 - val_loss: 0.6306 - val_acc: 0.6905\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3326 - acc: 0.9645 - val_loss: 0.6291 - val_acc: 0.6905\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3285 - acc: 0.9645 - val_loss: 0.6260 - val_acc: 0.6905\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3238 - acc: 0.9645 - val_loss: 0.6247 - val_acc: 0.6905\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3205 - acc: 0.9645 - val_loss: 0.6262 - val_acc: 0.7143\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3158 - acc: 0.9704 - val_loss: 0.6235 - val_acc: 0.7143\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3113 - acc: 0.9704 - val_loss: 0.6196 - val_acc: 0.7143\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3069 - acc: 0.9704 - val_loss: 0.6159 - val_acc: 0.7381\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3032 - acc: 0.9704 - val_loss: 0.6125 - val_acc: 0.7143\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2999 - acc: 0.9763 - val_loss: 0.6108 - val_acc: 0.7381\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2981 - acc: 0.9704 - val_loss: 0.6134 - val_acc: 0.7381\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2919 - acc: 0.9704 - val_loss: 0.6106 - val_acc: 0.7381\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2880 - acc: 0.9763 - val_loss: 0.6075 - val_acc: 0.7381\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2846 - acc: 0.9763 - val_loss: 0.6039 - val_acc: 0.7381\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2811 - acc: 0.9763 - val_loss: 0.6026 - val_acc: 0.7381\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2777 - acc: 0.9763 - val_loss: 0.6022 - val_acc: 0.7381\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2744 - acc: 0.9763 - val_loss: 0.5999 - val_acc: 0.7381\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2708 - acc: 0.9822 - val_loss: 0.5997 - val_acc: 0.7381\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2676 - acc: 0.9763 - val_loss: 0.6002 - val_acc: 0.7381\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2645 - acc: 0.9763 - val_loss: 0.5987 - val_acc: 0.7381\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2617 - acc: 0.9763 - val_loss: 0.5980 - val_acc: 0.7381\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2581 - acc: 0.9763 - val_loss: 0.5940 - val_acc: 0.7381\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2555 - acc: 0.9882 - val_loss: 0.5892 - val_acc: 0.7619\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2530 - acc: 0.9882 - val_loss: 0.5875 - val_acc: 0.7619\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2499 - acc: 0.9882 - val_loss: 0.5882 - val_acc: 0.7619\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "[[23  3]\n",
      " [ 7  9]]\n",
      "None\n",
      "(0.75, 0.7619047619047619, 0.5625, 0.6428571428571429, 0.8461538461538461, 0.7410768233959024, 0.7274898301129172)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " snv_inputs (InputLayer)        [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " mRNA_inputs (InputLayer)       [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " miRNA_inputs (InputLayer)      [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " h0_snv (Biological_module)     (None, 238)          3387        ['snv_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " h0_mRNA (Biological_module)    (None, 238)          3276        ['mRNA_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " h0_miRNA (Biological_module)   (None, 238)          8973        ['miRNA_inputs[0][0]']           \n",
      "                                                                                                  \n",
      " self__attention_9 (Self_Attent  (None, 64)          45696       ['h0_snv[0][0]']                 \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " self__attention_10 (Self_Atten  (None, 64)          45696       ['h0_mRNA[0][0]']                \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_11 (Self_Atten  (None, 64)          45696       ['h0_miRNA[0][0]']               \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 192)          0           ['self__attention_9[0][0]',      \n",
      "                                                                  'self__attention_10[0][0]',     \n",
      "                                                                  'self__attention_11[0][0]']     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 32)           6176        ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            33          ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 158,933\n",
      "Trainable params: 158,933\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "1/3 [=========>....................] - ETA: 2s - loss: 1.4926 - acc: 0.5000WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "3/3 [==============================] - 2s 177ms/step - loss: 1.4935 - acc: 0.5266 - val_loss: 1.4826 - val_acc: 0.5952\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4792 - acc: 0.5621 - val_loss: 1.4685 - val_acc: 0.6429\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4651 - acc: 0.5740 - val_loss: 1.4544 - val_acc: 0.5952\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.4512 - acc: 0.6154 - val_loss: 1.4406 - val_acc: 0.6190\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4374 - acc: 0.6095 - val_loss: 1.4271 - val_acc: 0.5952\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4239 - acc: 0.6154 - val_loss: 1.4137 - val_acc: 0.5952\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.4106 - acc: 0.5444 - val_loss: 1.4006 - val_acc: 0.4762\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3974 - acc: 0.5858 - val_loss: 1.3876 - val_acc: 0.4286\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3845 - acc: 0.6568 - val_loss: 1.3749 - val_acc: 0.5000\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3717 - acc: 0.5799 - val_loss: 1.3624 - val_acc: 0.4524\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3592 - acc: 0.4142 - val_loss: 1.3502 - val_acc: 0.3810\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3469 - acc: 0.3964 - val_loss: 1.3381 - val_acc: 0.3810\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.3348 - acc: 0.3964 - val_loss: 1.3264 - val_acc: 0.3810\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.3229 - acc: 0.3905 - val_loss: 1.3148 - val_acc: 0.3810\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3111 - acc: 0.3905 - val_loss: 1.3035 - val_acc: 0.3810\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.2996 - acc: 0.3905 - val_loss: 1.2923 - val_acc: 0.3810\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.2883 - acc: 0.3905 - val_loss: 1.2813 - val_acc: 0.3810\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.2771 - acc: 0.3905 - val_loss: 1.2706 - val_acc: 0.3810\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.2661 - acc: 0.3905 - val_loss: 1.2599 - val_acc: 0.3810\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.2553 - acc: 0.3905 - val_loss: 1.2496 - val_acc: 0.3810\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.2446 - acc: 0.3905 - val_loss: 1.2394 - val_acc: 0.3810\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.2342 - acc: 0.3905 - val_loss: 1.2294 - val_acc: 0.3810\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.2238 - acc: 0.3905 - val_loss: 1.2194 - val_acc: 0.3810\n",
      "Epoch 24/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 28ms/step - loss: 1.2136 - acc: 0.3964 - val_loss: 1.2096 - val_acc: 0.3810\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.2037 - acc: 0.4083 - val_loss: 1.2001 - val_acc: 0.4048\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.1938 - acc: 0.4201 - val_loss: 1.1907 - val_acc: 0.4048\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1840 - acc: 0.4438 - val_loss: 1.1814 - val_acc: 0.4048\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1744 - acc: 0.4497 - val_loss: 1.1724 - val_acc: 0.4048\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.1649 - acc: 0.4675 - val_loss: 1.1636 - val_acc: 0.4048\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1555 - acc: 0.4675 - val_loss: 1.1549 - val_acc: 0.4048\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.1462 - acc: 0.4911 - val_loss: 1.1464 - val_acc: 0.4048\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.1369 - acc: 0.5030 - val_loss: 1.1379 - val_acc: 0.4048\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.1278 - acc: 0.5148 - val_loss: 1.1298 - val_acc: 0.4286\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.1189 - acc: 0.5266 - val_loss: 1.1218 - val_acc: 0.4286\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1097 - acc: 0.5562 - val_loss: 1.1132 - val_acc: 0.4762\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.1008 - acc: 0.5917 - val_loss: 1.1050 - val_acc: 0.5000\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0920 - acc: 0.6036 - val_loss: 1.0970 - val_acc: 0.5238\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0832 - acc: 0.6331 - val_loss: 1.0891 - val_acc: 0.5476\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0742 - acc: 0.6450 - val_loss: 1.0811 - val_acc: 0.5000\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0655 - acc: 0.6450 - val_loss: 1.0733 - val_acc: 0.5476\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0566 - acc: 0.6450 - val_loss: 1.0663 - val_acc: 0.5238\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0476 - acc: 0.6627 - val_loss: 1.0589 - val_acc: 0.5476\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0384 - acc: 0.6627 - val_loss: 1.0523 - val_acc: 0.5476\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0297 - acc: 0.6450 - val_loss: 1.0459 - val_acc: 0.5476\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0201 - acc: 0.6568 - val_loss: 1.0381 - val_acc: 0.5476\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0109 - acc: 0.6686 - val_loss: 1.0302 - val_acc: 0.5476\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0015 - acc: 0.6923 - val_loss: 1.0227 - val_acc: 0.5238\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9918 - acc: 0.7041 - val_loss: 1.0138 - val_acc: 0.5476\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9822 - acc: 0.6982 - val_loss: 1.0057 - val_acc: 0.5714\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9721 - acc: 0.7160 - val_loss: 0.9969 - val_acc: 0.5714\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9622 - acc: 0.7337 - val_loss: 0.9883 - val_acc: 0.5952\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9522 - acc: 0.7278 - val_loss: 0.9805 - val_acc: 0.6190\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9424 - acc: 0.7160 - val_loss: 0.9717 - val_acc: 0.5952\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9312 - acc: 0.7219 - val_loss: 0.9658 - val_acc: 0.6190\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9210 - acc: 0.7278 - val_loss: 0.9611 - val_acc: 0.5952\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9101 - acc: 0.7337 - val_loss: 0.9573 - val_acc: 0.5952\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8989 - acc: 0.7456 - val_loss: 0.9509 - val_acc: 0.5952\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8882 - acc: 0.7456 - val_loss: 0.9454 - val_acc: 0.5952\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8769 - acc: 0.7456 - val_loss: 0.9385 - val_acc: 0.6190\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8660 - acc: 0.7456 - val_loss: 0.9341 - val_acc: 0.6190\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.8555 - acc: 0.7456 - val_loss: 0.9288 - val_acc: 0.6190\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8445 - acc: 0.7515 - val_loss: 0.9233 - val_acc: 0.6190\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8336 - acc: 0.7515 - val_loss: 0.9148 - val_acc: 0.6190\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8231 - acc: 0.7456 - val_loss: 0.9021 - val_acc: 0.6429\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8117 - acc: 0.7456 - val_loss: 0.8951 - val_acc: 0.6429\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8013 - acc: 0.7515 - val_loss: 0.8893 - val_acc: 0.6429\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7913 - acc: 0.7456 - val_loss: 0.8861 - val_acc: 0.6905\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7808 - acc: 0.7633 - val_loss: 0.8821 - val_acc: 0.6667\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7706 - acc: 0.7574 - val_loss: 0.8821 - val_acc: 0.6429\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7608 - acc: 0.7692 - val_loss: 0.8788 - val_acc: 0.6190\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7504 - acc: 0.7751 - val_loss: 0.8742 - val_acc: 0.6429\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7402 - acc: 0.7751 - val_loss: 0.8638 - val_acc: 0.6667\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7308 - acc: 0.7751 - val_loss: 0.8557 - val_acc: 0.6905\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7208 - acc: 0.7811 - val_loss: 0.8484 - val_acc: 0.6905\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7113 - acc: 0.7811 - val_loss: 0.8445 - val_acc: 0.6905\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7018 - acc: 0.7870 - val_loss: 0.8402 - val_acc: 0.6905\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6925 - acc: 0.7870 - val_loss: 0.8376 - val_acc: 0.6905\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6829 - acc: 0.7929 - val_loss: 0.8307 - val_acc: 0.6905\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6735 - acc: 0.7929 - val_loss: 0.8237 - val_acc: 0.6905\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6646 - acc: 0.8107 - val_loss: 0.8176 - val_acc: 0.6905\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6553 - acc: 0.7988 - val_loss: 0.8178 - val_acc: 0.7143\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6459 - acc: 0.8107 - val_loss: 0.8130 - val_acc: 0.7143\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6369 - acc: 0.8166 - val_loss: 0.8061 - val_acc: 0.7143\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6277 - acc: 0.8284 - val_loss: 0.7981 - val_acc: 0.7143\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6185 - acc: 0.8225 - val_loss: 0.7912 - val_acc: 0.7143\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6094 - acc: 0.8284 - val_loss: 0.7807 - val_acc: 0.7143\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6008 - acc: 0.8343 - val_loss: 0.7708 - val_acc: 0.6905\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5930 - acc: 0.8521 - val_loss: 0.7580 - val_acc: 0.6667\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5843 - acc: 0.8639 - val_loss: 0.7541 - val_acc: 0.6905\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5747 - acc: 0.8580 - val_loss: 0.7564 - val_acc: 0.7143\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5661 - acc: 0.8580 - val_loss: 0.7602 - val_acc: 0.7143\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5586 - acc: 0.8639 - val_loss: 0.7587 - val_acc: 0.7143\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5517 - acc: 0.8580 - val_loss: 0.7425 - val_acc: 0.7143\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5408 - acc: 0.8698 - val_loss: 0.7360 - val_acc: 0.7143\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5330 - acc: 0.8698 - val_loss: 0.7298 - val_acc: 0.7143\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5255 - acc: 0.8757 - val_loss: 0.7172 - val_acc: 0.6667\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5170 - acc: 0.8757 - val_loss: 0.7124 - val_acc: 0.6667\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5088 - acc: 0.8757 - val_loss: 0.7121 - val_acc: 0.7143\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5009 - acc: 0.8817 - val_loss: 0.7098 - val_acc: 0.7143\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4930 - acc: 0.8757 - val_loss: 0.7030 - val_acc: 0.7143\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4852 - acc: 0.8817 - val_loss: 0.6959 - val_acc: 0.6905\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4775 - acc: 0.8876 - val_loss: 0.6886 - val_acc: 0.6667\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4705 - acc: 0.8935 - val_loss: 0.6800 - val_acc: 0.6667\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4626 - acc: 0.8935 - val_loss: 0.6764 - val_acc: 0.6667\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4553 - acc: 0.8935 - val_loss: 0.6741 - val_acc: 0.6905\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4485 - acc: 0.8935 - val_loss: 0.6676 - val_acc: 0.6905\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4417 - acc: 0.9053 - val_loss: 0.6587 - val_acc: 0.6667\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4344 - acc: 0.9053 - val_loss: 0.6565 - val_acc: 0.6905\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4281 - acc: 0.9112 - val_loss: 0.6510 - val_acc: 0.6667\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4212 - acc: 0.9053 - val_loss: 0.6377 - val_acc: 0.6429\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4144 - acc: 0.9172 - val_loss: 0.6328 - val_acc: 0.6429\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4080 - acc: 0.9172 - val_loss: 0.6307 - val_acc: 0.6667\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4013 - acc: 0.9172 - val_loss: 0.6299 - val_acc: 0.6667\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3960 - acc: 0.9290 - val_loss: 0.6322 - val_acc: 0.7143\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3893 - acc: 0.9349 - val_loss: 0.6279 - val_acc: 0.7143\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3835 - acc: 0.9349 - val_loss: 0.6202 - val_acc: 0.7143\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3779 - acc: 0.9349 - val_loss: 0.6108 - val_acc: 0.6667\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3715 - acc: 0.9408 - val_loss: 0.6063 - val_acc: 0.6905\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3658 - acc: 0.9408 - val_loss: 0.6030 - val_acc: 0.6905\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3608 - acc: 0.9467 - val_loss: 0.6002 - val_acc: 0.6905\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3548 - acc: 0.9527 - val_loss: 0.5931 - val_acc: 0.6905\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3496 - acc: 0.9586 - val_loss: 0.5863 - val_acc: 0.6667\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3447 - acc: 0.9527 - val_loss: 0.5841 - val_acc: 0.6667\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3394 - acc: 0.9586 - val_loss: 0.5809 - val_acc: 0.7143\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3343 - acc: 0.9586 - val_loss: 0.5769 - val_acc: 0.6905\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3294 - acc: 0.9586 - val_loss: 0.5718 - val_acc: 0.6905\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3252 - acc: 0.9586 - val_loss: 0.5676 - val_acc: 0.6905\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3200 - acc: 0.9586 - val_loss: 0.5691 - val_acc: 0.7143\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3157 - acc: 0.9704 - val_loss: 0.5712 - val_acc: 0.7381\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3112 - acc: 0.9704 - val_loss: 0.5674 - val_acc: 0.7381\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3067 - acc: 0.9704 - val_loss: 0.5603 - val_acc: 0.7143\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3029 - acc: 0.9586 - val_loss: 0.5531 - val_acc: 0.6905\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2984 - acc: 0.9704 - val_loss: 0.5512 - val_acc: 0.7143\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2940 - acc: 0.9704 - val_loss: 0.5496 - val_acc: 0.7143\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2898 - acc: 0.9763 - val_loss: 0.5517 - val_acc: 0.7143\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2862 - acc: 0.9704 - val_loss: 0.5511 - val_acc: 0.7143\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.2825 - acc: 0.9763 - val_loss: 0.5448 - val_acc: 0.7143\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2782 - acc: 0.9763 - val_loss: 0.5395 - val_acc: 0.7381\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2747 - acc: 0.9704 - val_loss: 0.5333 - val_acc: 0.6905\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2712 - acc: 0.9763 - val_loss: 0.5307 - val_acc: 0.6905\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2678 - acc: 0.9822 - val_loss: 0.5312 - val_acc: 0.7381\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2638 - acc: 0.9822 - val_loss: 0.5311 - val_acc: 0.7381\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2604 - acc: 0.9822 - val_loss: 0.5298 - val_acc: 0.7381\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2573 - acc: 0.9822 - val_loss: 0.5281 - val_acc: 0.7381\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2538 - acc: 0.9882 - val_loss: 0.5249 - val_acc: 0.7381\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2506 - acc: 0.9882 - val_loss: 0.5234 - val_acc: 0.7381\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2474 - acc: 0.9882 - val_loss: 0.5191 - val_acc: 0.7381\n",
      "Epoch 148/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2442 - acc: 0.9882 - val_loss: 0.5170 - val_acc: 0.7381\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2413 - acc: 0.9882 - val_loss: 0.5155 - val_acc: 0.7381\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2382 - acc: 0.9882 - val_loss: 0.5158 - val_acc: 0.7381\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "[[19  7]\n",
      " [ 4 12]]\n",
      "None\n",
      "(0.631578947368421, 0.7380952380952381, 0.75, 0.6857142857142857, 0.875, 0.8410650719993751, 0.8365473963879494)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " snv_inputs (InputLayer)        [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " mRNA_inputs (InputLayer)       [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " miRNA_inputs (InputLayer)      [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " h0_snv (Biological_module)     (None, 238)          3387        ['snv_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " h0_mRNA (Biological_module)    (None, 238)          3276        ['mRNA_inputs[0][0]']            \n",
      "                                                                                                  \n",
      " h0_miRNA (Biological_module)   (None, 238)          8973        ['miRNA_inputs[0][0]']           \n",
      "                                                                                                  \n",
      " self__attention_12 (Self_Atten  (None, 64)          45696       ['h0_snv[0][0]']                 \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_13 (Self_Atten  (None, 64)          45696       ['h0_mRNA[0][0]']                \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " self__attention_14 (Self_Atten  (None, 64)          45696       ['h0_miRNA[0][0]']               \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 192)          0           ['self__attention_12[0][0]',     \n",
      "                                                                  'self__attention_13[0][0]',     \n",
      "                                                                  'self__attention_14[0][0]']     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 32)           6176        ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            33          ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 158,933\n",
      "Trainable params: 158,933\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "1/3 [=========>....................] - ETA: 2s - loss: 1.5076 - acc: 0.4375WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "3/3 [==============================] - 2s 213ms/step - loss: 1.4865 - acc: 0.3846 - val_loss: 1.4780 - val_acc: 0.4048\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4722 - acc: 0.3846 - val_loss: 1.4638 - val_acc: 0.4048\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.4581 - acc: 0.3846 - val_loss: 1.4499 - val_acc: 0.4048\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.4442 - acc: 0.3846 - val_loss: 1.4361 - val_acc: 0.4286\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.4305 - acc: 0.3846 - val_loss: 1.4225 - val_acc: 0.4286\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4170 - acc: 0.3964 - val_loss: 1.4092 - val_acc: 0.4048\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4037 - acc: 0.4320 - val_loss: 1.3960 - val_acc: 0.4524\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.3906 - acc: 0.4911 - val_loss: 1.3830 - val_acc: 0.5476\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.3777 - acc: 0.6213 - val_loss: 1.3701 - val_acc: 0.6190\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3650 - acc: 0.7278 - val_loss: 1.3576 - val_acc: 0.5952\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3525 - acc: 0.7041 - val_loss: 1.3452 - val_acc: 0.5714\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3402 - acc: 0.7160 - val_loss: 1.3331 - val_acc: 0.5952\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.3281 - acc: 0.7396 - val_loss: 1.3212 - val_acc: 0.6190\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.3161 - acc: 0.7337 - val_loss: 1.3095 - val_acc: 0.6429\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.3045 - acc: 0.6923 - val_loss: 1.2981 - val_acc: 0.6429\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.2929 - acc: 0.7219 - val_loss: 1.2867 - val_acc: 0.6190\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.2815 - acc: 0.7278 - val_loss: 1.2755 - val_acc: 0.6190\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.2704 - acc: 0.7160 - val_loss: 1.2644 - val_acc: 0.6429\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.2594 - acc: 0.7337 - val_loss: 1.2536 - val_acc: 0.6190\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2485 - acc: 0.7219 - val_loss: 1.2429 - val_acc: 0.6429\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.2379 - acc: 0.7219 - val_loss: 1.2325 - val_acc: 0.6190\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.2274 - acc: 0.7041 - val_loss: 1.2221 - val_acc: 0.6429\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.2170 - acc: 0.7219 - val_loss: 1.2120 - val_acc: 0.6667\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.2068 - acc: 0.7219 - val_loss: 1.2019 - val_acc: 0.6429\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.1967 - acc: 0.7219 - val_loss: 1.1920 - val_acc: 0.6190\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1869 - acc: 0.7101 - val_loss: 1.1821 - val_acc: 0.6190\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1770 - acc: 0.7219 - val_loss: 1.1726 - val_acc: 0.6429\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.1674 - acc: 0.7160 - val_loss: 1.1632 - val_acc: 0.6429\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.1577 - acc: 0.7160 - val_loss: 1.1540 - val_acc: 0.6429\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1483 - acc: 0.7160 - val_loss: 1.1448 - val_acc: 0.6667\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.1389 - acc: 0.7278 - val_loss: 1.1359 - val_acc: 0.6667\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.1295 - acc: 0.7278 - val_loss: 1.1269 - val_acc: 0.6667\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1203 - acc: 0.7278 - val_loss: 1.1181 - val_acc: 0.6429\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.1110 - acc: 0.7337 - val_loss: 1.1094 - val_acc: 0.6429\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1018 - acc: 0.7337 - val_loss: 1.1011 - val_acc: 0.6429\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0927 - acc: 0.7396 - val_loss: 1.0930 - val_acc: 0.6905\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0837 - acc: 0.7219 - val_loss: 1.0851 - val_acc: 0.6667\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0745 - acc: 0.7219 - val_loss: 1.0768 - val_acc: 0.6667\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0655 - acc: 0.7041 - val_loss: 1.0689 - val_acc: 0.6667\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0563 - acc: 0.7160 - val_loss: 1.0603 - val_acc: 0.6667\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0472 - acc: 0.7160 - val_loss: 1.0511 - val_acc: 0.6905\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0379 - acc: 0.7396 - val_loss: 1.0417 - val_acc: 0.6667\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0286 - acc: 0.7515 - val_loss: 1.0324 - val_acc: 0.6429\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0194 - acc: 0.7515 - val_loss: 1.0233 - val_acc: 0.6905\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.0099 - acc: 0.7515 - val_loss: 1.0143 - val_acc: 0.6905\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0003 - acc: 0.7337 - val_loss: 1.0047 - val_acc: 0.6905\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9907 - acc: 0.7219 - val_loss: 0.9954 - val_acc: 0.6667\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9808 - acc: 0.7278 - val_loss: 0.9868 - val_acc: 0.6667\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9710 - acc: 0.7278 - val_loss: 0.9787 - val_acc: 0.6667\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9608 - acc: 0.7278 - val_loss: 0.9697 - val_acc: 0.6905\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9508 - acc: 0.7278 - val_loss: 0.9614 - val_acc: 0.6905\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9414 - acc: 0.7515 - val_loss: 0.9548 - val_acc: 0.6667\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9302 - acc: 0.7574 - val_loss: 0.9452 - val_acc: 0.6667\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9200 - acc: 0.7574 - val_loss: 0.9367 - val_acc: 0.6905\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9092 - acc: 0.7633 - val_loss: 0.9268 - val_acc: 0.6667\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8986 - acc: 0.7515 - val_loss: 0.9167 - val_acc: 0.7143\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8882 - acc: 0.7456 - val_loss: 0.9072 - val_acc: 0.7143\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8776 - acc: 0.7574 - val_loss: 0.8996 - val_acc: 0.6667\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8667 - acc: 0.7574 - val_loss: 0.8899 - val_acc: 0.7143\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8559 - acc: 0.7692 - val_loss: 0.8818 - val_acc: 0.6905\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8449 - acc: 0.7692 - val_loss: 0.8735 - val_acc: 0.6667\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8344 - acc: 0.7692 - val_loss: 0.8654 - val_acc: 0.6667\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8236 - acc: 0.7692 - val_loss: 0.8561 - val_acc: 0.6905\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8125 - acc: 0.7692 - val_loss: 0.8497 - val_acc: 0.6667\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8020 - acc: 0.7751 - val_loss: 0.8436 - val_acc: 0.6905\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7913 - acc: 0.7751 - val_loss: 0.8350 - val_acc: 0.7143\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7804 - acc: 0.7811 - val_loss: 0.8270 - val_acc: 0.7143\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7703 - acc: 0.7811 - val_loss: 0.8177 - val_acc: 0.6905\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7595 - acc: 0.7811 - val_loss: 0.8080 - val_acc: 0.6667\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7487 - acc: 0.7870 - val_loss: 0.7998 - val_acc: 0.6667\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7387 - acc: 0.7988 - val_loss: 0.7926 - val_acc: 0.6905\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7273 - acc: 0.8047 - val_loss: 0.7880 - val_acc: 0.7143\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7173 - acc: 0.8107 - val_loss: 0.7836 - val_acc: 0.6905\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7074 - acc: 0.8166 - val_loss: 0.7775 - val_acc: 0.6905\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6973 - acc: 0.8166 - val_loss: 0.7701 - val_acc: 0.6905\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6871 - acc: 0.8166 - val_loss: 0.7620 - val_acc: 0.6905\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6764 - acc: 0.8343 - val_loss: 0.7521 - val_acc: 0.7381\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6687 - acc: 0.8402 - val_loss: 0.7390 - val_acc: 0.7381\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6567 - acc: 0.8521 - val_loss: 0.7336 - val_acc: 0.7381\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6462 - acc: 0.8521 - val_loss: 0.7282 - val_acc: 0.7381\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6363 - acc: 0.8521 - val_loss: 0.7234 - val_acc: 0.7143\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6266 - acc: 0.8580 - val_loss: 0.7194 - val_acc: 0.7381\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6177 - acc: 0.8817 - val_loss: 0.7145 - val_acc: 0.7381\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6077 - acc: 0.8876 - val_loss: 0.7044 - val_acc: 0.7143\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5977 - acc: 0.8757 - val_loss: 0.6966 - val_acc: 0.7381\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5885 - acc: 0.8876 - val_loss: 0.6891 - val_acc: 0.7619\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5790 - acc: 0.8876 - val_loss: 0.6839 - val_acc: 0.7619\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5708 - acc: 0.8935 - val_loss: 0.6802 - val_acc: 0.7381\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5607 - acc: 0.8935 - val_loss: 0.6749 - val_acc: 0.7381\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5515 - acc: 0.8935 - val_loss: 0.6697 - val_acc: 0.7619\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5428 - acc: 0.8935 - val_loss: 0.6642 - val_acc: 0.7381\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5343 - acc: 0.8935 - val_loss: 0.6589 - val_acc: 0.7381\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5255 - acc: 0.8994 - val_loss: 0.6516 - val_acc: 0.7381\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5171 - acc: 0.8935 - val_loss: 0.6433 - val_acc: 0.7619\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5089 - acc: 0.9112 - val_loss: 0.6360 - val_acc: 0.7619\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5008 - acc: 0.9172 - val_loss: 0.6316 - val_acc: 0.7857\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4927 - acc: 0.9112 - val_loss: 0.6291 - val_acc: 0.7619\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4843 - acc: 0.9172 - val_loss: 0.6258 - val_acc: 0.7619\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4768 - acc: 0.9172 - val_loss: 0.6204 - val_acc: 0.7619\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4688 - acc: 0.9231 - val_loss: 0.6170 - val_acc: 0.7619\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4613 - acc: 0.9231 - val_loss: 0.6127 - val_acc: 0.7619\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4539 - acc: 0.9231 - val_loss: 0.6074 - val_acc: 0.7857\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4466 - acc: 0.9231 - val_loss: 0.6024 - val_acc: 0.7857\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4395 - acc: 0.9231 - val_loss: 0.5968 - val_acc: 0.7857\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4324 - acc: 0.9231 - val_loss: 0.5925 - val_acc: 0.7857\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4256 - acc: 0.9231 - val_loss: 0.5891 - val_acc: 0.7857\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4192 - acc: 0.9290 - val_loss: 0.5876 - val_acc: 0.7857\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4126 - acc: 0.9290 - val_loss: 0.5824 - val_acc: 0.7857\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4057 - acc: 0.9290 - val_loss: 0.5768 - val_acc: 0.7857\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3992 - acc: 0.9349 - val_loss: 0.5725 - val_acc: 0.7857\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3934 - acc: 0.9527 - val_loss: 0.5685 - val_acc: 0.7857\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3872 - acc: 0.9467 - val_loss: 0.5658 - val_acc: 0.7857\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3812 - acc: 0.9349 - val_loss: 0.5633 - val_acc: 0.7857\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3752 - acc: 0.9408 - val_loss: 0.5600 - val_acc: 0.7857\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3704 - acc: 0.9408 - val_loss: 0.5576 - val_acc: 0.7857\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3640 - acc: 0.9467 - val_loss: 0.5533 - val_acc: 0.7857\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3585 - acc: 0.9645 - val_loss: 0.5493 - val_acc: 0.7857\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3536 - acc: 0.9645 - val_loss: 0.5465 - val_acc: 0.7857\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3484 - acc: 0.9704 - val_loss: 0.5445 - val_acc: 0.7857\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3429 - acc: 0.9763 - val_loss: 0.5423 - val_acc: 0.7857\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3378 - acc: 0.9763 - val_loss: 0.5395 - val_acc: 0.7857\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3330 - acc: 0.9763 - val_loss: 0.5367 - val_acc: 0.7857\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3281 - acc: 0.9763 - val_loss: 0.5336 - val_acc: 0.7857\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3236 - acc: 0.9763 - val_loss: 0.5312 - val_acc: 0.8095\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.3189 - acc: 0.9822 - val_loss: 0.5289 - val_acc: 0.7857\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3143 - acc: 0.9763 - val_loss: 0.5268 - val_acc: 0.7857\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3100 - acc: 0.9763 - val_loss: 0.5248 - val_acc: 0.7857\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3060 - acc: 0.9763 - val_loss: 0.5223 - val_acc: 0.7857\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3019 - acc: 0.9763 - val_loss: 0.5206 - val_acc: 0.7857\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2975 - acc: 0.9763 - val_loss: 0.5177 - val_acc: 0.8095\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2931 - acc: 0.9822 - val_loss: 0.5159 - val_acc: 0.8095\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2894 - acc: 0.9822 - val_loss: 0.5140 - val_acc: 0.8095\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2855 - acc: 0.9882 - val_loss: 0.5124 - val_acc: 0.8095\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2818 - acc: 0.9882 - val_loss: 0.5104 - val_acc: 0.8095\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2789 - acc: 0.9882 - val_loss: 0.5084 - val_acc: 0.8095\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2743 - acc: 0.9882 - val_loss: 0.5068 - val_acc: 0.8095\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2705 - acc: 0.9882 - val_loss: 0.5056 - val_acc: 0.8333\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2677 - acc: 0.9882 - val_loss: 0.5050 - val_acc: 0.8333\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2642 - acc: 0.9882 - val_loss: 0.5027 - val_acc: 0.8333\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2604 - acc: 0.9882 - val_loss: 0.5005 - val_acc: 0.8095\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2568 - acc: 0.9882 - val_loss: 0.4989 - val_acc: 0.8095\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2555 - acc: 0.9822 - val_loss: 0.4980 - val_acc: 0.8095\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2516 - acc: 0.9822 - val_loss: 0.4961 - val_acc: 0.8095\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2485 - acc: 0.9882 - val_loss: 0.4958 - val_acc: 0.8333\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2449 - acc: 0.9882 - val_loss: 0.4959 - val_acc: 0.8333\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2433 - acc: 0.9882 - val_loss: 0.4931 - val_acc: 0.8333\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2388 - acc: 0.9882 - val_loss: 0.4924 - val_acc: 0.8333\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2361 - acc: 0.9882 - val_loss: 0.4904 - val_acc: 0.8333\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2331 - acc: 0.9882 - val_loss: 0.4889 - val_acc: 0.8333\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2303 - acc: 0.9882 - val_loss: 0.4875 - val_acc: 0.8333\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WQ.shape (None, 64)\n",
      "K.permute_dimensions(WK.shape (64, None)\n",
      "QK.shape (64, 64)\n",
      "(None, 64)\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D704D401F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[24  1]\n",
      " [ 6 11]]\n",
      "None\n",
      "(0.9166666666666666, 0.8333333333333334, 0.6470588235294118, 0.7586206896551724, 0.9129411764705883, 0.8664071609505046, 0.8606814195015342)\n",
      "Cross validated results :  ACC = 0.782170542635659, REC = 0.625, F1 = 0.6793620073080344, AUC = 0.8847658371040724, AUPR =0.8398564001557339\n"
     ]
    }
   ],
   "source": [
    "#  5-fold cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=1029) \n",
    "\n",
    "kfscore = []\n",
    "for train_index, test_index in skf.split(snv_data.values,y):\n",
    "\n",
    "    snv_train_x = snv_data.values[train_index]\n",
    "    snv_test_x  = snv_data.values[test_index]\n",
    "\n",
    "    mRNA_train_x = mRNA_data.values[train_index]\n",
    "    mRNA_test_x  = mRNA_data.values[test_index]\n",
    "\n",
    "    miRNA_train_x = miRNA_data.values[train_index]\n",
    "    miRNA_test_x  = miRNA_data.values[test_index]\n",
    "\n",
    "    train_y  = y[train_index]\n",
    "    test_y   = y[test_index]\n",
    "\n",
    "    model = create_model(snv_data,mRNA_data,miRNA_data)\n",
    "    model.fit( {\"snv_inputs\": snv_train_x,  \"mRNA_inputs\": mRNA_train_x, 'miRNA_inputs':miRNA_train_x},train_y,\n",
    "                 validation_data=({\"snv_inputs\": snv_test_x, \"mRNA_inputs\": mRNA_test_x,'miRNA_inputs':miRNA_test_x},test_y),\n",
    "                 epochs=150,batch_size = 64,class_weight = {0:x_0,1:x_1})  \n",
    "\n",
    "    y_pred = model.predict({\"snv_inputs\": snv_test_x, \"mRNA_inputs\": mRNA_test_x,'miRNA_inputs':miRNA_test_x})\n",
    "\n",
    "    y_score = [1 if index>=0.5  else 0 for index in  y_pred]\n",
    "\n",
    "    evaluate_epoch = get_metrics(test_y,y_score,y_pred)\n",
    "    print(evaluate_epoch)\n",
    "    kfscore.append(evaluate_epoch)\n",
    "    \n",
    "results = list(np.array(kfscore).sum(axis= 0)/5.0)\n",
    "print('Cross validated results :  ACC = {}, REC = {}, F1 = {}, AUC = {}, AUPR ={}'.format(results[1],results[2],results[3],results[4],results[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ff269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
